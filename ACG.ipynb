{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPPKPPf5VL+3V0+T3oUASh/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArthiyaD/TroubleShooters/blob/Development/ACG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ohhq97L1PZUS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5f9b48f-cedb-492a-ad15-984f8414cb9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gensim==3.8.3\n",
            "  Downloading gensim-3.8.3.tar.gz (23.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.4/23.4 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.9/dist-packages (from gensim==3.8.3) (1.22.4)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.9/dist-packages (from gensim==3.8.3) (1.10.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.9/dist-packages (from gensim==3.8.3) (1.16.0)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from gensim==3.8.3) (6.3.0)\n",
            "Building wheels for collected packages: gensim\n",
            "  Building wheel for gensim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gensim: filename=gensim-3.8.3-cp39-cp39-linux_x86_64.whl size=26528062 sha256=22a88225865f394a8280ed9a335e27b8658c0eb1acccf0d456178378fade3410\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/5d/af/618594ec2f28608c1d6ee7d2b7e95a3e9b06551e3b80a491d6\n",
            "Successfully built gensim\n",
            "Installing collected packages: gensim\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 4.3.1\n",
            "    Uninstalling gensim-4.3.1:\n",
            "      Successfully uninstalled gensim-4.3.1\n",
            "Successfully installed gensim-3.8.3\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim==3.8.3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle as pkl\n",
        "import cv2\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "from gensim.models import Word2Vec,KeyedVectors\n",
        "from IPython.display import Image, display\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras.preprocessing import image, sequence\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50"
      ],
      "metadata": {
        "id": "JFzaG53LPdnB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78bdbfef-4804-43c8-c5c5-9493b44b40bf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "KMQfbcPiiCGc",
        "outputId": "a2103259-73e4-4fb9-f9da-bab3635bd024"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.12.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1Y6v9wfUkibbYBTso534eK9uWJ3JzXKO9\n",
        "!gdown 1Z4C6sVs5EhnwhW6I8m-DKhYJw3e7A6WX\n",
        "!gdown 1Xv3CVAUuQPZbgQJqWJbuiPx14hcApcj5\n",
        "!gdown 1YN4m-gece5itGTzIUdZC1t8pn1sWWZOc\n",
        "!gdown 1jNFcFytMGUnG3oTgIYttilXD5B7ORjlD"
      ],
      "metadata": {
        "id": "5uq6UNTXPiRy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d23d9c1-4876-458b-dab3-0ce7e432fd69"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Y6v9wfUkibbYBTso534eK9uWJ3JzXKO9\n",
            "To: /content/model_text_categorize.h5\n",
            "100% 1.15M/1.15M [00:00<00:00, 125MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Z4C6sVs5EhnwhW6I8m-DKhYJw3e7A6WX\n",
            "To: /content/GoogleNews-vectors-negative300.bin.gz\n",
            "100% 1.65G/1.65G [00:26<00:00, 63.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Xv3CVAUuQPZbgQJqWJbuiPx14hcApcj5\n",
            "To: /content/saved_model.hp5\n",
            "100% 60.0M/60.0M [00:00<00:00, 137MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1YN4m-gece5itGTzIUdZC1t8pn1sWWZOc\n",
            "To: /content/word_2_indices.pickle\n",
            "100% 105k/105k [00:00<00:00, 66.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1jNFcFytMGUnG3oTgIYttilXD5B7ORjlD\n",
            "To: /content/indices_2_word.pickle\n",
            "100% 105k/105k [00:00<00:00, 82.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_vect = '/content/GoogleNews-vectors-negative300.bin.gz'\n",
        "model_text = '/content/model_text_categorize.h5'\n",
        "model_image = '/content/saved_model.hp5'\n",
        "\n",
        "loaded_model = tf.keras.models.load_model(model_text)\n",
        "saved_model = tf.keras.models.load_model(model_image)\n",
        "model = KeyedVectors.load_word2vec_format(word_vect, \n",
        "                                          binary=True,\n",
        "                                          limit=1000000)"
      ],
      "metadata": {
        "id": "VWlMtuTmPlRi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet = ResNet50(include_top=False, weights='imagenet',\n",
        "                  input_shape=(224,224,3), pooling='avg')"
      ],
      "metadata": {
        "id": "_okk2zPTPmtS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab6b7acc-878c-4408-f48c-4ba57ee592cf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/word_2_indices.pickle', 'rb') as handle:\n",
        "     word_2_indices = pkl.load(handle)\n",
        "\n",
        "with open('/content/indices_2_word.pickle', 'rb') as handle:\n",
        "    indices_2_word = pkl.load(handle)"
      ],
      "metadata": {
        "id": "Ec5ZwbPfQ_g5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(img_path):\n",
        "    im = image.load_img(img_path, target_size=(224,224,3))\n",
        "    im = image.img_to_array(im)\n",
        "    im = np.expand_dims(im, axis=0)\n",
        "    return im\n",
        "\n",
        "def get_encoding(model1, img):\n",
        "    image = preprocessing(img)\n",
        "    pred = model1.predict(image, verbose=0).reshape(2048)\n",
        "    return pred\n",
        "\n",
        "def predict_captions(image,model):\n",
        "    start_word = [\"<start>\"]\n",
        "    while True:\n",
        "        par_caps = [word_2_indices[i] for i in start_word]\n",
        "        par_caps = sequence.pad_sequences([par_caps], maxlen=40, \n",
        "                                          padding='post')\n",
        "        preds = model.predict([np.array([image]), np.array(par_caps)], verbose=0)\n",
        "        word_pred = indices_2_word[np.argmax(preds[0])]\n",
        "        start_word.append(word_pred)\n",
        "        \n",
        "        if word_pred == \"<end>\" or len(start_word) >40:\n",
        "            break\n",
        "            \n",
        "    return ' '.join(start_word[1:-1])\n",
        "\n",
        "def word_vector(tokens,size,model):\n",
        "  vec = np.zeros(size).reshape((1, size))\n",
        "  count = 0\n",
        "  for word in tokens:\n",
        "    vec += model[word].reshape((1, size))\n",
        "    count += 1.\n",
        "  if count != 0:\n",
        "      vec /= count\n",
        "  return vec\n",
        "\n",
        "def token_check(x,model):\n",
        "  token_list=[]\n",
        "  for i in x:\n",
        "      if len(i) > 3 and i in model.vocab:\n",
        "          token_list.append(i)\n",
        "      else:\n",
        "          continue\n",
        "  return token_list\n",
        "\n",
        "def clean_description_text(description):\n",
        "  description = description.replace(r'\\d+','')\n",
        "  spec_chars = [\"!\",'\"',\"#\",\"%\",\"&\",\"'\",\"(\",\")\",\n",
        "                \"*\",\"+\",\",\",\"-\",\".\",\"/\",\":\",\";\",\"<\",\n",
        "                \"=\",\">\",\"?\",\"@\",\"[\",\"\\\\\",\"]\",\"^\",\"_\",\n",
        "                \"`\",\"{\",\"|\",\"}\",\"~\",\"–\"]\n",
        "  for char in spec_chars:\n",
        "      description = description.replace(char, ' ')\n",
        "\n",
        "  word_list_t = description.lower().split() \n",
        " \n",
        "  filtered_words = [word for word in word_list_t \n",
        "                    if word not in stopwords.words('english')]\n",
        "  text = ' '.join(filtered_words)\n",
        "  return text\n",
        "\n",
        "def FrameCapture(path):\n",
        "    vidObj = cv2.VideoCapture(path)\n",
        "    success, image = vidObj.read()\n",
        "    cv2.imwrite(\"frame.jpg\", image)\n"
      ],
      "metadata": {
        "id": "8Fj6XNsfRBRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "option = input(\"Enter Video or Image\")\n",
        "\n",
        "if option == \"Video\"\n",
        "   # Input the video path\n",
        "   img = input(\"Video Path: \")\n",
        "\n",
        "  # Convert to frames\n",
        "   FrameCapture(img)\n",
        "   frame_path = '/content/frame.jpg'\n",
        "\n",
        "elif option == \"Image\"\n",
        "   # Input the image path\n",
        "   frame_path = input(\"Image Path: \")\n",
        "\n",
        "\n",
        "# Load the Image and Preprocess\n",
        "test_img = get_encoding(resnet, frame_path)\n",
        "\n",
        "# Predict the caption\n",
        "caption = predict_captions(test_img,saved_model)\n",
        "\n",
        "# Predict the image category\n",
        "clean_description = clean_description_text(caption)\n",
        "description_tokens = list(clean_description.split(\" \"))\n",
        "description_tokens_filtered = token_check(description_tokens,model)\n",
        "\n",
        "_arrays = np.zeros((1, 300))\n",
        "_arrays[0,:] = word_vector(description_tokens_filtered,300,model)\n",
        "vectorized_array = pd.DataFrame(_arrays)\n",
        "\n",
        "pred = loaded_model.predict([vectorized_array.iloc[:,0:300]], verbose=0)\n",
        "value = np.argmax(pred, axis=-1)\n",
        "labels = ['adventure','art and music','food','history','manufacturing',\n",
        "          'nature','science and technology','sports','travel']\n",
        "\n",
        "# Print the result\n",
        "img = mpimg.imread(frame_path)\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nPredicted Caption : \", caption)\n",
        "print(\"Predicted Label   : \", labels[value.item()]) "
      ],
      "metadata": {
        "id": "C0L4YUkdtsDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "captions = pd.read_csv('/content/ModelCaptions.csv')\n",
        "is_category = captions['Category'].str.lower()==  labels[value.item()]\n",
        "df = captions.loc[is_category]\n",
        "    #df.columns = ('Category', 'Description')\n",
        "    #df.head()\n",
        "caption_list = df['Description']\n",
        "result = \"'\"\n",
        "count = 1\n",
        "for caption in caption_list:\n",
        "        result = caption\n",
        "        print (result)\n",
        "        count = count+1\n",
        "        if (count == 6):\n",
        "            break "
      ],
      "metadata": {
        "id": "54G-WDQCuD55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_obj = {\"captions\": result}\n",
        "\n",
        "# Save the JSON object to a file\n",
        "with open(\"result.json\", \"w\") as outfile:\n",
        "    json.dump(json_obj, outfile)"
      ],
      "metadata": {
        "id": "0Vr5I0mw-aBv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}