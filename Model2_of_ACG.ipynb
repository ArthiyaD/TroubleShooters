{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArthiyaD/TroubleShooters/blob/Development/Model2_of_ACG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEsFY8NAncAd",
        "outputId": "a52a196c-4888-40b0-dac8-3de895a61b15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'AI-based-Social-Media-Caption-Generator'...\n",
            "remote: Enumerating objects: 63, done.\u001b[K\n",
            "remote: Counting objects: 100% (63/63), done.\u001b[K\n",
            "remote: Compressing objects: 100% (61/61), done.\u001b[K\n",
            "remote: Total 63 (delta 28), reused 0 (delta 0), pack-reused 0\n",
            "Unpacking objects: 100% (63/63), 3.54 MiB | 3.69 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/aashish-bidap/AI-based-Social-Media-Caption-Generator.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJSTG8ibrNEr"
      },
      "outputs": [],
      "source": [
        "/content/drive/My Drive/GoogleNews-vectors-negative300.bin.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avd8SMHo7D7Q",
        "outputId": "65f9029a-8e6f-46e3-a501-c15350d1ff91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gensim==3.8.3\n",
            "  Downloading gensim-3.8.3.tar.gz (23.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.4/23.4 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.9/dist-packages (from gensim==3.8.3) (1.22.4)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.9/dist-packages (from gensim==3.8.3) (1.10.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.9/dist-packages (from gensim==3.8.3) (1.16.0)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from gensim==3.8.3) (6.3.0)\n",
            "Building wheels for collected packages: gensim\n",
            "  Building wheel for gensim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gensim: filename=gensim-3.8.3-cp39-cp39-linux_x86_64.whl size=26528010 sha256=2e95fae070b650770b7b2e18bc3e93d87a205dc35d9d927b101a6d01f4c41c28\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/5d/af/618594ec2f28608c1d6ee7d2b7e95a3e9b06551e3b80a491d6\n",
            "Successfully built gensim\n",
            "Installing collected packages: gensim\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 4.3.1\n",
            "    Uninstalling gensim-4.3.1:\n",
            "      Successfully uninstalled gensim-4.3.1\n",
            "Successfully installed gensim-3.8.3\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim==3.8.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLmlpyEfpR04",
        "outputId": "6f30c21d-b4b3-4ba4-e5f6-b51154ed7a67"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xy1rpuh6lAE0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "oM7XRlZopX_J",
        "outputId": "76d3ad55-d360-4ed8-d075-c92d95a9e20d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-92d51eea-0a8f-4978-bbf9-15f00880a3eb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Category</th>\n",
              "      <th>Description</th>\n",
              "      <th>Title</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Video Id</th>\n",
              "      <th>file</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>travel</td>\n",
              "      <td>DISCLAIMER* Please do not ride elephants when ...</td>\n",
              "      <td>Welcome to Bali | Travel Vlog | Priscilla Lee</td>\n",
              "      <td>0</td>\n",
              "      <td>i9E_Blai8vk</td>\n",
              "      <td>Collected_data_raw1.csv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>travel</td>\n",
              "      <td>Had the most amazing experience in Finland for...</td>\n",
              "      <td>FINLAND VACATION: TRAVEL VLOG</td>\n",
              "      <td>1</td>\n",
              "      <td>UBvJKs9eW3I</td>\n",
              "      <td>Collected_data_raw1.csv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>travel</td>\n",
              "      <td>Hello loves Today's video is the Vlog of my tr...</td>\n",
              "      <td>MYKONOS GREECE TRAVEL VLOG 2020 |  Living our ...</td>\n",
              "      <td>2</td>\n",
              "      <td>jeIQ_Z35HZ4</td>\n",
              "      <td>Collected_data_raw1.csv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>travel</td>\n",
              "      <td>Thank you so much for watching! I hope you fou...</td>\n",
              "      <td>TRAVEL VLOG: SANTORINI, GREECE</td>\n",
              "      <td>3</td>\n",
              "      <td>EthqIhPtd2I</td>\n",
              "      <td>Collected_data_raw1.csv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>travel</td>\n",
              "      <td>Las Vegas Travel Vlog 2020 - Pandemic Version....</td>\n",
              "      <td>Las Vegas Travel Vlog 2020 | Pandemic Edition</td>\n",
              "      <td>4</td>\n",
              "      <td>X0F0Dh8ut3U</td>\n",
              "      <td>Collected_data_raw1.csv</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-92d51eea-0a8f-4978-bbf9-15f00880a3eb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-92d51eea-0a8f-4978-bbf9-15f00880a3eb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-92d51eea-0a8f-4978-bbf9-15f00880a3eb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Unnamed: 0.1 Category                                        Description  \\\n",
              "0             0   travel  DISCLAIMER* Please do not ride elephants when ...   \n",
              "1             1   travel  Had the most amazing experience in Finland for...   \n",
              "2             2   travel  Hello loves Today's video is the Vlog of my tr...   \n",
              "3             3   travel  Thank you so much for watching! I hope you fou...   \n",
              "4             4   travel  Las Vegas Travel Vlog 2020 - Pandemic Version....   \n",
              "\n",
              "                                               Title  Unnamed: 0     Video Id  \\\n",
              "0      Welcome to Bali | Travel Vlog | Priscilla Lee           0  i9E_Blai8vk   \n",
              "1                      FINLAND VACATION: TRAVEL VLOG           1  UBvJKs9eW3I   \n",
              "2  MYKONOS GREECE TRAVEL VLOG 2020 |  Living our ...           2  jeIQ_Z35HZ4   \n",
              "3                     TRAVEL VLOG: SANTORINI, GREECE           3  EthqIhPtd2I   \n",
              "4      Las Vegas Travel Vlog 2020 | Pandemic Edition           4  X0F0Dh8ut3U   \n",
              "\n",
              "                      file  \n",
              "0  Collected_data_raw1.csv  \n",
              "1  Collected_data_raw1.csv  \n",
              "2  Collected_data_raw1.csv  \n",
              "3  Collected_data_raw1.csv  \n",
              "4  Collected_data_raw1.csv  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv('/content/AI-based-Social-Media-Caption-Generator/merged_data_file.csv')\n",
        "data.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6F-1MsuSphg_",
        "outputId": "4cb9e2d8-619e-419f-d7b5-225c57d46148"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(29245, 7)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "j0cwdW4uplev",
        "outputId": "24c1e1d4-c33b-4d8f-b114-6f7486cfc74c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ab3bda09-80e4-4ac3-aade-534a909822f8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Description</th>\n",
              "      <th>Title</th>\n",
              "      <th>Video Id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>travel</td>\n",
              "      <td>DISCLAIMER* Please do not ride elephants when ...</td>\n",
              "      <td>Welcome to Bali | Travel Vlog | Priscilla Lee</td>\n",
              "      <td>i9E_Blai8vk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>travel</td>\n",
              "      <td>Had the most amazing experience in Finland for...</td>\n",
              "      <td>FINLAND VACATION: TRAVEL VLOG</td>\n",
              "      <td>UBvJKs9eW3I</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>travel</td>\n",
              "      <td>Hello loves Today's video is the Vlog of my tr...</td>\n",
              "      <td>MYKONOS GREECE TRAVEL VLOG 2020 |  Living our ...</td>\n",
              "      <td>jeIQ_Z35HZ4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>travel</td>\n",
              "      <td>Thank you so much for watching! I hope you fou...</td>\n",
              "      <td>TRAVEL VLOG: SANTORINI, GREECE</td>\n",
              "      <td>EthqIhPtd2I</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>travel</td>\n",
              "      <td>Las Vegas Travel Vlog 2020 - Pandemic Version....</td>\n",
              "      <td>Las Vegas Travel Vlog 2020 | Pandemic Edition</td>\n",
              "      <td>X0F0Dh8ut3U</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab3bda09-80e4-4ac3-aade-534a909822f8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ab3bda09-80e4-4ac3-aade-534a909822f8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ab3bda09-80e4-4ac3-aade-534a909822f8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  Category                                        Description  \\\n",
              "0   travel  DISCLAIMER* Please do not ride elephants when ...   \n",
              "1   travel  Had the most amazing experience in Finland for...   \n",
              "2   travel  Hello loves Today's video is the Vlog of my tr...   \n",
              "3   travel  Thank you so much for watching! I hope you fou...   \n",
              "4   travel  Las Vegas Travel Vlog 2020 - Pandemic Version....   \n",
              "\n",
              "                                               Title     Video Id  \n",
              "0      Welcome to Bali | Travel Vlog | Priscilla Lee  i9E_Blai8vk  \n",
              "1                      FINLAND VACATION: TRAVEL VLOG  UBvJKs9eW3I  \n",
              "2  MYKONOS GREECE TRAVEL VLOG 2020 |  Living our ...  jeIQ_Z35HZ4  \n",
              "3                     TRAVEL VLOG: SANTORINI, GREECE  EthqIhPtd2I  \n",
              "4      Las Vegas Travel Vlog 2020 | Pandemic Edition  X0F0Dh8ut3U  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "del data['Unnamed: 0']\n",
        "del data['Unnamed: 0.1']\n",
        "del data['file']\n",
        "data.isnull().sum()\n",
        "df = data[data['Description'].notnull()]\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "--kVfthkpq-J",
        "outputId": "1b2868ab-1df9-401f-ef90-2e6ed2511f74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-54273b2c-ef2e-4a78-9f04-4bfe42e1910e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Description</th>\n",
              "      <th>Title</th>\n",
              "      <th>Video Id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>travel</td>\n",
              "      <td>DISCLAIMER* Please do not ride elephants when ...</td>\n",
              "      <td>Welcome to Bali | Travel Vlog | Priscilla Lee</td>\n",
              "      <td>i9E_Blai8vk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>travel</td>\n",
              "      <td>Had the most amazing experience in Finland for...</td>\n",
              "      <td>FINLAND VACATION: TRAVEL VLOG</td>\n",
              "      <td>UBvJKs9eW3I</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>travel</td>\n",
              "      <td>Hello loves Today's video is the Vlog of my tr...</td>\n",
              "      <td>MYKONOS GREECE TRAVEL VLOG 2020 |  Living our ...</td>\n",
              "      <td>jeIQ_Z35HZ4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>travel</td>\n",
              "      <td>Thank you so much for watching! I hope you fou...</td>\n",
              "      <td>TRAVEL VLOG: SANTORINI, GREECE</td>\n",
              "      <td>EthqIhPtd2I</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>travel</td>\n",
              "      <td>Las Vegas Travel Vlog 2020 - Pandemic Version....</td>\n",
              "      <td>Las Vegas Travel Vlog 2020 | Pandemic Edition</td>\n",
              "      <td>X0F0Dh8ut3U</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54273b2c-ef2e-4a78-9f04-4bfe42e1910e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-54273b2c-ef2e-4a78-9f04-4bfe42e1910e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-54273b2c-ef2e-4a78-9f04-4bfe42e1910e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  Category                                        Description  \\\n",
              "0   travel  DISCLAIMER* Please do not ride elephants when ...   \n",
              "1   travel  Had the most amazing experience in Finland for...   \n",
              "2   travel  Hello loves Today's video is the Vlog of my tr...   \n",
              "3   travel  Thank you so much for watching! I hope you fou...   \n",
              "4   travel  Las Vegas Travel Vlog 2020 - Pandemic Version....   \n",
              "\n",
              "                                               Title     Video Id  \n",
              "0      Welcome to Bali | Travel Vlog | Priscilla Lee  i9E_Blai8vk  \n",
              "1                      FINLAND VACATION: TRAVEL VLOG  UBvJKs9eW3I  \n",
              "2  MYKONOS GREECE TRAVEL VLOG 2020 |  Living our ...  jeIQ_Z35HZ4  \n",
              "3                     TRAVEL VLOG: SANTORINI, GREECE  EthqIhPtd2I  \n",
              "4      Las Vegas Travel Vlog 2020 | Pandemic Edition  X0F0Dh8ut3U  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df.drop_duplicates(subset = 'Video Id')\n",
        "boolean = df['Video Id'].duplicated().any()\n",
        "print(boolean)\n",
        "df.set_index('Video Id')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZC8ancJrJhM",
        "outputId": "4084f6c1-1ff3-4b65-8c16-28b7625fa091"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-a1cd2250b433>:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df['Category'] = df['Category'].str.replace(r'\\d+','')\n",
            "<ipython-input-9-a1cd2250b433>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df['Description'] = df['Description'].str.replace(r'\\d+','')\n",
            "<ipython-input-9-a1cd2250b433>:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df['Title'] = df['Title'].str.replace(r'\\d+','')\n",
            "<ipython-input-9-a1cd2250b433>:9: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  df['Title'] = df['Title'].str.replace(char, ' ')\n",
            "<ipython-input-9-a1cd2250b433>:10: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  df['Description'] = df['Description'].str.replace(char, ' ')\n",
            "<ipython-input-9-a1cd2250b433>:11: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  df['Category'] = df['Category'].str.replace(char, ' ')\n"
          ]
        }
      ],
      "source": [
        "df['Category'] = df['Category'].str.replace(r'\\d+','')\n",
        "df['Description'] = df['Description'].str.replace(r'\\d+','')\n",
        "df['Title'] = df['Title'].str.replace(r'\\d+','')\n",
        "spec_chars = [\"!\",'\"',\"#\",\"%\",\"&\",\"'\",\"(\",\")\",\n",
        "              \"*\",\"+\",\",\",\"-\",\".\",\"/\",\":\",\";\",\"<\",\n",
        "              \"=\",\">\",\"?\",\"@\",\"[\",\"\\\\\",\"]\",\"^\",\"_\",\n",
        "              \"`\",\"{\",\"|\",\"}\",\"~\",\"–\"]\n",
        "for char in spec_chars:\n",
        "    df['Title'] = df['Title'].str.replace(char, ' ')\n",
        "    df['Description'] = df['Description'].str.replace(char, ' ')\n",
        "    df['Category'] = df['Category'].str.replace(char, ' ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGUDjSNbrNhX"
      },
      "outputs": [],
      "source": [
        "def remove_emoji(string):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', string)\n",
        "for i, row in df.iterrows():\n",
        "    text_t = remove_emoji(row['Title'])\n",
        "    text_d = remove_emoji(row['Description'])\n",
        "    df.at[i,'Title']= text_t\n",
        "    df.at[i,'Description'] = text_d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSF76K6QrR64"
      },
      "outputs": [],
      "source": [
        "for i, row in df.iterrows():\n",
        "    text_t = ' '.join([w for w in row['Title'].split() if wordnet.synsets(w)])\n",
        "    df.at[i,'Title'] = text_t\n",
        "    text_d = ' '.join([w for w in row['Description'].split() if wordnet.synsets(w)])\n",
        "    df.at[i,'Description'] = text_d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FtPi7_LerV4w"
      },
      "outputs": [],
      "source": [
        "for i, row in df.iterrows():\n",
        "    word_list_t = row['Title'].lower().split() \n",
        "    filtered_words = [word for word in word_list_t if word not in stopwords.words('english')]\n",
        "    text_t = ' '.join(filtered_words)\n",
        "    df.at[i,'Title']= text_t\n",
        "    word_list_d = row['Description'].lower().split() \n",
        "    filtered_words = [word for word in word_list_d if word not in stopwords.words('english')]\n",
        "    text_d = ' '.join(filtered_words)\n",
        "    df.at[i,'Description'] = text_d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-tgIYQWrcwB",
        "outputId": "2cb963ce-893e-40f5-a9f2-fe85d8be8326"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sports                    2984\n",
              "nature                    2526\n",
              "science and technology    2499\n",
              "travel                    2431\n",
              "food                      2318\n",
              "art and music             2167\n",
              "manufacturing             1932\n",
              "adventure                 1575\n",
              "history                   1298\n",
              "Name: Category, dtype: int64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.Category.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6lSNXY8rj-x"
      },
      "outputs": [],
      "source": [
        "# Tokenization\n",
        "df['descriptions_token'] = df['Description'].apply(lambda x: x.split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIswAbG-rn8Y"
      },
      "outputs": [],
      "source": [
        "def token_check(x,model):\n",
        "  \"\"\"\n",
        "  1.Check if the token exists in the word2vec model vocab. \n",
        "  2.Check if the length of the token is greater than 3 \n",
        "  \"\"\"\n",
        "  token_list=[]\n",
        "  for i in x:\n",
        "      if len(i) > 3 and i in model.vocab:\n",
        "          token_list.append(i)\n",
        "      else:\n",
        "          continue\n",
        "  return token_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Al3MwU0qrqz0"
      },
      "outputs": [],
      "source": [
        "def word_vector(tokens,size,model):\n",
        "\n",
        "  \"\"\"Averaging the word vectors\"\"\"\n",
        "  \n",
        "  vec = np.zeros(size).reshape((1, size))\n",
        "  count = 0\n",
        "  for word in tokens:\n",
        "    vec += model[word].reshape((1, size))\n",
        "    count += 1.\n",
        "  if count != 0:\n",
        "      vec /= count\n",
        "  return vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neWGbIbyrv3S"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec,KeyedVectors "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHz9nqNit-El",
        "outputId": "303d147b-bb24-4252-f0cc-08dfbcfd0d74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading googlenewsvectorsnegative300.zip to /content\n",
            "100% 3.17G/3.17G [02:12<00:00, 25.4MB/s]\n",
            "100% 3.17G/3.17G [02:12<00:00, 25.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download -d leadbest/googlenewsvectorsnegative300"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvozHvbEWV0x",
        "outputId": "5983ff45-2f69-47f4-aee0-042f5b1ffc6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/googlenewsvectorsnegative300.zip\n",
            "  inflating: GoogleNews-vectors-negative300.bin  \n",
            "  inflating: GoogleNews-vectors-negative300.bin.gz  \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/googlenewsvectorsnegative300.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GFO8QLSr2QZ"
      },
      "outputs": [],
      "source": [
        "#Load the word2vec pre trained Model to get the word embeddings for each token\n",
        "model = KeyedVectors.load_word2vec_format('/content/GoogleNews-vectors-negative300.bin.gz',binary=True,limit=1000000)\n",
        "\n",
        "df['descriptions_token'] = df['descriptions_token'].apply(lambda x:token_check(x,model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aR7BWq1rr6US"
      },
      "outputs": [],
      "source": [
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "wordvec_arrays = np.zeros((len(df.descriptions_token),300))\n",
        "\n",
        "for i in range(len(df.descriptions_token)):\n",
        "  wordvec_arrays[i,:] = word_vector(df.descriptions_token[i],300,model)\n",
        "\n",
        "vectorized_df = pd.DataFrame(wordvec_arrays)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiRrYNpOr-PO"
      },
      "outputs": [],
      "source": [
        "target_one_hot_encoded = pd.get_dummies(df['Category'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "W6Cfb3uQsA9v",
        "outputId": "860153d2-3927-45e9-8d1d-92651fa3bd3b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-73129c3d-61a1-4e4e-95c9-65ddaae1add4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>adventure</th>\n",
              "      <th>art and music</th>\n",
              "      <th>food</th>\n",
              "      <th>history</th>\n",
              "      <th>manufacturing</th>\n",
              "      <th>nature</th>\n",
              "      <th>science and technology</th>\n",
              "      <th>sports</th>\n",
              "      <th>travel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73129c3d-61a1-4e4e-95c9-65ddaae1add4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-73129c3d-61a1-4e4e-95c9-65ddaae1add4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-73129c3d-61a1-4e4e-95c9-65ddaae1add4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   adventure  art and music  food  history  manufacturing  nature  \\\n",
              "0          0              0     0        0              0       0   \n",
              "1          0              0     0        0              0       0   \n",
              "2          0              0     0        0              0       0   \n",
              "3          0              0     0        0              0       0   \n",
              "4          0              0     0        0              0       0   \n",
              "\n",
              "   science and technology  sports  travel  \n",
              "0                       0       0       1  \n",
              "1                       0       0       1  \n",
              "2                       0       0       1  \n",
              "3                       0       0       1  \n",
              "4                       0       0       1  "
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target_one_hot_encoded.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9fRhf_ssD4t"
      },
      "outputs": [],
      "source": [
        "dataset = pd.merge(vectorized_df,target_one_hot_encoded,left_index=True, right_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2RqG7DCsMMB"
      },
      "outputs": [],
      "source": [
        "dataset_shuffled = dataset.reindex(np.random.permutation(dataset.index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCUhXmDZsU-H"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "target=['adventure','art and music','food','history','manufacturing','nature','science and technology','sports','travel']\n",
        "X = dataset_shuffled.loc[:,~dataset_shuffled.columns.isin(target)]\n",
        "y = dataset_shuffled.loc[:,dataset_shuffled.columns.isin(target)]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,train_size=0.75,test_size=0.25,random_state=101)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTjjJM6qsqbg"
      },
      "outputs": [],
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras.layers import Dropout\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras import backend as K\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def NN_arch1(lrate=0.0001):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Dense(300,input_dim = 300, activation='relu'))\n",
        "    model.add(layers.Dense(5,activation='relu'))\n",
        "    model.add(layers.Dense(4,activation='relu'))\n",
        "    model.add(layers.Dense(9,activation='softmax'))\n",
        "    opt = keras.optimizers.Adam(lr=lrate)\n",
        "    model.compile(optimizer=opt,loss='binary_crossentropy',metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def NN_arch2(lrate=0.0001):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Dense(300,input_dim = 300, activation='relu'))\n",
        "    model.add(layers.Dense(5,activation='sigmoid'))\n",
        "    model.add(Dropout(0.20))\n",
        "    model.add(layers.Dense(6,activation='relu'))\n",
        "    model.add(Dropout(0.10))\n",
        "    #model.add(layers.Dense(4,activation='relu'))\n",
        "    model.add(layers.Dense(9,activation='softmax'))\n",
        "    opt = keras.optimizers.Adam(lr=lrate)\n",
        "    model.compile(optimizer=opt,loss='binary_crossentropy',metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def model_fit(model,X_train,y_train,X_test,y_test,epoch_val=50):\n",
        "    callbacks = EarlyStopping(monitor='val_loss',mode='min',patience=3)\n",
        "    model.fit(X_train, y_train, epochs=epoch_val,batch_size=50)\n",
        "    val_loss, val_acc = model.evaluate(X_test,y_test)\n",
        "    print(\"val_loss, val_acc\",val_loss, val_acc)\n",
        "    return val_loss,val_acc\n",
        "\n",
        "def history_plot(history):\n",
        "    \"\"\" history plot \"\"\"\n",
        "    training_loss = history.history['loss']\n",
        "    test_loss = history.history['val_loss']\n",
        "    training_acc = history.history['accuracy']\n",
        "    test_acc = history.history['val_accuracy']\n",
        "\n",
        "    # Create count of the number of epochs\n",
        "    epoch_count = range(1, len(training_loss) + 1)\n",
        "\n",
        "    # Visualize loss history\n",
        "    plt.figure(figsize=(5,3))\n",
        "\n",
        "    plt.plot(epoch_count, training_loss, 'r--')\n",
        "    plt.plot(epoch_count, test_loss, 'b-')\n",
        "    plt.legend(['Training Loss', 'Test Loss'])\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.show()\n",
        "\n",
        "    #Visualize accuracy history\n",
        "    plt.plot(epoch_count, training_acc, 'r--')\n",
        "    plt.plot(epoch_count, test_acc, 'b-')\n",
        "    plt.legend(['Training acc', 'Test acc'])\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Acc')\n",
        "    plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OQxtFzLUswxj",
        "outputId": "cc7de29b-c1f3-4228-f837-1c11bf1f5fc6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "148/148 [==============================] - 4s 8ms/step - loss: 0.6048 - accuracy: 0.1106 - val_loss: 0.4973 - val_accuracy: 0.1091\n",
            "Epoch 2/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.4359 - accuracy: 0.1091 - val_loss: 0.3653 - val_accuracy: 0.1091\n",
            "Epoch 3/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.3675 - accuracy: 0.1504 - val_loss: 0.3409 - val_accuracy: 0.2696\n",
            "Epoch 4/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.3547 - accuracy: 0.1934 - val_loss: 0.3348 - val_accuracy: 0.2337\n",
            "Epoch 5/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.3483 - accuracy: 0.2017 - val_loss: 0.3305 - val_accuracy: 0.2197\n",
            "Epoch 6/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.3416 - accuracy: 0.2115 - val_loss: 0.3231 - val_accuracy: 0.2777\n",
            "Epoch 7/200\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.3334 - accuracy: 0.2526 - val_loss: 0.3167 - val_accuracy: 0.3100\n",
            "Epoch 8/200\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.3274 - accuracy: 0.2591 - val_loss: 0.3112 - val_accuracy: 0.3201\n",
            "Epoch 9/200\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 0.3198 - accuracy: 0.2766 - val_loss: 0.3032 - val_accuracy: 0.3237\n",
            "Epoch 10/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.3125 - accuracy: 0.2895 - val_loss: 0.2965 - val_accuracy: 0.3521\n",
            "Epoch 11/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.3062 - accuracy: 0.3163 - val_loss: 0.2915 - val_accuracy: 0.3756\n",
            "Epoch 12/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.3009 - accuracy: 0.3245 - val_loss: 0.2851 - val_accuracy: 0.3933\n",
            "Epoch 13/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.2961 - accuracy: 0.3432 - val_loss: 0.2784 - val_accuracy: 0.4308\n",
            "Epoch 14/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.2901 - accuracy: 0.3686 - val_loss: 0.2731 - val_accuracy: 0.4525\n",
            "Epoch 15/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.2853 - accuracy: 0.3901 - val_loss: 0.2669 - val_accuracy: 0.4995\n",
            "Epoch 16/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.2799 - accuracy: 0.4127 - val_loss: 0.2618 - val_accuracy: 0.5102\n",
            "Epoch 17/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.2754 - accuracy: 0.4220 - val_loss: 0.2580 - val_accuracy: 0.5159\n",
            "Epoch 18/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.2713 - accuracy: 0.4341 - val_loss: 0.2551 - val_accuracy: 0.5208\n",
            "Epoch 19/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.2696 - accuracy: 0.4413 - val_loss: 0.2517 - val_accuracy: 0.5323\n",
            "Epoch 20/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.2679 - accuracy: 0.4411 - val_loss: 0.2488 - val_accuracy: 0.5323\n",
            "Epoch 21/200\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.2637 - accuracy: 0.4490 - val_loss: 0.2463 - val_accuracy: 0.5362\n",
            "Epoch 22/200\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.2593 - accuracy: 0.4566 - val_loss: 0.2438 - val_accuracy: 0.5423\n",
            "Epoch 23/200\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.2565 - accuracy: 0.4611 - val_loss: 0.2419 - val_accuracy: 0.5530\n",
            "Epoch 24/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.2547 - accuracy: 0.4719 - val_loss: 0.2402 - val_accuracy: 0.5544\n",
            "Epoch 25/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.2525 - accuracy: 0.4712 - val_loss: 0.2379 - val_accuracy: 0.5605\n",
            "Epoch 26/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.2497 - accuracy: 0.4753 - val_loss: 0.2367 - val_accuracy: 0.5729\n",
            "Epoch 27/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.2474 - accuracy: 0.4824 - val_loss: 0.2354 - val_accuracy: 0.5711\n",
            "Epoch 28/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.2464 - accuracy: 0.4859 - val_loss: 0.2340 - val_accuracy: 0.5696\n",
            "Epoch 29/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.2455 - accuracy: 0.4870 - val_loss: 0.2337 - val_accuracy: 0.5664\n",
            "Epoch 30/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.2427 - accuracy: 0.4910 - val_loss: 0.2318 - val_accuracy: 0.5792\n",
            "Epoch 31/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.2405 - accuracy: 0.5013 - val_loss: 0.2317 - val_accuracy: 0.5869\n",
            "Epoch 32/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.2380 - accuracy: 0.5062 - val_loss: 0.2320 - val_accuracy: 0.5771\n",
            "Epoch 33/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.2350 - accuracy: 0.5155 - val_loss: 0.2307 - val_accuracy: 0.5804\n",
            "Epoch 34/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.2349 - accuracy: 0.5126 - val_loss: 0.2297 - val_accuracy: 0.5798\n",
            "Epoch 35/200\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 0.2314 - accuracy: 0.5233 - val_loss: 0.2292 - val_accuracy: 0.5867\n",
            "Epoch 36/200\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 0.2310 - accuracy: 0.5253 - val_loss: 0.2286 - val_accuracy: 0.5956\n",
            "Epoch 37/200\n",
            "148/148 [==============================] - 2s 10ms/step - loss: 0.2284 - accuracy: 0.5332 - val_loss: 0.2288 - val_accuracy: 0.6029\n",
            "Epoch 38/200\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 0.2268 - accuracy: 0.5365 - val_loss: 0.2293 - val_accuracy: 0.5956\n",
            "Epoch 39/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.2241 - accuracy: 0.5415 - val_loss: 0.2284 - val_accuracy: 0.6061\n",
            "Epoch 40/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.2231 - accuracy: 0.5444 - val_loss: 0.2283 - val_accuracy: 0.5954\n",
            "Epoch 41/200\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.2235 - accuracy: 0.5459 - val_loss: 0.2294 - val_accuracy: 0.6084\n",
            "Epoch 42/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.2197 - accuracy: 0.5523 - val_loss: 0.2283 - val_accuracy: 0.6027\n",
            "Epoch 43/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.2182 - accuracy: 0.5578 - val_loss: 0.2268 - val_accuracy: 0.6081\n",
            "Epoch 44/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.2166 - accuracy: 0.5603 - val_loss: 0.2277 - val_accuracy: 0.6102\n",
            "Epoch 45/200\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.2138 - accuracy: 0.5712 - val_loss: 0.2287 - val_accuracy: 0.6069\n",
            "Epoch 46/200\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.2149 - accuracy: 0.5642 - val_loss: 0.2261 - val_accuracy: 0.6122\n",
            "Epoch 47/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.2128 - accuracy: 0.5700 - val_loss: 0.2277 - val_accuracy: 0.6110\n",
            "Epoch 48/200\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.2111 - accuracy: 0.5782 - val_loss: 0.2276 - val_accuracy: 0.6142\n",
            "Epoch 49/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.2112 - accuracy: 0.5851 - val_loss: 0.2285 - val_accuracy: 0.6126\n",
            "Epoch 50/200\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 0.2084 - accuracy: 0.5861 - val_loss: 0.2267 - val_accuracy: 0.6148\n",
            "Epoch 51/200\n",
            "148/148 [==============================] - 3s 21ms/step - loss: 0.2078 - accuracy: 0.5856 - val_loss: 0.2282 - val_accuracy: 0.6161\n",
            "Epoch 52/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.2035 - accuracy: 0.5984 - val_loss: 0.2296 - val_accuracy: 0.6225\n",
            "Epoch 53/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.2031 - accuracy: 0.6046 - val_loss: 0.2278 - val_accuracy: 0.6169\n",
            "Epoch 54/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.2031 - accuracy: 0.6063 - val_loss: 0.2293 - val_accuracy: 0.6246\n",
            "Epoch 55/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.2017 - accuracy: 0.6034 - val_loss: 0.2291 - val_accuracy: 0.6209\n",
            "Epoch 56/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.2012 - accuracy: 0.6077 - val_loss: 0.2301 - val_accuracy: 0.6252\n",
            "Epoch 57/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.2011 - accuracy: 0.6161 - val_loss: 0.2295 - val_accuracy: 0.6296\n",
            "Epoch 58/200\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 0.1976 - accuracy: 0.6158 - val_loss: 0.2308 - val_accuracy: 0.6244\n",
            "Epoch 59/200\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 0.1964 - accuracy: 0.6295 - val_loss: 0.2295 - val_accuracy: 0.6246\n",
            "Epoch 60/200\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 0.1973 - accuracy: 0.6276 - val_loss: 0.2307 - val_accuracy: 0.6302\n",
            "Epoch 61/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1952 - accuracy: 0.6272 - val_loss: 0.2316 - val_accuracy: 0.6272\n",
            "Epoch 62/200\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.1954 - accuracy: 0.6284 - val_loss: 0.2316 - val_accuracy: 0.6304\n",
            "Epoch 63/200\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 0.1947 - accuracy: 0.6279 - val_loss: 0.2339 - val_accuracy: 0.6339\n",
            "Epoch 64/200\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.1946 - accuracy: 0.6354 - val_loss: 0.2341 - val_accuracy: 0.6329\n",
            "Epoch 65/200\n",
            "148/148 [==============================] - 2s 10ms/step - loss: 0.1918 - accuracy: 0.6407 - val_loss: 0.2334 - val_accuracy: 0.6375\n",
            "Epoch 66/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1901 - accuracy: 0.6509 - val_loss: 0.2361 - val_accuracy: 0.6359\n",
            "Epoch 67/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1906 - accuracy: 0.6449 - val_loss: 0.2373 - val_accuracy: 0.6351\n",
            "Epoch 68/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1904 - accuracy: 0.6450 - val_loss: 0.2361 - val_accuracy: 0.6323\n",
            "Epoch 69/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1886 - accuracy: 0.6577 - val_loss: 0.2377 - val_accuracy: 0.6357\n",
            "Epoch 70/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1876 - accuracy: 0.6553 - val_loss: 0.2388 - val_accuracy: 0.6327\n",
            "Epoch 71/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1837 - accuracy: 0.6709 - val_loss: 0.2374 - val_accuracy: 0.6347\n",
            "Epoch 72/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1853 - accuracy: 0.6619 - val_loss: 0.2417 - val_accuracy: 0.6377\n",
            "Epoch 73/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1840 - accuracy: 0.6645 - val_loss: 0.2390 - val_accuracy: 0.6373\n",
            "Epoch 74/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1857 - accuracy: 0.6659 - val_loss: 0.2403 - val_accuracy: 0.6284\n",
            "Epoch 75/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1839 - accuracy: 0.6683 - val_loss: 0.2422 - val_accuracy: 0.6345\n",
            "Epoch 76/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1832 - accuracy: 0.6688 - val_loss: 0.2422 - val_accuracy: 0.6329\n",
            "Epoch 77/200\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 0.1806 - accuracy: 0.6754 - val_loss: 0.2422 - val_accuracy: 0.6351\n",
            "Epoch 78/200\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 0.1797 - accuracy: 0.6808 - val_loss: 0.2436 - val_accuracy: 0.6343\n",
            "Epoch 79/200\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 0.1810 - accuracy: 0.6738 - val_loss: 0.2469 - val_accuracy: 0.6345\n",
            "Epoch 80/200\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 0.1806 - accuracy: 0.6758 - val_loss: 0.2497 - val_accuracy: 0.6371\n",
            "Epoch 81/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1782 - accuracy: 0.6819 - val_loss: 0.2522 - val_accuracy: 0.6337\n",
            "Epoch 82/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1788 - accuracy: 0.6826 - val_loss: 0.2521 - val_accuracy: 0.6335\n",
            "Epoch 83/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1759 - accuracy: 0.6863 - val_loss: 0.2516 - val_accuracy: 0.6343\n",
            "Epoch 84/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1767 - accuracy: 0.6913 - val_loss: 0.2556 - val_accuracy: 0.6294\n",
            "Epoch 85/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1743 - accuracy: 0.6945 - val_loss: 0.2535 - val_accuracy: 0.6335\n",
            "Epoch 86/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1735 - accuracy: 0.7005 - val_loss: 0.2557 - val_accuracy: 0.6276\n",
            "Epoch 87/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1734 - accuracy: 0.6994 - val_loss: 0.2547 - val_accuracy: 0.6335\n",
            "Epoch 88/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1738 - accuracy: 0.6955 - val_loss: 0.2594 - val_accuracy: 0.6337\n",
            "Epoch 89/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1722 - accuracy: 0.7013 - val_loss: 0.2585 - val_accuracy: 0.6292\n",
            "Epoch 90/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1730 - accuracy: 0.6975 - val_loss: 0.2617 - val_accuracy: 0.6331\n",
            "Epoch 91/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1706 - accuracy: 0.7002 - val_loss: 0.2649 - val_accuracy: 0.6294\n",
            "Epoch 92/200\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.1709 - accuracy: 0.6976 - val_loss: 0.2619 - val_accuracy: 0.6290\n",
            "Epoch 93/200\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.1716 - accuracy: 0.6999 - val_loss: 0.2641 - val_accuracy: 0.6296\n",
            "Epoch 94/200\n",
            "148/148 [==============================] - 2s 10ms/step - loss: 0.1700 - accuracy: 0.7054 - val_loss: 0.2638 - val_accuracy: 0.6244\n",
            "Epoch 95/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1719 - accuracy: 0.7024 - val_loss: 0.2623 - val_accuracy: 0.6304\n",
            "Epoch 96/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1687 - accuracy: 0.7087 - val_loss: 0.2653 - val_accuracy: 0.6311\n",
            "Epoch 97/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1671 - accuracy: 0.7062 - val_loss: 0.2649 - val_accuracy: 0.6258\n",
            "Epoch 98/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1698 - accuracy: 0.7072 - val_loss: 0.2681 - val_accuracy: 0.6292\n",
            "Epoch 99/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1672 - accuracy: 0.7112 - val_loss: 0.2651 - val_accuracy: 0.6290\n",
            "Epoch 100/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1682 - accuracy: 0.7103 - val_loss: 0.2655 - val_accuracy: 0.6272\n",
            "Epoch 101/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1673 - accuracy: 0.7073 - val_loss: 0.2684 - val_accuracy: 0.6311\n",
            "Epoch 102/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1677 - accuracy: 0.7108 - val_loss: 0.2723 - val_accuracy: 0.6286\n",
            "Epoch 103/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1641 - accuracy: 0.7144 - val_loss: 0.2781 - val_accuracy: 0.6300\n",
            "Epoch 104/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1658 - accuracy: 0.7138 - val_loss: 0.2744 - val_accuracy: 0.6264\n",
            "Epoch 105/200\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.1666 - accuracy: 0.7116 - val_loss: 0.2764 - val_accuracy: 0.6278\n",
            "Epoch 106/200\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 0.1652 - accuracy: 0.7157 - val_loss: 0.2786 - val_accuracy: 0.6264\n",
            "Epoch 107/200\n",
            "148/148 [==============================] - 2s 10ms/step - loss: 0.1611 - accuracy: 0.7268 - val_loss: 0.2803 - val_accuracy: 0.6300\n",
            "Epoch 108/200\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 0.1650 - accuracy: 0.7139 - val_loss: 0.2900 - val_accuracy: 0.6254\n",
            "Epoch 109/200\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 0.1637 - accuracy: 0.7194 - val_loss: 0.2836 - val_accuracy: 0.6264\n",
            "Epoch 110/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1644 - accuracy: 0.7189 - val_loss: 0.2874 - val_accuracy: 0.6248\n",
            "Epoch 111/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1623 - accuracy: 0.7262 - val_loss: 0.2836 - val_accuracy: 0.6268\n",
            "Epoch 112/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1633 - accuracy: 0.7210 - val_loss: 0.2800 - val_accuracy: 0.6272\n",
            "Epoch 113/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1605 - accuracy: 0.7286 - val_loss: 0.2837 - val_accuracy: 0.6248\n",
            "Epoch 114/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1597 - accuracy: 0.7293 - val_loss: 0.2981 - val_accuracy: 0.6274\n",
            "Epoch 115/200\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.1617 - accuracy: 0.7252 - val_loss: 0.2855 - val_accuracy: 0.6270\n",
            "Epoch 116/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1624 - accuracy: 0.7263 - val_loss: 0.2906 - val_accuracy: 0.6209\n",
            "Epoch 117/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1607 - accuracy: 0.7273 - val_loss: 0.2927 - val_accuracy: 0.6288\n",
            "Epoch 118/200\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 0.1594 - accuracy: 0.7312 - val_loss: 0.2927 - val_accuracy: 0.6270\n",
            "Epoch 119/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1609 - accuracy: 0.7272 - val_loss: 0.3014 - val_accuracy: 0.6298\n",
            "Epoch 120/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1584 - accuracy: 0.7322 - val_loss: 0.2927 - val_accuracy: 0.6209\n",
            "Epoch 121/200\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 0.1571 - accuracy: 0.7348 - val_loss: 0.3038 - val_accuracy: 0.6250\n",
            "Epoch 122/200\n",
            "148/148 [==============================] - 2s 10ms/step - loss: 0.1590 - accuracy: 0.7293 - val_loss: 0.2975 - val_accuracy: 0.6276\n",
            "Epoch 123/200\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 0.1591 - accuracy: 0.7287 - val_loss: 0.2998 - val_accuracy: 0.6242\n",
            "Epoch 124/200\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 0.1588 - accuracy: 0.7319 - val_loss: 0.2972 - val_accuracy: 0.6229\n",
            "Epoch 125/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1572 - accuracy: 0.7374 - val_loss: 0.3069 - val_accuracy: 0.6248\n",
            "Epoch 126/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1553 - accuracy: 0.7371 - val_loss: 0.3191 - val_accuracy: 0.6225\n",
            "Epoch 127/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1562 - accuracy: 0.7394 - val_loss: 0.3031 - val_accuracy: 0.6254\n",
            "Epoch 128/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1567 - accuracy: 0.7377 - val_loss: 0.3147 - val_accuracy: 0.6236\n",
            "Epoch 129/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1584 - accuracy: 0.7310 - val_loss: 0.3158 - val_accuracy: 0.6248\n",
            "Epoch 130/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1566 - accuracy: 0.7368 - val_loss: 0.3128 - val_accuracy: 0.6264\n",
            "Epoch 131/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1566 - accuracy: 0.7381 - val_loss: 0.3138 - val_accuracy: 0.6250\n",
            "Epoch 132/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1567 - accuracy: 0.7362 - val_loss: 0.3118 - val_accuracy: 0.6270\n",
            "Epoch 133/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1547 - accuracy: 0.7430 - val_loss: 0.3142 - val_accuracy: 0.6225\n",
            "Epoch 134/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1568 - accuracy: 0.7354 - val_loss: 0.3185 - val_accuracy: 0.6215\n",
            "Epoch 135/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1560 - accuracy: 0.7362 - val_loss: 0.3191 - val_accuracy: 0.6227\n",
            "Epoch 136/200\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 0.1559 - accuracy: 0.7399 - val_loss: 0.3238 - val_accuracy: 0.6240\n",
            "Epoch 137/200\n",
            "148/148 [==============================] - 2s 10ms/step - loss: 0.1550 - accuracy: 0.7375 - val_loss: 0.3253 - val_accuracy: 0.6221\n",
            "Epoch 138/200\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.1527 - accuracy: 0.7420 - val_loss: 0.3168 - val_accuracy: 0.6274\n",
            "Epoch 139/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1526 - accuracy: 0.7412 - val_loss: 0.3217 - val_accuracy: 0.6234\n",
            "Epoch 140/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1561 - accuracy: 0.7391 - val_loss: 0.3282 - val_accuracy: 0.6205\n",
            "Epoch 141/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1564 - accuracy: 0.7366 - val_loss: 0.3144 - val_accuracy: 0.6211\n",
            "Epoch 142/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1552 - accuracy: 0.7393 - val_loss: 0.3277 - val_accuracy: 0.6225\n",
            "Epoch 143/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1524 - accuracy: 0.7457 - val_loss: 0.3344 - val_accuracy: 0.6240\n",
            "Epoch 144/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1552 - accuracy: 0.7390 - val_loss: 0.3235 - val_accuracy: 0.6232\n",
            "Epoch 145/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1511 - accuracy: 0.7504 - val_loss: 0.3188 - val_accuracy: 0.6234\n",
            "Epoch 146/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1537 - accuracy: 0.7412 - val_loss: 0.3266 - val_accuracy: 0.6219\n",
            "Epoch 147/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1532 - accuracy: 0.7428 - val_loss: 0.3395 - val_accuracy: 0.6223\n",
            "Epoch 148/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1544 - accuracy: 0.7410 - val_loss: 0.3195 - val_accuracy: 0.6215\n",
            "Epoch 149/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1533 - accuracy: 0.7404 - val_loss: 0.3457 - val_accuracy: 0.6232\n",
            "Epoch 150/200\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 0.1550 - accuracy: 0.7369 - val_loss: 0.3550 - val_accuracy: 0.6203\n",
            "Epoch 151/200\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 0.1524 - accuracy: 0.7424 - val_loss: 0.3483 - val_accuracy: 0.6161\n",
            "Epoch 152/200\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 0.1553 - accuracy: 0.7372 - val_loss: 0.3399 - val_accuracy: 0.6221\n",
            "Epoch 153/200\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 0.1512 - accuracy: 0.7433 - val_loss: 0.3538 - val_accuracy: 0.6242\n",
            "Epoch 154/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1541 - accuracy: 0.7340 - val_loss: 0.3508 - val_accuracy: 0.6225\n",
            "Epoch 155/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1498 - accuracy: 0.7477 - val_loss: 0.3492 - val_accuracy: 0.6244\n",
            "Epoch 156/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1494 - accuracy: 0.7467 - val_loss: 0.3458 - val_accuracy: 0.6207\n",
            "Epoch 157/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1528 - accuracy: 0.7412 - val_loss: 0.3442 - val_accuracy: 0.6219\n",
            "Epoch 158/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1527 - accuracy: 0.7364 - val_loss: 0.3527 - val_accuracy: 0.6236\n",
            "Epoch 159/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1509 - accuracy: 0.7391 - val_loss: 0.3598 - val_accuracy: 0.6280\n",
            "Epoch 160/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1501 - accuracy: 0.7406 - val_loss: 0.3514 - val_accuracy: 0.6234\n",
            "Epoch 161/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1494 - accuracy: 0.7462 - val_loss: 0.3611 - val_accuracy: 0.6193\n",
            "Epoch 162/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1518 - accuracy: 0.7412 - val_loss: 0.3451 - val_accuracy: 0.6254\n",
            "Epoch 163/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1488 - accuracy: 0.7439 - val_loss: 0.3689 - val_accuracy: 0.6189\n",
            "Epoch 164/200\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 0.1506 - accuracy: 0.7437 - val_loss: 0.3494 - val_accuracy: 0.6219\n",
            "Epoch 165/200\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 0.1488 - accuracy: 0.7487 - val_loss: 0.3649 - val_accuracy: 0.6134\n",
            "Epoch 166/200\n",
            "148/148 [==============================] - 2s 10ms/step - loss: 0.1496 - accuracy: 0.7388 - val_loss: 0.3653 - val_accuracy: 0.6185\n",
            "Epoch 167/200\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 0.1524 - accuracy: 0.7348 - val_loss: 0.3781 - val_accuracy: 0.6207\n",
            "Epoch 168/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1510 - accuracy: 0.7429 - val_loss: 0.3521 - val_accuracy: 0.6169\n",
            "Epoch 169/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1526 - accuracy: 0.7395 - val_loss: 0.3649 - val_accuracy: 0.6171\n",
            "Epoch 170/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1497 - accuracy: 0.7431 - val_loss: 0.3670 - val_accuracy: 0.6209\n",
            "Epoch 171/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1505 - accuracy: 0.7440 - val_loss: 0.3808 - val_accuracy: 0.6165\n",
            "Epoch 172/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1506 - accuracy: 0.7408 - val_loss: 0.3757 - val_accuracy: 0.6195\n",
            "Epoch 173/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1485 - accuracy: 0.7458 - val_loss: 0.3733 - val_accuracy: 0.6197\n",
            "Epoch 174/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1463 - accuracy: 0.7497 - val_loss: 0.3791 - val_accuracy: 0.6205\n",
            "Epoch 175/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1467 - accuracy: 0.7481 - val_loss: 0.4029 - val_accuracy: 0.6171\n",
            "Epoch 176/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1497 - accuracy: 0.7422 - val_loss: 0.3819 - val_accuracy: 0.6207\n",
            "Epoch 177/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1498 - accuracy: 0.7429 - val_loss: 0.3826 - val_accuracy: 0.6236\n",
            "Epoch 178/200\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 0.1485 - accuracy: 0.7466 - val_loss: 0.3971 - val_accuracy: 0.6187\n",
            "Epoch 179/200\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.1487 - accuracy: 0.7487 - val_loss: 0.3799 - val_accuracy: 0.6177\n",
            "Epoch 180/200\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 0.1480 - accuracy: 0.7458 - val_loss: 0.3852 - val_accuracy: 0.6258\n",
            "Epoch 181/200\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 0.1467 - accuracy: 0.7499 - val_loss: 0.3756 - val_accuracy: 0.6219\n",
            "Epoch 182/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1484 - accuracy: 0.7481 - val_loss: 0.3900 - val_accuracy: 0.6205\n",
            "Epoch 183/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1499 - accuracy: 0.7426 - val_loss: 0.3832 - val_accuracy: 0.6213\n",
            "Epoch 184/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1472 - accuracy: 0.7485 - val_loss: 0.3933 - val_accuracy: 0.6215\n",
            "Epoch 185/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1486 - accuracy: 0.7456 - val_loss: 0.3891 - val_accuracy: 0.6197\n",
            "Epoch 186/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1494 - accuracy: 0.7434 - val_loss: 0.3882 - val_accuracy: 0.6229\n",
            "Epoch 187/200\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 0.1451 - accuracy: 0.7487 - val_loss: 0.4055 - val_accuracy: 0.6179\n",
            "Epoch 188/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1471 - accuracy: 0.7460 - val_loss: 0.3829 - val_accuracy: 0.6171\n",
            "Epoch 189/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1500 - accuracy: 0.7394 - val_loss: 0.4094 - val_accuracy: 0.6179\n",
            "Epoch 190/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1444 - accuracy: 0.7525 - val_loss: 0.3929 - val_accuracy: 0.6193\n",
            "Epoch 191/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1462 - accuracy: 0.7460 - val_loss: 0.3963 - val_accuracy: 0.6154\n",
            "Epoch 192/200\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 0.1477 - accuracy: 0.7454 - val_loss: 0.4189 - val_accuracy: 0.6193\n",
            "Epoch 193/200\n",
            "148/148 [==============================] - 2s 10ms/step - loss: 0.1466 - accuracy: 0.7478 - val_loss: 0.3888 - val_accuracy: 0.6169\n",
            "Epoch 194/200\n",
            "148/148 [==============================] - 2s 10ms/step - loss: 0.1446 - accuracy: 0.7516 - val_loss: 0.4078 - val_accuracy: 0.6242\n",
            "Epoch 195/200\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 0.1467 - accuracy: 0.7458 - val_loss: 0.4105 - val_accuracy: 0.6217\n",
            "Epoch 196/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1450 - accuracy: 0.7520 - val_loss: 0.4015 - val_accuracy: 0.6179\n",
            "Epoch 197/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1437 - accuracy: 0.7520 - val_loss: 0.4032 - val_accuracy: 0.6209\n",
            "Epoch 198/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1472 - accuracy: 0.7446 - val_loss: 0.4195 - val_accuracy: 0.6215\n",
            "Epoch 199/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1465 - accuracy: 0.7485 - val_loss: 0.4193 - val_accuracy: 0.6197\n",
            "Epoch 200/200\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 0.1458 - accuracy: 0.7483 - val_loss: 0.4005 - val_accuracy: 0.6205\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAADQCAYAAABhoyiUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAvRUlEQVR4nO2daXgVVdKA30qAhE1AwA1UUFlEQJaII4qACyIouCuDjqjjOsrgjIqoOOjgJ+qMouCGDuIO6ghuKCIKMihLQJBVxIAYcAmoYQ1kqe9H3UtCyM7t3OSm3ufpp7tPn+5TfW9upc6pOnVEVXEcx3EKJy7aAjiO41R0XFE6juMUgytKx3GcYnBF6TiOUwyuKB3HcYrBFaXjOE4xVIu2AKWlUaNG2qxZs2iL4ThOjLFw4cJNqtq4oGuVTlE2a9aM5OTkaIvhOE6MISLfF3bNu96O4zjF4IrScRynGFxROo7jFEOgY5Qi0ht4HIgHnlfVUQXUuQQYASiwRFX/GKRMjlPeZGZmkpqaSkZGRrRFcYDExESaNm1K9erVS3xPYIpSROKBJ4EzgVRggYi8q6or8tRpAQwDTlbV30TkoKDkcZxokZqaSt26dWnWrBkiEm1xqjSqyubNm0lNTaV58+Ylvi/IrncXYI2qpqjqbmAi0D9fnWuBJ1X1NwBV/SXiUrRsCY88EvHHOk5JycjIoGHDhq4kKwAiQsOGDUtt3QepKJsAP+Q5Tw2V5aUl0FJE5ojI3FBXPbKkpkJaWsQf6zilwZVkxaEs30W0nTnVgBZAD2AA8JyI1M9fSUSuE5FkEUlOK63Sq14ddu/ef0kdp5KyefNmOnToQIcOHTjkkENo0qTJnvPdxfw2kpOTGTx4cLFtdO3aNSKyzpw5k3POOSciz4okQTpzNgCH5zlvGirLSyowT1UzgbUishpTnAvyVlLVccA4gKSkpNJlGq5RwxWlU6Vp2LAhixcvBmDEiBHUqVOH2267bc/1rKwsqlUrWBUkJSWRlJRUbBtffPFFRGStqARpUS4AWohIcxGpAVwGvJuvzhTMmkREGmFd8ZSISuGK0nH2YdCgQdxwww2ceOKJ3HHHHcyfP5+TTjqJjh070rVrV7755htgbwtvxIgRXH311fTo0YOjjjqKJ554Ys/z6tSps6d+jx49uOiii2jdujUDBw4kvIrC1KlTad26NZ07d2bw4MGlshxff/112rVrR9u2bRk6dCgA2dnZDBo0iLZt29KuXTsee+wxAJ544gnatGlD+/btueyyy/b/wyJAi1JVs0TkZmAaFh40XlWXi8j9QLKqvhu61ktEVgDZwO2qujmigvTtC+3bR/SRjrNf9Oixb9kll8BNN8GOHdCnz77XBw2ybdMmuOiiva/NnFkmMVJTU/niiy+Ij49ny5YtzJ49m2rVqvHJJ59w11138d///nefe1atWsVnn33G1q1badWqFTfeeOM+YTZfffUVy5cv57DDDuPkk09mzpw5JCUlcf311/P555/TvHlzBgwYUGI5N27cyNChQ1m4cCENGjSgV69eTJkyhcMPP5wNGzawbNkyAH7//XcARo0axdq1a0lISNhTtr8EGkepqlOBqfnK7s1zrMDfQlswjBsX2KMdpzJz8cUXEx8fD0B6ejpXXnkl3377LSJCZmZmgff07duXhIQEEhISOOigg/j5559p2rTpXnW6dOmyp6xDhw6sW7eOOnXqcNRRR+0JyRkwYADjSvjbXLBgAT169KBxY8tXMXDgQD7//HOGDx9OSkoKt9xyC3379qVXr14AtG/fnoEDB3Leeedx3nnnlfpzKYhKlxTDcSo9RVmAtWoVfb1RozJbkPmpXbv2nuPhw4fTs2dPJk+ezLp16+hRkNULJCQk7DmOj48nKyurTHUiQYMGDViyZAnTpk3jmWee4Y033mD8+PF88MEHfP7557z33ns88MADLF26tNAx2JISba938PTqBaUw8x2nKpKenk6TJha9N2HChIg/v1WrVqSkpLBu3ToAJk2aVOJ7u3TpwqxZs9i0aRPZ2dm8/vrrdO/enU2bNpGTk8OFF17IyJEjWbRoETk5Ofzwww/07NmThx56iPT0dLZt27bf8se+RbltG3gMm+MUyR133MGVV17JyJEj6du3b8SfX7NmTZ566il69+5N7dq1OeGEEwqtO2PGjL2682+++SajRo2iZ8+eqCp9+/alf//+LFmyhKuuuoqcnBwAHnzwQbKzs7n88stJT09HVRk8eDD169ffb/mlsq3rnZSUpKXKR9mjhynKzz4LTCbHKYqVK1dy7LHHRluMqLNt2zbq1KmDqvKXv/yFFi1acOutt0ZFloK+ExFZqKoFxkLFfte7Rg3YtSvaUjhOlee5556jQ4cOHHfccaSnp3P99ddHW6QSE/tdb4+jdJwKwa233ho1C3J/iX1FecYZ8Ouv0ZbCcZxKTOwryiFDoi2B4ziVnNgfo3Qcx9lPYl9R3ngj+PK2juPsB7Hf9QabP+s4VZTNmzdz+umnA/DTTz8RHx+/Zzrg/PnzqVGjRpH3z5w5kxo1ahSYSm3ChAkkJyczduzYyAtegYh9Releb6eKU1yateKYOXMmderUiVjOycpI7He9ExJcUTpOPhYuXEj37t3p3LkzZ511Fj/++COwb4qydevW8cwzz/DYY4/RoUMHZs+eXaLnP/roo7Rt25a2bdsyevRoALZv307fvn05/vjjadu27Z5pjHfeeeeeNkujwMsTtygdpxwZMgRCxl3E6NABQrqoRKgqt9xyC++88w6NGzdm0qRJ3H333YwfP36fFGX169fnhhtuKJUVunDhQl544QXmzZuHqnLiiSfSvXt3UlJSOOyww/jggw8Am1++efNmJk+ezKpVqxCRiKVFizSxb1GedJLl+atkUzUdJyh27drFsmXLOPPMM+nQoQMjR44kNTUVyE1R9sorr5Q5487//vc/zj//fGrXrk2dOnW44IILmD17Nu3atWP69OkMHTqU2bNnU69ePerVq0diYiLXXHMNb7/9NrVq1Yrkq0aM2Lco+/a1zXEqAKWx/IJCVTnuuOP48ssv97lWUIqySNGyZUsWLVrE1KlTueeeezj99NO59957mT9/PjNmzOCtt95i7NixfPrppxFrM1LEvkWZkwMZGW5ROk6IhIQE0tLS9ijKzMxMli9fXmiKsrp167J169YSP79bt25MmTKFHTt2sH37diZPnky3bt3YuHEjtWrV4vLLL+f2229n0aJFbNu2jfT0dPr06cNjjz3GkiVLgnrt/SL2Lconn4TBg23J2kaNoi2N40SduLg43nrrLQYPHkx6ejpZWVkMGTKEli1bFpii7Nxzz+Wiiy7inXfeYcyYMXTr1m2v502YMIEpU6bsOZ87dy6DBg2iS5cuAPz5z3+mY8eOTJs2jdtvv524uDiqV6/O008/zdatW+nfvz8ZGRmoKo8++mh5fhQlJvbTrD37LNxwA2zYAIcdFpxgjlMInmat4uFp1vITDqZ1z7fjOGXEFaXjOE4xuKJ0HMcphthXlMceC8OGQcOG0ZbEqcJUNl9ALFOW7yJQRSkivUXkGxFZIyJ3FnB9kIikicji0PbniAvRti383//BoYdG/NGOUxISExPZvHmzK8sKgKqyefNmEhMTS3VfYOFBIhIPPAmcCaQCC0TkXVVdka/qJFW9OSg5yMqC33+HAw7I7YY7TjnStGlTUlNTSUtLi7YoDvaPK+8qjyUhyDjKLsAaVU0BEJGJQH8gv6IMlrlzoVs3mD7dloVwnHKmevXqNG/ePNpiOPtBkF3vJsAPec5TQ2X5uVBEvhaRt0Tk8EgKoAq/76rJdmq5M8dxnDITbWfOe0AzVW0PTAdeLKiSiFwnIskiklza7kuDMzrzCLe7onQcp8wEqSg3AHktxKahsj2o6mZVDS+6/TzQuaAHqeo4VU1S1aRwZuaSIAI1queQQaIrSsdxykyQinIB0EJEmotIDeAy4N28FUQkryu6H7Ay0kIkJqgrSsdx9ovAnDmqmiUiNwPTgHhgvKouF5H7gWRVfRcYLCL9gCzgV2BQpOVIrCnsanMqHF890o92HKeKEGj2IFWdCkzNV3ZvnuNhwLAgZUhIjCOjTSdoF2QrjuPEMtF25gROYqKSsXmbxVI6juOUgdhXlDVy2PXex/D889EWxXGcSkrMK8qERHFnjuM4+0XMK8rEmq4oHcfZP2JfUSYKu8QVpeM4ZSfmFWVCAmRITVeUjuOUmZhXlImJkHHwkXD++dEWxXGcSkrVUJQ1D4STT462KI7jVFJiXlEmJMCu7Zmwbl20RXEcp5IS84oyMREy0rbCPfdEWxTHcSopVUNRqnu9HccpO1VCUe7S6q4oHccpMzGvKBMSIIvqZGVkRVsUx3EqKTGvKMOLre3aVXQ9x3Gcwqg6ivIvf4uuII7jVFpiXlEmJNg+o+tp0RXEcZxKS8wryrBFmfHFougK4jhOpaXKKMpdNw6JqhyO41ReYl5R7ul6b82MriCO41RaYl5R7ul67wIyXVk6TqySkwPZ2cE8u+ooShIhPT26wjiOU2YmT4arrir8+gknQLVq0Lt35NuOeUUZ7nrvIsEVpeNUYl55BSZMgB079r32/fewaBEcfDB8/DFs3RrZtmNeUe6xKO/6p32KjuNUSpYts304Edju3bBzpx1//rnthwwBVVOakSRQRSkivUXkGxFZIyJ3FlHvQhFREUmKtAx7FGW7E6BOnUg/3nGcgFi5Ei65xJThzp2wZo2Vp6TA9OnQvDmceaYpxs8/h/r14eqrrc78+ZGVJTBFKSLxwJPA2UAbYICItCmgXl3gr8C8IOTY0/WetxhSU4NownGcCDJ5MnzzDbzzDrz5JsyeDStWmLMGYOlS6NfPuuBz5sD//gezZkG3bnDQQXDUUZVIUQJdgDWqmqKqu4GJQP8C6v0TeAjICEKIPRbl6Kfh00+DaMJxnDxs3Qo33gibN5f+3p074dJLYeRIWL3aymbPNuUY5r//hYwMePZZOPBAuOUW+PZb6N7drnfpUrkUZRPghzznqaGyPYhIJ+BwVf0gKCHc6+045cuMGfDMM/Dee6W/d8ECi+JbutSsSrBu9bJl9ls+9lhYuNDKu3eHm2+GJUvM4z1woJV36QLr18NPP0XmfaCEilJEaotIXOi4pYj0E5Hq+9Nw6HmPAn8vQd3rRCRZRJLT0tJK1c6emTnu9XaccmHFCtt/9ZXtFy6Ec87JdbwUxRdf2H7lStsA5s2DuXOhTRto0cLKjjjCfLPDh5s1OX8+HHKIXTvtNHPqRDKmsqQW5edAoog0AT4GrgAmFHPPBuDwPOdNQ2Vh6gJtgZkisg74A/BuQQ4dVR2nqkmqmtS4ceMSimzsmZlTrY4rSscpB5Yvt/3ixbb/z3/ggw/gyy8Lrv/++/DWW3Y8Z47td++G336DU06xFIlz5sDZZ9v4I5jVCBY3ecwxez/v+OPhscegSRMiRkkVpajqDuAC4ClVvRg4rph7FgAtRKS5iNQALgPeDV9U1XRVbaSqzVS1GTAX6KeqyaV+iyKIj7cPM6NGPVeUjlMO5FWUqhbXCLlKEGwc85FH4Pff4cor4eKLYexYsyg7d86td911pgjvugvuv9883WBd7fKkWgnriYicBAwErgmVxRd1g6pmicjNwLRQ3fGqulxE7geSVfXdou6PJImJkNH3Yrijb3k16ThVkuxsWLUKGjY0Z84nn8B339m1OXNMcQK8/DLccQe88Qb8+iu0bm1OGTBHzuLF9qwTT7SudZg2obiZ8l59uqSKcggwDJgcUnZHAZ8Vd5OqTgWm5iu7t5C6PUooS6lJSIBdDQ+DY4qv6zhO2UlJsa7y1VfD00/DQw9Z+WmnWde7e3dTcuHxx+RksxIXL4Zp06z8T3+CMWPM6x22IMOcfro5fJIiHnFdNCXqeqvqLFXtp6oPhZwwm1R1cMCyRYzERMhY9xO8W25GrONUCTZvhvvug23b7Dzc7b70Uhv2mjHDlN2gQbBli4X6jB5t5eecA/Xqmec6IcFiI4cOhdq14aSTbKyxej6XsUj5K0koudf7NRE5QERqA8uAFSJye7CiRY7ERMhYuhqGDYu2KI5TaVm2DK6/HrLyrNM3YQKMGGFjiaoWqiwCnTrBSy/B44/D1KlmScbHw4UXWgzktm2W4GLjRrj11n3beuIJ67ZXFEra9W6jqltEZCDwIXAnsBB4JDDJIkhCAuzKqmX/0hzHKROjR5sHe/BgOC7kyp061ay+11+3mTLvvQfXXAN168If/7j3/evXw6GHWtd7/nzrjteqVXBbtWvbVlEoqaKsHoqbPA8Yq6qZIqLBiRVZEhMhY2dN+NW93o5TFrKzcwPIV682Rbl1q3Wl//pXiyz5178svvHRRwt+xmGH2f7JJy1IvH79chE9IpQ0POhZYB1QG/hcRI4EKo15lpgIGdS0bzaozJ6OE0PMmmVe6LCXet48+OUXOw7PmJkxw2bR9O0LDz5oSSu++MKsyaLo2NHGLCsTJXXmPKGqTVS1jxrfAz0Dli1iJCTArrjQFB1PjOE4xfLiixbXuHEjTJpkcYzVq9vc6m++scQVN99sVmHXrnbPkUda1zoWKakzp56IPBqeRigi/8asy0pBo0bwU85BFntw5JHRFsdxKixr1piVGJ6G+MknNta4cKE5ctq3t27zFVeY0vzgA6hRI7oylwcl7XqPB7YCl4S2LcALQQkVaVq3hpTvq5HRrHW0RXGcCsczz5gDZs0a+62MHZurKP/9b0tv9sEHFtvYqpXN4d6+3WIkw9ZkrFNSZ87RqnphnvP7RGRxAPIEQps29mV/+/43tJvyT/vGGzSItliOExhLl5rSyx+HmJ+NG+HvfzeP9bff2hD++PG5SyksXQo1a9oMGTBFCZYD+7TTgpO/olFSi3KniJwSPhGRk4ES5AKpGBx7rO1XrhJ49VUbgHGcGGXZMgvWvuMOO09JsbnREyfuW/fee62r3bChebDD90Nupp5TTslNLhNWlGefnVtWFSiporwBeFJE1oUy/YwFrg9MqgjTsiXExcGKzBbQqxf84x/w44/RFstxAmHMGPNWjxljFuHrr9tUwQED7M8/nL967VoLGL/pJrjtNiu79trc5/zpT7bvmcdt27GjRZGEcz9WFUS15OGQInIAQCj4fIiqjg5KsMJISkrS5OTSJxg65hjLSjJp5LfQtq2lK3nllQAkdJzo8dtv0LSpLdk6a5ZN99u2zbrWl1yS68keNcrGJCdMMIV50EGWtKJ1a/NcH3ywLbHQs6dl/wn3ysDyStasGbVXDAwRWaiqBU+QVNUybcD6st67P1vnzp21LJxzjmrbtqGTe+5RBdVZs8r0LMepqEyYYH/aycmqDz5oxyKqw4fb9W3bVC+4wMpB9Zpr9n1GmzaqvXqVr9wVASyrWYF6p6TOnAIV8H7cW+60aWP/GXfuhJp33WWj0dGYXe84AbBqlVmFK1eaA+f4460X9eCDNnP37LOtXu3aliR3+nTLEXNnAWujvvNO1Qj5KQ2l6nrvdaPIelU9IsLyFEtZu96zZ8Opp9oAdzj1k+PEArt22TIIF18MmzaZ0gyH9/zf/8ELL1hZfJEZZJ2iut5FOnNEZKuIbClg2wocFoi0AdGtmw1U/+tfuYul88EHcPnlufO0HKeCk5Nj/+wXLMgtmzXLMoXPnWuzZlq2zL02bJjNzXYluX8UqShVta6qHlDAVldV96fbHhUeecRCHvr1C4VApKVZuNBLL0VbNMcpES+8YH/H99+fW/bOO7ZfscIcNOEQHrCUZ1KpBskqJkEuV1vhqFfPsijXrGm58HIu/5MFiQ0ZYq5Ax6mAjB4NU6aY1ThsmFmHH31k/+dVbayxXj0LFt+9e2+L0okMVUpRgk31HjXK4sreejvOpiHs3Al33x1t0RyHpUst2cR999n57NmW2Hb4cFtfJi0Nxo2z5LmTJtn11NS9k9/mtSidyFBmZ060KKszJy/Z2RY4u22bpa6vOfw2W99yxQr/K3Oixty50KOHOWcAFi2yoO/wTJmOHc2q/O47yyD+++8W87h2rZUdfrgt1PXLL1DKVZ0d9sOZE6vEx1uK+rVrzSvIsGE2Thmes+U4EeCVV2w8sTiWL7ekFOecY2tRL19uw0M9e5qSDD/jq6+sjogt3PXjj7Zg17Bhlim8c2dLe9aoUaCvVTUpLMCyom5lDTgviCuuUK1eXXXJkog90nFUVTUnR/WII1Rr1VLdvVv1/fdVr7tO9Zln7FpWltVbvVr1oINUDzhA9YwzVFessPLBgy0g/O67rf6RR9r5tGm5bUyZonrJJao7d9r57NmqL79crq8ZU1BEwHnUFV9pt0gqyrQ01UMOsZkI27er6rPPqp53nv1lOs5+MH9+7uyXMWNsX7Om7Q85RDU+XvWii1Tr11dt1Eh11aq979+yRXXixFyFOmSI6oEHqmZklP+7VBWKUpRVsusdplEj63GvWBEKQs/JMffia69FWzSnkvPf/+bGLg4fbrNlUlNtdcGuXW0phPfesxk0c+bsOzRet27ukq9gQ0RLl1atjD0ViUCdOSLSG3gciAeeV9VR+a7fAPwFyAa2Adep6oqinhkJZ05+LrzQMjl/n5JN/b4nW16qFSt8sMcpE6oWotO8uSnHlSttXZn339+3nsc4Vhyi4swRkXjgSeBsoA0wQETa5Kv2mqq2U9UOwMNAIeu3Bcu999p82NFj4i32Ij0drrzSLEzHKYBwx3r3bjjvPIvPDTNrlgV+//GP5sUGsw7z40qy8hBk17sLsEZVU1R1NzAR6J+3gqrmXcmxNhCVWKXjj4eLLjLv4g8N2tt6m1On5mYydZx83HGHLdn6/vs2M2bQIPjwQ3j+eeteN2hgynHgQFvHun//Yh/pVGQKG7zc3w24COtuh8+vwNYEz1/vL8B3wA9Ai0KedR2QDCQfccQRkR/FVdW1a1UTE82LqDk5lqfKqdJkZakef7zqU0/tXf7LL/a3AqoHH2we67i4XOcNqN56a1REdvYDKrIzR1WfVNWjgaHAPYXUGaeqSaqa1DigSNpmzWxJzjfegAkvigWlgWUvTUsLpE2nYrNoka04+Nxzdq5q61YPHw4ZGRbz+PPPFhQ+bpzN+HrvPTj/fJsV68QQhWnQ/d2Ak4Bpec6HAcOKqB8HpBf33EiGB+UnM1P1tNNUExJUly1T1U2bVGvXVu3dWzU7O7B2neixfr2F8hTEP/+ZayFOn67apUvuef/+uUlyFywoV5GdgCBKFuUCoIWINBeRGsBlwLt5K4hI3qkwfYFvA5SnWKpVs/VFate2dUT0wIaWl+2jjzyJZYxy1VWWgm/FCvuqV63Kvfbxx3BYKJlgnz42TfC55yyc5+WXzZJcu9bzP1cJCtOgkdiAPsBqbAzy7lDZ/UC/0PHjwHJgMfAZcFxxzwzSogwzbpxZCi+9pDZeeemlNgjlS0fEFKtW5VqI4WDwAw9UnTdPNT1dtVo11WHDVI87zr7+Tz+NtsROkFCERVklk2IUR06OBQWvXWuJUOvHbcldpWnpUlvb06n0DBkCTz1l4WEjRljGnvHjLalEp06W4PmLLyyJyqZNFgbkxC6BLC4Wra08LEpV1YULzYq48cZQweLFqg895GOVlZCcHPNcL1pk5/PmqfbtaxbkwIFWtnWr7TdutEXoRGxGq1N1IKDFxWKaTp1g8GBLmtq7N/Trd7wFXEJuTitfgalS8PLLNuZcuzb84Q8wYwYceCA88IB9x2BrzYGlLfvyS1i/3hakcxyoovkoS0pGhnXB162z1FeHHor1wVq1gjPPtJiQAw4oF1mcsrFmjY2aHHusrW29cSPcdpspzrp1oy2dU5HwfJRlJDHRvOA7duRaHjRqBEOHWnrpJk3swvr1UZXTMbZvN2sxPPN02TJbebN6dcsNmZwMGzbY1+dK0ikNriiLoVUrG+x/6y3TjUDuMnjnnw/PPAMnnmippZ3AyMw050p2tinCjAwrV7WET089BSedBGecYYvH3X03dOlidT/7DI4+2hSmj5Y4ZcG73iUgMxO6dzeH94IF0Lp1nosrVsCnn9pCJ04gpKXBJZfAzJkW85iaahEJBx1k44gzZ1q9Bg0sLnLMGPvOzjrLVi089NBoSu9UForqeruiLCGpqebgqVHDUrLtpSzDfP21LVbiv8z9ZvduS1JSty78+98WsnPddRbw3aqVpcZbssSszJtvtqUU6ta1betWsx4TE6P9Fk5lwhVlhPj6a/PhZGaapbJXRpht22zNncxMePhhm7ZRzYMKSkJOjhnlJ51k68CsXQsTJ1pMI1iAweTJNv1+2zZbHybOB42cCOPOnAjRvr0FIDdvbsHH991nY2SAxZd89hkcc4yZN61bmwehkv0jKi9WrbJ8I6tWwQ032D+gZs3sY+vVy5TkXXeZ13rFitwcJXXquJJ0yh83eUrJ0Uebsrz+epvNkZxs3cFDDsF+5V9+aSlk/vEPuOIKaNo0N3urw7Zt5nV+6qm9y6+91jLxNG9ucatpaZbL0ZWiUxHwrncZUbUErXfeaYHMTz9tyX/3ZK3OybHBzF697Hz0aBu77NYtN9NCFWPOHPvfsW6dTR/s3dvGHmvVsgACz/jtRBOfwhggK1aoJiXZdLh+/VRXriygUlaWauPGVikuztYg3b273GUtT3JybMXAjAxb7fKRR2xp4KOPtmVVHaeiQUVO3FvZOfZY64o/8ogFO7dpAwMG2LjaHuLjbUpIcrKtxfPAA9Chg0VExwjjxllw98yZNr7Yrp15nRMTLRDg9tvh9NMtvOqUU6ItreOUDu96R5C0NFtuZ+xYmyVywQVw+eUWz1ezZp6K770H999vi6xUopUeN20ykevWtfeZNMnCc5o1M691fDxkZVndtm3h4ostTCc+3pRkp07evXYqLh4eVM5s2gSPPWaTdn791cYw+/bN9ez26AHV4kNrlWZlmQm6e7dZmxdcEG3xARuD/fRTy/9Rq5aF7IwcaWKGqV/frMjkZPNjvfqqLbTVsSOccIIrRady4YoySmRm2tKlb71lcYC//GLlzZtboobMTGDHdk5L+Q+9d7zNMRtnITffbFMiL73UzLGA+P13C/NMT4evvrIYxnXrzP+0YoUtbf6//+19z8UX2+zNLVssqPuss3KDutXXqHYqOa4oKwDZ2ZY7Y9Ei85Cnppoe3LHDlBJAverbOTpzFU3jfiTj5NP5YVNNDjzQxvsyMmws9OijzbveqZNZcvPnm5Lr08fGB3fvthkrTZuavp040ZT0ccdZCNOcOdbWt0UsutGkiVmRgwebNzo93drv1Cnwj8lxooYrygrOd9/Z+izLlsF3a3L48ftMEusl0KSJ8uOX3/PtzibEJ1TjhBNg+XJh3brce2vXtvFQkdzY9ho1crvINWpYhNK8ebBzp3X/4+LMlxQXZ1tSEsyda5bu6aeHYkIdp4rhirKysn69mYU//WR5L3fuRG+8ia+ueJSV38Rxwgk2Eeill2wGy3nnmaOleXOzKr/5xsZGGzSwbn5ODiQkRPulHKdi4oqyMvPbb/D229Zn37TJcootWGDzKR3HiRiuKGMFVZscfeyxdn7ppTbPr2NHMxePPDK68jlOJcaTYsQKIrlKcscO61v37w9HHGH97Ysv9mzrjhMAnhSjslKrlnlonnzSrMnffrPcb+HI9vfftznlYa+N4zhlJtCut4j0Bh4H4oHnVXVUvut/A/4MZAFpwNWq+n1Rz6zSXe/iyMy0mKOsLLM816wxT86bb5o723GcQolK11tE4oEngbOBNsAAEcm/AOhXQJKqtgfeAh4OSp4qQThAvVo1C7ocN86syv79LbljOGaoko1LO060CbJP1gVYo6opqrobmAjkzQmOqn6mqjtCp3OBpgHKU7Vo3NiSPE6fbtHmDz+cuyLX7bfb/MNjjrHJ6Fu2RFVUx6noBKkomwA/5DlPDZUVxjXAhwVdEJHrRCRZRJLT0tIiKGIV4NBDbSxz167cNVpbtbKlKjp3tqk7XbvCRx/ZNdXczBaO4wAVxJkjIpcDSUD3gq6r6jhgHNgYZTmKFjvEx+ceX3tt7vG0aXDTTbnzKKdPh3PPNQdQy5Zw8MGW4eKee/KlQHKcqkOQinIDcHie86ahsr0QkTOAu4HuqrorQHmcgjjrLHP6hK3IxERbxCY+3sKP0tJs/ddrr7XURy+9ZHMmjznGHETuUXeqAEEqygVACxFpjinIy4A/5q0gIh2BZ4HeqvpLgLI4RSGS6wg69VTb8vLzz2ZZAowaBStX2nGLFmZ9/u1vlknDcWKUwBSlqmaJyM3ANCw8aLyqLheR+7GU6+8CjwB1gDfFcnStV9V+QcnklJGwkgTLG5eVZStOjh9vWYrj4izF+5tvWuLKDz+0APirrrKUQ7VrR092x4kAPoXR2T9Wr4ajjrKQpF69bIyzRQvYsMFmD51zjmV0V7WF0dessVxxxx/vCSydCkVRcZQVwpnjVGJatsw9/ugjS7R5+OGWGXj2bFOIYOnSzzgjt27v3pZI8957y1VcxykLPhLvRI64OJt3LmIzgvr1y03UUasWPPusZUF65BELiH/iCZt+uWOHhTENH25rZzhOBcO73k50yM42xRrufl96Kbzxhh03bGj7V181r/zLL9vc9X/8wxZjW73aAubbto2K6E5s4l1vp+KRN64TbEnHv//duujr19uY5kEH2bWGDW2cM6xIwSzQ9euti3/VVXDffXb+yis2XTO8bkVOjgXbewyosx+4onQqDl262JafPn0sIP7VV21ti6OPNouyWjUr/+ILm2UEpoBTUmDhQvPO169vc9wffdTuW77cpnCG2b7duvuHH75vu44TwrveTuXn11/htdfs+JJLzMps2RI2b4bRo20VtvAUzQYNLIg+Ls6Wxxw50rzxzZvbSmr//rctXvTaazB0KNSrZ4sNpaTYnHknZvEM507VJivLLMojj7R106tXtyUre/a0mUhDhtiylGeeCddfb6FNTZualdmrl3X7q1WzcrBlND/80JKMPPyw5fwMs369rUvcqZPPWqpkuKJ0nIJ4+WWL+fzDH/a9NncuDBtmXvouXeDmm82Ln5Nj46PhvJ9padC6tQXgH3wwPPCAzYtv2dIUcFKSWbxnnWXjrv37W67QaqFRrz594OST7TglxWY9tWxpU0Tzxplu3mzK+cwzrZ3w77a4WNRwkpMA14iPFYpSlKhqpdo6d+6sjhNVdu1Szc5W3bxZ9f77VU89VXXqVLu2bp3qiy+qJiWpmppSbd/erqWlqZ58smpcnGq1arYH1Zkz7fro0bn3tG6t+tprqmvX2rWUFCuPj1f9+99VO3RQ7dpVNStL9dFHVUeNUh0wQPXss1WvvdZk2r1bdcQI1caNVT/7THXwYNVPPrHn5eSofvml6vTpqps2lf4zSEtT3blzfz7FCgc2Y7BAvRN1xVfazRWlUynIyVGdM0d10iRTngWxbZvqmDGq779v5z//bMrr6adVW7Wyn+fRR6v+8osp5oULVS+/PFeZPv643fevf9l5o0amYKtXVx071q6FFWx4S0w0eSZOzC2rWVP1yivtnvR0u+/VV1U//lj1H/9QnT9f9fvvc+W+/XZVEdVmzVSfekp12DDVRYv2fb+vv1adPFk1Obng99+92xR4WFHv2qW6cWPJP+MI44rScSobu3erzp6t+umnpkDy8uWXZs3mJT3drEtVU6p5Wb1a9YorTPH95z9Wlpmp+vzzZmEOGqR64IGmDn7/3azFOnX2VrAiJo+q6qWXqt5xhylKMOv4tdfs2po1Zl0PG2b3gCn38Dt16qR6002qQ4eqHnywXZ8+3a537Wrn99xjCvT663PfZcsWU8pDhpjyzcy08pyc3PecMsXeacWKsnzirigdxymGnBzVDRtyz1euVH3pJdUffjAL94UXVFNT975n+3arF1ZaqntbvFdeaVbwDz/YtbQ01d69VWvVsmGHc881yzWs7N5+25Rw+P4jjrB7//MfG3IA1Ro1bH/rrXbPyy+rdutmww7h+8LXSklRitKdOY7jRI7ffrMY1qZNzclVEDt32rTV8AysvGRnw4gRtpTJn/9squ/UU20W1k03WTTB++9Du3bm8Hr9dfjnP80JNniwOd0SEmwqbSlxr7fjOLHN9u37nc4vKqswOo7jlBsB5zx1Rek4jlMMrigdx3GKwRWl4zhOMbiidBzHKQZXlI7jOMVQ6cKDRCQN+L6E1RsBmwIUx9v39r39itl+Wdo+UlUbF3Sh0inK0iAiyYXFRXn73r63H7vtR7pt73o7juMUgytKx3GcYoh1RTnO2/f2vf0q2X5E247pMUrHcZxIEOsWpeM4zn4Ts4pSRHqLyDciskZE7iyH9g4Xkc9EZIWILBeRv4bKR4jIBhFZHNr6BCjDOhFZGmonOVR2oIhMF5FvQ/sGAbXdKs87LhaRLSIyJMj3F5HxIvKLiCzLU1bg+4rxROjv4WsR6RRA24+IyKrQ8yeLSP1QeTMR2ZnnM3hmf9ouov1CP2sRGRZ6929E5KyA2p+Up+11IrI4VB7E+xf2ewvm+y8sUWVl3oB44DvgKKAGsARoE3CbhwKdQsd1gdVAG2AEcFs5vfc6oFG+soeBO0PHdwIPldPn/xNwZJDvD5wKdAKWFfe+QB/gQ0CAPwDzAmi7F1AtdPxQnrab5a0X4LsX+FmH/g6XAAlA89BvIz7S7ee7/m/g3gDfv7DfWyDff6xalF2ANaqaoqq7gYlA/yAbVNUfVXVR6HgrsBJoEmSbJaQ/8GLo+EXgvHJo83TgO1Ut6cSAMqGqnwO/5isu7H37Ay+pMReoLyKHRrJtVf1YVbNCp3OBpmV9flnaL4L+wERV3aWqa4E12G8kkPZFRIBLgNf3p41i2i/s9xbI9x+rirIJ8EOe81TKUWmJSDOgIzAvVHRzyNwfH1TXN4QCH4vIQhG5LlR2sKr+GDr+CTg4wPbDXMbeP5Lyen8o/H3L+2/iasyCCdNcRL4SkVki0i3Adgv6rMv73bsBP6vqt3nKAnv/fL+3QL7/WFWUUUNE6gD/BYao6hbgaeBooAPwI9YlCYpTVLUTcDbwFxE5Ne9FtT5IoGEOIlID6Ae8GSoqz/ffi/J434IQkbuBLODVUNGPwBGq2hH4G/CaiBwQQNNR+6zzMYC9/1EG9v4F/N72EMnvP1YV5Qbg8DznTUNlgSIi1bEv7VVVfRtAVX9W1WxVzQGeYz+7PEWhqhtC+1+AyaG2fg53MUL7X4JqP8TZwCJV/TkkS7m9f4jC3rdc/iZEZBBwDjAw9EMl1OXdHDpeiI0Rtox020V81uX2exCRasAFwKQ8cgXy/gX93gjo+49VRbkAaCEizUMWzmXAu0E2GBqX+Q+wUlUfzVOedxzkfGBZ/nsj1H5tEakbPsYcC8uw974yVO1K4J0g2s/DXtZEeb1/Hgp733eBP4W8n38A0vN00SKCiPQG7gD6qeqOPOWNRSQ+dHwU0AJIiWTboWcX9lm/C1wmIgki0jzU/vxItx/iDGCVqqbmkSvi71/Y742gvv9IeqIq0oZ5uVZj/73uLof2TsHM/K+BxaGtD/AysDRU/i5waEDtH4V5NpcAy8PvDDQEZgDfAp8ABwb4GdQGNgP18pQF9v6YQv4RyMTGnK4p7H0xb+eTob+HpUBSAG2vwcbBwt//M6G6F4a+k8XAIuDcgN690M8auDv07t8AZwfRfqh8AnBDvrpBvH9hv7dAvn+fmeM4jlMMsdr1dhzHiRiuKB3HcYrBFaXjOE4xuKJ0HMcpBleUjuM4xeCK0qnwiEi27J2ZKGLZoEKZbYKO7XQqOdWiLYDjlICdqtoh2kI4VRe3KJ1KSyjn4cNiOTjni8gxofJmIvJpKDnEDBE5IlR+sFieyCWhrWvoUfEi8lwor+HHIlIzai/lVEhcUTqVgZr5ut6X5rmWrqrtgLHA6FDZGOBFVW2PJaZ4IlT+BDBLVY/HcikuD5W3AJ5U1eOA37GZJI6zB5+Z41R4RGSbqtYpoHwdcJqqpoQSJPykqg1FZBM2fS8zVP6jqjYSkTSgqaruyvOMZsB0VW0ROh8KVFfVkeXwak4lwS1Kp7KjhRyXhl15jrPxsXsnH64oncrOpXn2X4aOv8AyRgEMBGaHjmcANwKISLyI1CsvIZ3Kjf/ndCoDNSW0UFWIj1Q1HCLUQES+xqzCAaGyW4AXROR2IA24KlT+V2CciFyDWY43YhlwHKdIfIzSqbSExiiTVHVTtGVxYhvvejuO4xSDW5SO4zjF4Bal4zhOMbiidBzHKQZXlI7jOMXgitJxHKcYXFE6juMUgytKx3GcYvh/Oh3rJhzEf5YAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_NN = NN_arch2(0.0009)\n",
        "#val_loss,val_acc = model_fit(model_NN,100)\n",
        "history = model_NN.fit(X_train,y_train,epochs=200,verbose=1,batch_size=100,validation_data=(X_test, y_test)) \n",
        "history_plot(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwR2Q6bIoUdu"
      },
      "outputs": [],
      "source": [
        "model_NN.save('/content/model_text_categorize.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yy2EA_uRoZJa"
      },
      "outputs": [],
      "source": [
        "loaded_model = tf.keras.models.load_model('/content/model_text_categorize.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ODIpYuxoi2A"
      },
      "outputs": [],
      "source": [
        "#Load the word2vec pre trained Model to get the word embeddings for each token\n",
        "model = KeyedVectors.load_word2vec_format('/content/GoogleNews-vectors-negative300.bin.gz',binary=True,limit=1000000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfzrbldcovrP"
      },
      "outputs": [],
      "source": [
        "def clean_description_text(description):\n",
        "  description = description.replace(r'\\d+','')\n",
        "  spec_chars = [\"!\",'\"',\"#\",\"%\",\"&\",\"'\",\"(\",\")\",\n",
        "                \"*\",\"+\",\",\",\"-\",\".\",\"/\",\":\",\";\",\"<\",\n",
        "                \"=\",\">\",\"?\",\"@\",\"[\",\"\\\\\",\"]\",\"^\",\"_\",\n",
        "                \"`\",\"{\",\"|\",\"}\",\"~\",\"–\"]\n",
        "  for char in spec_chars:\n",
        "      description = description.replace(char, ' ')\n",
        "\n",
        "  word_list_t = description.lower().split() \n",
        " \n",
        "  filtered_words = [word for word in word_list_t if word not in stopwords.words('english')]\n",
        "  text = ' '.join(filtered_words)\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSaeWlGso3rh",
        "outputId": "adfd2809-6208-4fd2-d018-bdf354076bc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 28ms/step\n",
            "Predicted Label :  science and technology\n"
          ]
        }
      ],
      "source": [
        "description = 'robot'\n",
        "\n",
        "clean_description = clean_description_text(description)\n",
        "description_tokens = list(clean_description.split(\" \"))\n",
        "description_tokens_filtered = token_check(description_tokens,model)\n",
        "\n",
        "_arrays = np.zeros((1, 300))\n",
        "_arrays[0,:] = word_vector(description_tokens_filtered,300,model)\n",
        "vectorized_array = pd.DataFrame(_arrays)\n",
        "\n",
        "pred = loaded_model.predict([vectorized_array.iloc[:,0:300]])\n",
        "\n",
        "value = np.argmax(pred,axis=-1)\n",
        "labels = ['adventure','art and music','food','history','manufacturing','nature','science and technology','sports','travel']\n",
        "\n",
        "print(\"Predicted Label : \" , labels[value.item()])  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "mfVIC9NYo_JX",
        "outputId": "80966d1c-594c-42bf-bdce-9fe0d4553c3b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3b5053bc-2d8e-4268-942c-083ef032c3de\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>290</th>\n",
              "      <th>291</th>\n",
              "      <th>292</th>\n",
              "      <th>293</th>\n",
              "      <th>294</th>\n",
              "      <th>295</th>\n",
              "      <th>296</th>\n",
              "      <th>297</th>\n",
              "      <th>298</th>\n",
              "      <th>299</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.024719</td>\n",
              "      <td>0.063202</td>\n",
              "      <td>-0.054357</td>\n",
              "      <td>0.113420</td>\n",
              "      <td>-0.110855</td>\n",
              "      <td>0.028269</td>\n",
              "      <td>0.086772</td>\n",
              "      <td>-0.029327</td>\n",
              "      <td>0.051575</td>\n",
              "      <td>0.005269</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.083984</td>\n",
              "      <td>0.073039</td>\n",
              "      <td>-0.088826</td>\n",
              "      <td>-0.074422</td>\n",
              "      <td>0.046855</td>\n",
              "      <td>-0.055272</td>\n",
              "      <td>0.020864</td>\n",
              "      <td>-0.060996</td>\n",
              "      <td>-0.037821</td>\n",
              "      <td>-0.071991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.053044</td>\n",
              "      <td>0.063425</td>\n",
              "      <td>-0.031696</td>\n",
              "      <td>-0.004019</td>\n",
              "      <td>0.037795</td>\n",
              "      <td>-0.002310</td>\n",
              "      <td>0.018555</td>\n",
              "      <td>-0.098257</td>\n",
              "      <td>0.012489</td>\n",
              "      <td>0.060678</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.143508</td>\n",
              "      <td>0.016310</td>\n",
              "      <td>-0.132531</td>\n",
              "      <td>0.102217</td>\n",
              "      <td>-0.067932</td>\n",
              "      <td>-0.009230</td>\n",
              "      <td>-0.036093</td>\n",
              "      <td>-0.053872</td>\n",
              "      <td>0.098778</td>\n",
              "      <td>-0.041584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.010413</td>\n",
              "      <td>0.068515</td>\n",
              "      <td>0.037320</td>\n",
              "      <td>0.090747</td>\n",
              "      <td>0.021960</td>\n",
              "      <td>0.068805</td>\n",
              "      <td>0.011243</td>\n",
              "      <td>-0.160822</td>\n",
              "      <td>0.073511</td>\n",
              "      <td>0.099237</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.099612</td>\n",
              "      <td>0.002881</td>\n",
              "      <td>-0.130408</td>\n",
              "      <td>-0.058983</td>\n",
              "      <td>-0.012489</td>\n",
              "      <td>-0.049695</td>\n",
              "      <td>-0.031040</td>\n",
              "      <td>-0.092152</td>\n",
              "      <td>0.014050</td>\n",
              "      <td>-0.055670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.063796</td>\n",
              "      <td>0.067345</td>\n",
              "      <td>0.041410</td>\n",
              "      <td>0.090609</td>\n",
              "      <td>-0.032114</td>\n",
              "      <td>0.038180</td>\n",
              "      <td>-0.007963</td>\n",
              "      <td>-0.212551</td>\n",
              "      <td>0.053828</td>\n",
              "      <td>0.043058</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.062913</td>\n",
              "      <td>-0.012292</td>\n",
              "      <td>-0.068904</td>\n",
              "      <td>-0.011928</td>\n",
              "      <td>0.029579</td>\n",
              "      <td>-0.118211</td>\n",
              "      <td>0.068819</td>\n",
              "      <td>-0.047032</td>\n",
              "      <td>0.068650</td>\n",
              "      <td>-0.085679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.076660</td>\n",
              "      <td>0.065318</td>\n",
              "      <td>0.030645</td>\n",
              "      <td>0.078562</td>\n",
              "      <td>-0.045288</td>\n",
              "      <td>0.002884</td>\n",
              "      <td>-0.085266</td>\n",
              "      <td>-0.124573</td>\n",
              "      <td>0.165507</td>\n",
              "      <td>0.013784</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.004862</td>\n",
              "      <td>-0.005880</td>\n",
              "      <td>-0.129781</td>\n",
              "      <td>0.029958</td>\n",
              "      <td>0.110107</td>\n",
              "      <td>0.006927</td>\n",
              "      <td>-0.026138</td>\n",
              "      <td>-0.058268</td>\n",
              "      <td>0.017171</td>\n",
              "      <td>0.042714</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 300 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b5053bc-2d8e-4268-942c-083ef032c3de')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3b5053bc-2d8e-4268-942c-083ef032c3de button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3b5053bc-2d8e-4268-942c-083ef032c3de');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        0         1         2         3         4         5         6    \\\n",
              "0 -0.024719  0.063202 -0.054357  0.113420 -0.110855  0.028269  0.086772   \n",
              "1  0.053044  0.063425 -0.031696 -0.004019  0.037795 -0.002310  0.018555   \n",
              "2 -0.010413  0.068515  0.037320  0.090747  0.021960  0.068805  0.011243   \n",
              "3  0.063796  0.067345  0.041410  0.090609 -0.032114  0.038180 -0.007963   \n",
              "4  0.076660  0.065318  0.030645  0.078562 -0.045288  0.002884 -0.085266   \n",
              "\n",
              "        7         8         9    ...       290       291       292       293  \\\n",
              "0 -0.029327  0.051575  0.005269  ... -0.083984  0.073039 -0.088826 -0.074422   \n",
              "1 -0.098257  0.012489  0.060678  ... -0.143508  0.016310 -0.132531  0.102217   \n",
              "2 -0.160822  0.073511  0.099237  ... -0.099612  0.002881 -0.130408 -0.058983   \n",
              "3 -0.212551  0.053828  0.043058  ... -0.062913 -0.012292 -0.068904 -0.011928   \n",
              "4 -0.124573  0.165507  0.013784  ... -0.004862 -0.005880 -0.129781  0.029958   \n",
              "\n",
              "        294       295       296       297       298       299  \n",
              "0  0.046855 -0.055272  0.020864 -0.060996 -0.037821 -0.071991  \n",
              "1 -0.067932 -0.009230 -0.036093 -0.053872  0.098778 -0.041584  \n",
              "2 -0.012489 -0.049695 -0.031040 -0.092152  0.014050 -0.055670  \n",
              "3  0.029579 -0.118211  0.068819 -0.047032  0.068650 -0.085679  \n",
              "4  0.110107  0.006927 -0.026138 -0.058268  0.017171  0.042714  \n",
              "\n",
              "[5 rows x 300 columns]"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorized_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLTA7WbspBMp"
      },
      "outputs": [],
      "source": [
        "vectorized_df_lgbm = vectorized_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HT9MlhBupDsR"
      },
      "outputs": [],
      "source": [
        "vectorized_df_lgbm['Target'] = df.Category\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9Hd68lkpGL1"
      },
      "outputs": [],
      "source": [
        "import pandas\n",
        "from sklearn import preprocessing "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5a6WSMhpIhB"
      },
      "outputs": [],
      "source": [
        "def target_label_encoding(x):\n",
        "  labels = ['adventure','art and music','food','history','manufacturing','nature','science and technology','sports','travel']\n",
        "  if x == labels[0]:\n",
        "    return 0\n",
        "  elif x == labels[1]:\n",
        "    return 1\n",
        "  elif x == labels[2]:\n",
        "    return 2\n",
        "  elif x == labels[3]:\n",
        "    return 3\n",
        "  elif x == labels[4]:\n",
        "    return 4\n",
        "  elif x == labels[5]:\n",
        "    return 5\n",
        "  elif x == labels[6]:\n",
        "    return 6\n",
        "  elif x == labels[7]:\n",
        "    return 7\n",
        "  else:\n",
        "    return 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4PADxAvpMXq"
      },
      "outputs": [],
      "source": [
        "vectorized_df_lgbm.Target = vectorized_df_lgbm.Target.apply(lambda x : target_label_encoding(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50zYJ_D3pP04"
      },
      "outputs": [],
      "source": [
        "dataset_shuffled = vectorized_df.reindex(np.random.permutation(vectorized_df.index))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgNPUZLnpZkh"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#target=['adventure','art and music','food','history','manufacturing','nature','science and technology','sports','travel']\n",
        "X = dataset_shuffled.loc[:,~dataset_shuffled.columns.isin(['Target'])]\n",
        "y = dataset_shuffled.loc[:,dataset_shuffled.columns.isin(['Target'])]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,train_size=0.75,test_size=0.25,random_state=101)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBeFWSwjpdJd",
        "outputId": "c4ab2320-f46d-41b4-b10d-9be404949488"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 2.16285\n",
            "[2]\tvalid_0's multi_logloss: 2.15285\n",
            "[3]\tvalid_0's multi_logloss: 2.14351\n",
            "[4]\tvalid_0's multi_logloss: 2.13435\n",
            "[5]\tvalid_0's multi_logloss: 2.12533\n",
            "[6]\tvalid_0's multi_logloss: 2.11656\n",
            "[7]\tvalid_0's multi_logloss: 2.10812\n",
            "[8]\tvalid_0's multi_logloss: 2.0998\n",
            "[9]\tvalid_0's multi_logloss: 2.09174\n",
            "[10]\tvalid_0's multi_logloss: 2.08394\n",
            "[11]\tvalid_0's multi_logloss: 2.07627\n",
            "[12]\tvalid_0's multi_logloss: 2.06916\n",
            "[13]\tvalid_0's multi_logloss: 2.06203\n",
            "[14]\tvalid_0's multi_logloss: 2.05488\n",
            "[15]\tvalid_0's multi_logloss: 2.04822\n",
            "[16]\tvalid_0's multi_logloss: 2.0416\n",
            "[17]\tvalid_0's multi_logloss: 2.035\n",
            "[18]\tvalid_0's multi_logloss: 2.02869\n",
            "[19]\tvalid_0's multi_logloss: 2.02276\n",
            "[20]\tvalid_0's multi_logloss: 2.01682\n",
            "[21]\tvalid_0's multi_logloss: 2.01078\n",
            "[22]\tvalid_0's multi_logloss: 2.00497\n",
            "[23]\tvalid_0's multi_logloss: 1.99923\n",
            "[24]\tvalid_0's multi_logloss: 1.99358\n",
            "[25]\tvalid_0's multi_logloss: 1.98776\n",
            "[26]\tvalid_0's multi_logloss: 1.98226\n",
            "[27]\tvalid_0's multi_logloss: 1.9768\n",
            "[28]\tvalid_0's multi_logloss: 1.97142\n",
            "[29]\tvalid_0's multi_logloss: 1.96601\n",
            "[30]\tvalid_0's multi_logloss: 1.96086\n",
            "[31]\tvalid_0's multi_logloss: 1.95575\n",
            "[32]\tvalid_0's multi_logloss: 1.95072\n",
            "[33]\tvalid_0's multi_logloss: 1.94586\n",
            "[34]\tvalid_0's multi_logloss: 1.94094\n",
            "[35]\tvalid_0's multi_logloss: 1.93601\n",
            "[36]\tvalid_0's multi_logloss: 1.93154\n",
            "[37]\tvalid_0's multi_logloss: 1.92669\n",
            "[38]\tvalid_0's multi_logloss: 1.92186\n",
            "[39]\tvalid_0's multi_logloss: 1.91732\n",
            "[40]\tvalid_0's multi_logloss: 1.91265\n",
            "[41]\tvalid_0's multi_logloss: 1.908\n",
            "[42]\tvalid_0's multi_logloss: 1.90363\n",
            "[43]\tvalid_0's multi_logloss: 1.8992\n",
            "[44]\tvalid_0's multi_logloss: 1.89476\n",
            "[45]\tvalid_0's multi_logloss: 1.89048\n",
            "[46]\tvalid_0's multi_logloss: 1.88611\n",
            "[47]\tvalid_0's multi_logloss: 1.88181\n",
            "[48]\tvalid_0's multi_logloss: 1.87794\n",
            "[49]\tvalid_0's multi_logloss: 1.87372\n",
            "[50]\tvalid_0's multi_logloss: 1.86974\n",
            "[51]\tvalid_0's multi_logloss: 1.86598\n",
            "[52]\tvalid_0's multi_logloss: 1.86183\n",
            "[53]\tvalid_0's multi_logloss: 1.85775\n",
            "[54]\tvalid_0's multi_logloss: 1.85422\n",
            "[55]\tvalid_0's multi_logloss: 1.85028\n",
            "[56]\tvalid_0's multi_logloss: 1.84642\n",
            "[57]\tvalid_0's multi_logloss: 1.84267\n",
            "[58]\tvalid_0's multi_logloss: 1.83904\n",
            "[59]\tvalid_0's multi_logloss: 1.83543\n",
            "[60]\tvalid_0's multi_logloss: 1.83177\n",
            "[61]\tvalid_0's multi_logloss: 1.82802\n",
            "[62]\tvalid_0's multi_logloss: 1.82458\n",
            "[63]\tvalid_0's multi_logloss: 1.82112\n",
            "[64]\tvalid_0's multi_logloss: 1.81759\n",
            "[65]\tvalid_0's multi_logloss: 1.81417\n",
            "[66]\tvalid_0's multi_logloss: 1.81063\n",
            "[67]\tvalid_0's multi_logloss: 1.80731\n",
            "[68]\tvalid_0's multi_logloss: 1.80385\n",
            "[69]\tvalid_0's multi_logloss: 1.80069\n",
            "[70]\tvalid_0's multi_logloss: 1.79745\n",
            "[71]\tvalid_0's multi_logloss: 1.79426\n",
            "[72]\tvalid_0's multi_logloss: 1.79119\n",
            "[73]\tvalid_0's multi_logloss: 1.78804\n",
            "[74]\tvalid_0's multi_logloss: 1.78505\n",
            "[75]\tvalid_0's multi_logloss: 1.7821\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 2.16266\n",
            "[2]\tvalid_0's multi_logloss: 2.15258\n",
            "[3]\tvalid_0's multi_logloss: 2.1425\n",
            "[4]\tvalid_0's multi_logloss: 2.13289\n",
            "[5]\tvalid_0's multi_logloss: 2.12382\n",
            "[6]\tvalid_0's multi_logloss: 2.11505\n",
            "[7]\tvalid_0's multi_logloss: 2.10674\n",
            "[8]\tvalid_0's multi_logloss: 2.09845\n",
            "[9]\tvalid_0's multi_logloss: 2.09041\n",
            "[10]\tvalid_0's multi_logloss: 2.08273\n",
            "[11]\tvalid_0's multi_logloss: 2.0752\n",
            "[12]\tvalid_0's multi_logloss: 2.06781\n",
            "[13]\tvalid_0's multi_logloss: 2.0608\n",
            "[14]\tvalid_0's multi_logloss: 2.05386\n",
            "[15]\tvalid_0's multi_logloss: 2.04713\n",
            "[16]\tvalid_0's multi_logloss: 2.04037\n",
            "[17]\tvalid_0's multi_logloss: 2.03394\n",
            "[18]\tvalid_0's multi_logloss: 2.0275\n",
            "[19]\tvalid_0's multi_logloss: 2.02126\n",
            "[20]\tvalid_0's multi_logloss: 2.01519\n",
            "[21]\tvalid_0's multi_logloss: 2.00892\n",
            "[22]\tvalid_0's multi_logloss: 2.00294\n",
            "[23]\tvalid_0's multi_logloss: 1.99718\n",
            "[24]\tvalid_0's multi_logloss: 1.99143\n",
            "[25]\tvalid_0's multi_logloss: 1.98576\n",
            "[26]\tvalid_0's multi_logloss: 1.98052\n",
            "[27]\tvalid_0's multi_logloss: 1.97508\n",
            "[28]\tvalid_0's multi_logloss: 1.96961\n",
            "[29]\tvalid_0's multi_logloss: 1.96435\n",
            "[30]\tvalid_0's multi_logloss: 1.95907\n",
            "[31]\tvalid_0's multi_logloss: 1.95382\n",
            "[32]\tvalid_0's multi_logloss: 1.94859\n",
            "[33]\tvalid_0's multi_logloss: 1.94343\n",
            "[34]\tvalid_0's multi_logloss: 1.93877\n",
            "[35]\tvalid_0's multi_logloss: 1.93386\n",
            "[36]\tvalid_0's multi_logloss: 1.92885\n",
            "[37]\tvalid_0's multi_logloss: 1.92414\n",
            "[38]\tvalid_0's multi_logloss: 1.9196\n",
            "[39]\tvalid_0's multi_logloss: 1.91481\n",
            "[40]\tvalid_0's multi_logloss: 1.91055\n",
            "[41]\tvalid_0's multi_logloss: 1.90595\n",
            "[42]\tvalid_0's multi_logloss: 1.90131\n",
            "[43]\tvalid_0's multi_logloss: 1.89708\n",
            "[44]\tvalid_0's multi_logloss: 1.89263\n",
            "[45]\tvalid_0's multi_logloss: 1.88854\n",
            "[46]\tvalid_0's multi_logloss: 1.8841\n",
            "[47]\tvalid_0's multi_logloss: 1.87987\n",
            "[48]\tvalid_0's multi_logloss: 1.87575\n",
            "[49]\tvalid_0's multi_logloss: 1.87162\n",
            "[50]\tvalid_0's multi_logloss: 1.86749\n",
            "[51]\tvalid_0's multi_logloss: 1.86359\n",
            "[52]\tvalid_0's multi_logloss: 1.85973\n",
            "[53]\tvalid_0's multi_logloss: 1.85582\n",
            "[54]\tvalid_0's multi_logloss: 1.85197\n",
            "[55]\tvalid_0's multi_logloss: 1.84797\n",
            "[56]\tvalid_0's multi_logloss: 1.84427\n",
            "[57]\tvalid_0's multi_logloss: 1.84056\n",
            "[58]\tvalid_0's multi_logloss: 1.83689\n",
            "[59]\tvalid_0's multi_logloss: 1.8332\n",
            "[60]\tvalid_0's multi_logloss: 1.82956\n",
            "[61]\tvalid_0's multi_logloss: 1.82588\n",
            "[62]\tvalid_0's multi_logloss: 1.82239\n",
            "[63]\tvalid_0's multi_logloss: 1.81889\n",
            "[64]\tvalid_0's multi_logloss: 1.81538\n",
            "[65]\tvalid_0's multi_logloss: 1.81205\n",
            "[66]\tvalid_0's multi_logloss: 1.80852\n",
            "[67]\tvalid_0's multi_logloss: 1.80514\n",
            "[68]\tvalid_0's multi_logloss: 1.80165\n",
            "[69]\tvalid_0's multi_logloss: 1.79856\n",
            "[70]\tvalid_0's multi_logloss: 1.79536\n",
            "[71]\tvalid_0's multi_logloss: 1.79193\n",
            "[72]\tvalid_0's multi_logloss: 1.78885\n",
            "[73]\tvalid_0's multi_logloss: 1.78556\n",
            "[74]\tvalid_0's multi_logloss: 1.78253\n",
            "[75]\tvalid_0's multi_logloss: 1.77948\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 2.16299\n",
            "[2]\tvalid_0's multi_logloss: 2.15312\n",
            "[3]\tvalid_0's multi_logloss: 2.14357\n",
            "[4]\tvalid_0's multi_logloss: 2.13455\n",
            "[5]\tvalid_0's multi_logloss: 2.12573\n",
            "[6]\tvalid_0's multi_logloss: 2.117\n",
            "[7]\tvalid_0's multi_logloss: 2.10846\n",
            "[8]\tvalid_0's multi_logloss: 2.10034\n",
            "[9]\tvalid_0's multi_logloss: 2.09234\n",
            "[10]\tvalid_0's multi_logloss: 2.08458\n",
            "[11]\tvalid_0's multi_logloss: 2.07688\n",
            "[12]\tvalid_0's multi_logloss: 2.06984\n",
            "[13]\tvalid_0's multi_logloss: 2.06251\n",
            "[14]\tvalid_0's multi_logloss: 2.05529\n",
            "[15]\tvalid_0's multi_logloss: 2.04862\n",
            "[16]\tvalid_0's multi_logloss: 2.04215\n",
            "[17]\tvalid_0's multi_logloss: 2.03566\n",
            "[18]\tvalid_0's multi_logloss: 2.02926\n",
            "[19]\tvalid_0's multi_logloss: 2.02325\n",
            "[20]\tvalid_0's multi_logloss: 2.01698\n",
            "[21]\tvalid_0's multi_logloss: 2.01114\n",
            "[22]\tvalid_0's multi_logloss: 2.00557\n",
            "[23]\tvalid_0's multi_logloss: 1.99975\n",
            "[24]\tvalid_0's multi_logloss: 1.9941\n",
            "[25]\tvalid_0's multi_logloss: 1.98868\n",
            "[26]\tvalid_0's multi_logloss: 1.98326\n",
            "[27]\tvalid_0's multi_logloss: 1.97775\n",
            "[28]\tvalid_0's multi_logloss: 1.9724\n",
            "[29]\tvalid_0's multi_logloss: 1.9674\n",
            "[30]\tvalid_0's multi_logloss: 1.96207\n",
            "[31]\tvalid_0's multi_logloss: 1.95693\n",
            "[32]\tvalid_0's multi_logloss: 1.95198\n",
            "[33]\tvalid_0's multi_logloss: 1.94709\n",
            "[34]\tvalid_0's multi_logloss: 1.9421\n",
            "[35]\tvalid_0's multi_logloss: 1.93742\n",
            "[36]\tvalid_0's multi_logloss: 1.9327\n",
            "[37]\tvalid_0's multi_logloss: 1.92786\n",
            "[38]\tvalid_0's multi_logloss: 1.92347\n",
            "[39]\tvalid_0's multi_logloss: 1.91901\n",
            "[40]\tvalid_0's multi_logloss: 1.91449\n",
            "[41]\tvalid_0's multi_logloss: 1.91028\n",
            "[42]\tvalid_0's multi_logloss: 1.90585\n",
            "[43]\tvalid_0's multi_logloss: 1.90139\n",
            "[44]\tvalid_0's multi_logloss: 1.89723\n",
            "[45]\tvalid_0's multi_logloss: 1.89294\n",
            "[46]\tvalid_0's multi_logloss: 1.88867\n",
            "[47]\tvalid_0's multi_logloss: 1.88456\n",
            "[48]\tvalid_0's multi_logloss: 1.88039\n",
            "[49]\tvalid_0's multi_logloss: 1.8763\n",
            "[50]\tvalid_0's multi_logloss: 1.87237\n",
            "[51]\tvalid_0's multi_logloss: 1.86837\n",
            "[52]\tvalid_0's multi_logloss: 1.86425\n",
            "[53]\tvalid_0's multi_logloss: 1.86032\n",
            "[54]\tvalid_0's multi_logloss: 1.85632\n",
            "[55]\tvalid_0's multi_logloss: 1.85246\n",
            "[56]\tvalid_0's multi_logloss: 1.84868\n",
            "[57]\tvalid_0's multi_logloss: 1.84505\n",
            "[58]\tvalid_0's multi_logloss: 1.84117\n",
            "[59]\tvalid_0's multi_logloss: 1.83782\n",
            "[60]\tvalid_0's multi_logloss: 1.83421\n",
            "[61]\tvalid_0's multi_logloss: 1.83056\n",
            "[62]\tvalid_0's multi_logloss: 1.82711\n",
            "[63]\tvalid_0's multi_logloss: 1.82364\n",
            "[64]\tvalid_0's multi_logloss: 1.81992\n",
            "[65]\tvalid_0's multi_logloss: 1.81642\n",
            "[66]\tvalid_0's multi_logloss: 1.81308\n",
            "[67]\tvalid_0's multi_logloss: 1.80971\n",
            "[68]\tvalid_0's multi_logloss: 1.80634\n",
            "[69]\tvalid_0's multi_logloss: 1.80302\n",
            "[70]\tvalid_0's multi_logloss: 1.79985\n",
            "[71]\tvalid_0's multi_logloss: 1.79659\n",
            "[72]\tvalid_0's multi_logloss: 1.79347\n",
            "[73]\tvalid_0's multi_logloss: 1.79031\n",
            "[74]\tvalid_0's multi_logloss: 1.78709\n",
            "[75]\tvalid_0's multi_logloss: 1.78392\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 2.16257\n",
            "[2]\tvalid_0's multi_logloss: 2.1524\n",
            "[3]\tvalid_0's multi_logloss: 2.14288\n",
            "[4]\tvalid_0's multi_logloss: 2.1334\n",
            "[5]\tvalid_0's multi_logloss: 2.12426\n",
            "[6]\tvalid_0's multi_logloss: 2.11565\n",
            "[7]\tvalid_0's multi_logloss: 2.10706\n",
            "[8]\tvalid_0's multi_logloss: 2.09891\n",
            "[9]\tvalid_0's multi_logloss: 2.09084\n",
            "[10]\tvalid_0's multi_logloss: 2.08301\n",
            "[11]\tvalid_0's multi_logloss: 2.0755\n",
            "[12]\tvalid_0's multi_logloss: 2.068\n",
            "[13]\tvalid_0's multi_logloss: 2.06091\n",
            "[14]\tvalid_0's multi_logloss: 2.05396\n",
            "[15]\tvalid_0's multi_logloss: 2.04725\n",
            "[16]\tvalid_0's multi_logloss: 2.04071\n",
            "[17]\tvalid_0's multi_logloss: 2.03398\n",
            "[18]\tvalid_0's multi_logloss: 2.02755\n",
            "[19]\tvalid_0's multi_logloss: 2.02142\n",
            "[20]\tvalid_0's multi_logloss: 2.01513\n",
            "[21]\tvalid_0's multi_logloss: 2.00879\n",
            "[22]\tvalid_0's multi_logloss: 2.00306\n",
            "[23]\tvalid_0's multi_logloss: 1.99722\n",
            "[24]\tvalid_0's multi_logloss: 1.99139\n",
            "[25]\tvalid_0's multi_logloss: 1.98596\n",
            "[26]\tvalid_0's multi_logloss: 1.98039\n",
            "[27]\tvalid_0's multi_logloss: 1.97483\n",
            "[28]\tvalid_0's multi_logloss: 1.96952\n",
            "[29]\tvalid_0's multi_logloss: 1.96396\n",
            "[30]\tvalid_0's multi_logloss: 1.95867\n",
            "[31]\tvalid_0's multi_logloss: 1.95365\n",
            "[32]\tvalid_0's multi_logloss: 1.94849\n",
            "[33]\tvalid_0's multi_logloss: 1.94337\n",
            "[34]\tvalid_0's multi_logloss: 1.93839\n",
            "[35]\tvalid_0's multi_logloss: 1.93322\n",
            "[36]\tvalid_0's multi_logloss: 1.92859\n",
            "[37]\tvalid_0's multi_logloss: 1.92355\n",
            "[38]\tvalid_0's multi_logloss: 1.91892\n",
            "[39]\tvalid_0's multi_logloss: 1.91424\n",
            "[40]\tvalid_0's multi_logloss: 1.90979\n",
            "[41]\tvalid_0's multi_logloss: 1.90525\n",
            "[42]\tvalid_0's multi_logloss: 1.90083\n",
            "[43]\tvalid_0's multi_logloss: 1.8965\n",
            "[44]\tvalid_0's multi_logloss: 1.89205\n",
            "[45]\tvalid_0's multi_logloss: 1.88794\n",
            "[46]\tvalid_0's multi_logloss: 1.8837\n",
            "[47]\tvalid_0's multi_logloss: 1.87951\n",
            "[48]\tvalid_0's multi_logloss: 1.87526\n",
            "[49]\tvalid_0's multi_logloss: 1.8713\n",
            "[50]\tvalid_0's multi_logloss: 1.8673\n",
            "[51]\tvalid_0's multi_logloss: 1.86345\n",
            "[52]\tvalid_0's multi_logloss: 1.85958\n",
            "[53]\tvalid_0's multi_logloss: 1.85564\n",
            "[54]\tvalid_0's multi_logloss: 1.8519\n",
            "[55]\tvalid_0's multi_logloss: 1.84822\n",
            "[56]\tvalid_0's multi_logloss: 1.8445\n",
            "[57]\tvalid_0's multi_logloss: 1.84084\n",
            "[58]\tvalid_0's multi_logloss: 1.83712\n",
            "[59]\tvalid_0's multi_logloss: 1.83328\n",
            "[60]\tvalid_0's multi_logloss: 1.82987\n",
            "[61]\tvalid_0's multi_logloss: 1.82621\n",
            "[62]\tvalid_0's multi_logloss: 1.82257\n",
            "[63]\tvalid_0's multi_logloss: 1.81902\n",
            "[64]\tvalid_0's multi_logloss: 1.81559\n",
            "[65]\tvalid_0's multi_logloss: 1.81233\n",
            "[66]\tvalid_0's multi_logloss: 1.80888\n",
            "[67]\tvalid_0's multi_logloss: 1.80558\n",
            "[68]\tvalid_0's multi_logloss: 1.80223\n",
            "[69]\tvalid_0's multi_logloss: 1.79916\n",
            "[70]\tvalid_0's multi_logloss: 1.79586\n",
            "[71]\tvalid_0's multi_logloss: 1.79247\n",
            "[72]\tvalid_0's multi_logloss: 1.78927\n",
            "[73]\tvalid_0's multi_logloss: 1.78609\n",
            "[74]\tvalid_0's multi_logloss: 1.7829\n",
            "[75]\tvalid_0's multi_logloss: 1.78\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 2.16266\n",
            "[2]\tvalid_0's multi_logloss: 2.1523\n",
            "[3]\tvalid_0's multi_logloss: 2.14265\n",
            "[4]\tvalid_0's multi_logloss: 2.13325\n",
            "[5]\tvalid_0's multi_logloss: 2.12434\n",
            "[6]\tvalid_0's multi_logloss: 2.11565\n",
            "[7]\tvalid_0's multi_logloss: 2.10712\n",
            "[8]\tvalid_0's multi_logloss: 2.09882\n",
            "[9]\tvalid_0's multi_logloss: 2.09084\n",
            "[10]\tvalid_0's multi_logloss: 2.08308\n",
            "[11]\tvalid_0's multi_logloss: 2.07572\n",
            "[12]\tvalid_0's multi_logloss: 2.06853\n",
            "[13]\tvalid_0's multi_logloss: 2.06157\n",
            "[14]\tvalid_0's multi_logloss: 2.05454\n",
            "[15]\tvalid_0's multi_logloss: 2.04785\n",
            "[16]\tvalid_0's multi_logloss: 2.04144\n",
            "[17]\tvalid_0's multi_logloss: 2.03493\n",
            "[18]\tvalid_0's multi_logloss: 2.02877\n",
            "[19]\tvalid_0's multi_logloss: 2.02273\n",
            "[20]\tvalid_0's multi_logloss: 2.01681\n",
            "[21]\tvalid_0's multi_logloss: 2.01096\n",
            "[22]\tvalid_0's multi_logloss: 2.00508\n",
            "[23]\tvalid_0's multi_logloss: 1.99955\n",
            "[24]\tvalid_0's multi_logloss: 1.99401\n",
            "[25]\tvalid_0's multi_logloss: 1.98836\n",
            "[26]\tvalid_0's multi_logloss: 1.98302\n",
            "[27]\tvalid_0's multi_logloss: 1.97776\n",
            "[28]\tvalid_0's multi_logloss: 1.97248\n",
            "[29]\tvalid_0's multi_logloss: 1.96749\n",
            "[30]\tvalid_0's multi_logloss: 1.96212\n",
            "[31]\tvalid_0's multi_logloss: 1.95705\n",
            "[32]\tvalid_0's multi_logloss: 1.95234\n",
            "[33]\tvalid_0's multi_logloss: 1.94733\n",
            "[34]\tvalid_0's multi_logloss: 1.94244\n",
            "[35]\tvalid_0's multi_logloss: 1.93771\n",
            "[36]\tvalid_0's multi_logloss: 1.93285\n",
            "[37]\tvalid_0's multi_logloss: 1.92812\n",
            "[38]\tvalid_0's multi_logloss: 1.92328\n",
            "[39]\tvalid_0's multi_logloss: 1.91877\n",
            "[40]\tvalid_0's multi_logloss: 1.91428\n",
            "[41]\tvalid_0's multi_logloss: 1.90946\n",
            "[42]\tvalid_0's multi_logloss: 1.90493\n",
            "[43]\tvalid_0's multi_logloss: 1.9006\n",
            "[44]\tvalid_0's multi_logloss: 1.89612\n",
            "[45]\tvalid_0's multi_logloss: 1.89193\n",
            "[46]\tvalid_0's multi_logloss: 1.88748\n",
            "[47]\tvalid_0's multi_logloss: 1.88348\n",
            "[48]\tvalid_0's multi_logloss: 1.87951\n",
            "[49]\tvalid_0's multi_logloss: 1.87533\n",
            "[50]\tvalid_0's multi_logloss: 1.87131\n",
            "[51]\tvalid_0's multi_logloss: 1.86753\n",
            "[52]\tvalid_0's multi_logloss: 1.86371\n",
            "[53]\tvalid_0's multi_logloss: 1.85984\n",
            "[54]\tvalid_0's multi_logloss: 1.85599\n",
            "[55]\tvalid_0's multi_logloss: 1.85222\n",
            "[56]\tvalid_0's multi_logloss: 1.84849\n",
            "[57]\tvalid_0's multi_logloss: 1.84477\n",
            "[58]\tvalid_0's multi_logloss: 1.84114\n",
            "[59]\tvalid_0's multi_logloss: 1.83747\n",
            "[60]\tvalid_0's multi_logloss: 1.83397\n",
            "[61]\tvalid_0's multi_logloss: 1.83021\n",
            "[62]\tvalid_0's multi_logloss: 1.82668\n",
            "[63]\tvalid_0's multi_logloss: 1.82327\n",
            "[64]\tvalid_0's multi_logloss: 1.81967\n",
            "[65]\tvalid_0's multi_logloss: 1.81617\n",
            "[66]\tvalid_0's multi_logloss: 1.81271\n",
            "[67]\tvalid_0's multi_logloss: 1.80934\n",
            "[68]\tvalid_0's multi_logloss: 1.80593\n",
            "[69]\tvalid_0's multi_logloss: 1.80266\n",
            "[70]\tvalid_0's multi_logloss: 1.79935\n",
            "[71]\tvalid_0's multi_logloss: 1.79604\n",
            "[72]\tvalid_0's multi_logloss: 1.79275\n",
            "[73]\tvalid_0's multi_logloss: 1.78958\n",
            "[74]\tvalid_0's multi_logloss: 1.78645\n",
            "[75]\tvalid_0's multi_logloss: 1.7831\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 2.15945\n",
            "[2]\tvalid_0's multi_logloss: 2.14654\n",
            "[3]\tvalid_0's multi_logloss: 2.13412\n",
            "[4]\tvalid_0's multi_logloss: 2.12222\n",
            "[5]\tvalid_0's multi_logloss: 2.11113\n",
            "[6]\tvalid_0's multi_logloss: 2.09969\n",
            "[7]\tvalid_0's multi_logloss: 2.08905\n",
            "[8]\tvalid_0's multi_logloss: 2.07851\n",
            "[9]\tvalid_0's multi_logloss: 2.06826\n",
            "[10]\tvalid_0's multi_logloss: 2.05834\n",
            "[11]\tvalid_0's multi_logloss: 2.04861\n",
            "[12]\tvalid_0's multi_logloss: 2.03929\n",
            "[13]\tvalid_0's multi_logloss: 2.02998\n",
            "[14]\tvalid_0's multi_logloss: 2.02139\n",
            "[15]\tvalid_0's multi_logloss: 2.01282\n",
            "[16]\tvalid_0's multi_logloss: 2.00419\n",
            "[17]\tvalid_0's multi_logloss: 1.99593\n",
            "[18]\tvalid_0's multi_logloss: 1.98784\n",
            "[19]\tvalid_0's multi_logloss: 1.98002\n",
            "[20]\tvalid_0's multi_logloss: 1.97226\n",
            "[21]\tvalid_0's multi_logloss: 1.96481\n",
            "[22]\tvalid_0's multi_logloss: 1.95739\n",
            "[23]\tvalid_0's multi_logloss: 1.95007\n",
            "[24]\tvalid_0's multi_logloss: 1.9431\n",
            "[25]\tvalid_0's multi_logloss: 1.93605\n",
            "[26]\tvalid_0's multi_logloss: 1.92939\n",
            "[27]\tvalid_0's multi_logloss: 1.92276\n",
            "[28]\tvalid_0's multi_logloss: 1.91601\n",
            "[29]\tvalid_0's multi_logloss: 1.90972\n",
            "[30]\tvalid_0's multi_logloss: 1.90354\n",
            "[31]\tvalid_0's multi_logloss: 1.89705\n",
            "[32]\tvalid_0's multi_logloss: 1.89093\n",
            "[33]\tvalid_0's multi_logloss: 1.88481\n",
            "[34]\tvalid_0's multi_logloss: 1.8786\n",
            "[35]\tvalid_0's multi_logloss: 1.87274\n",
            "[36]\tvalid_0's multi_logloss: 1.86692\n",
            "[37]\tvalid_0's multi_logloss: 1.86088\n",
            "[38]\tvalid_0's multi_logloss: 1.85528\n",
            "[39]\tvalid_0's multi_logloss: 1.8498\n",
            "[40]\tvalid_0's multi_logloss: 1.84439\n",
            "[41]\tvalid_0's multi_logloss: 1.83904\n",
            "[42]\tvalid_0's multi_logloss: 1.83356\n",
            "[43]\tvalid_0's multi_logloss: 1.82838\n",
            "[44]\tvalid_0's multi_logloss: 1.82324\n",
            "[45]\tvalid_0's multi_logloss: 1.81814\n",
            "[46]\tvalid_0's multi_logloss: 1.81303\n",
            "[47]\tvalid_0's multi_logloss: 1.80814\n",
            "[48]\tvalid_0's multi_logloss: 1.80336\n",
            "[49]\tvalid_0's multi_logloss: 1.7984\n",
            "[50]\tvalid_0's multi_logloss: 1.79349\n",
            "[51]\tvalid_0's multi_logloss: 1.78879\n",
            "[52]\tvalid_0's multi_logloss: 1.7841\n",
            "[53]\tvalid_0's multi_logloss: 1.7795\n",
            "[54]\tvalid_0's multi_logloss: 1.7749\n",
            "[55]\tvalid_0's multi_logloss: 1.77053\n",
            "[56]\tvalid_0's multi_logloss: 1.7661\n",
            "[57]\tvalid_0's multi_logloss: 1.7617\n",
            "[58]\tvalid_0's multi_logloss: 1.75709\n",
            "[59]\tvalid_0's multi_logloss: 1.75301\n",
            "[60]\tvalid_0's multi_logloss: 1.74866\n",
            "[61]\tvalid_0's multi_logloss: 1.74444\n",
            "[62]\tvalid_0's multi_logloss: 1.74056\n",
            "[63]\tvalid_0's multi_logloss: 1.73643\n",
            "[64]\tvalid_0's multi_logloss: 1.7325\n",
            "[65]\tvalid_0's multi_logloss: 1.72854\n",
            "[66]\tvalid_0's multi_logloss: 1.72467\n",
            "[67]\tvalid_0's multi_logloss: 1.72071\n",
            "[68]\tvalid_0's multi_logloss: 1.71696\n",
            "[69]\tvalid_0's multi_logloss: 1.7132\n",
            "[70]\tvalid_0's multi_logloss: 1.7092\n",
            "[71]\tvalid_0's multi_logloss: 1.70554\n",
            "[72]\tvalid_0's multi_logloss: 1.7018\n",
            "[73]\tvalid_0's multi_logloss: 1.69813\n",
            "[74]\tvalid_0's multi_logloss: 1.69452\n",
            "[75]\tvalid_0's multi_logloss: 1.69095\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 2.15954\n",
            "[2]\tvalid_0's multi_logloss: 2.1463\n",
            "[3]\tvalid_0's multi_logloss: 2.13383\n",
            "[4]\tvalid_0's multi_logloss: 2.12194\n",
            "[5]\tvalid_0's multi_logloss: 2.11015\n",
            "[6]\tvalid_0's multi_logloss: 2.09885\n",
            "[7]\tvalid_0's multi_logloss: 2.08792\n",
            "[8]\tvalid_0's multi_logloss: 2.07744\n",
            "[9]\tvalid_0's multi_logloss: 2.06708\n",
            "[10]\tvalid_0's multi_logloss: 2.05707\n",
            "[11]\tvalid_0's multi_logloss: 2.04755\n",
            "[12]\tvalid_0's multi_logloss: 2.03821\n",
            "[13]\tvalid_0's multi_logloss: 2.0291\n",
            "[14]\tvalid_0's multi_logloss: 2.02029\n",
            "[15]\tvalid_0's multi_logloss: 2.01197\n",
            "[16]\tvalid_0's multi_logloss: 2.00363\n",
            "[17]\tvalid_0's multi_logloss: 1.99548\n",
            "[18]\tvalid_0's multi_logloss: 1.98761\n",
            "[19]\tvalid_0's multi_logloss: 1.97987\n",
            "[20]\tvalid_0's multi_logloss: 1.97225\n",
            "[21]\tvalid_0's multi_logloss: 1.96485\n",
            "[22]\tvalid_0's multi_logloss: 1.95755\n",
            "[23]\tvalid_0's multi_logloss: 1.95042\n",
            "[24]\tvalid_0's multi_logloss: 1.94334\n",
            "[25]\tvalid_0's multi_logloss: 1.93635\n",
            "[26]\tvalid_0's multi_logloss: 1.92944\n",
            "[27]\tvalid_0's multi_logloss: 1.92296\n",
            "[28]\tvalid_0's multi_logloss: 1.91644\n",
            "[29]\tvalid_0's multi_logloss: 1.90974\n",
            "[30]\tvalid_0's multi_logloss: 1.9033\n",
            "[31]\tvalid_0's multi_logloss: 1.89714\n",
            "[32]\tvalid_0's multi_logloss: 1.89058\n",
            "[33]\tvalid_0's multi_logloss: 1.8845\n",
            "[34]\tvalid_0's multi_logloss: 1.8783\n",
            "[35]\tvalid_0's multi_logloss: 1.87228\n",
            "[36]\tvalid_0's multi_logloss: 1.86639\n",
            "[37]\tvalid_0's multi_logloss: 1.86058\n",
            "[38]\tvalid_0's multi_logloss: 1.8549\n",
            "[39]\tvalid_0's multi_logloss: 1.84912\n",
            "[40]\tvalid_0's multi_logloss: 1.8435\n",
            "[41]\tvalid_0's multi_logloss: 1.83791\n",
            "[42]\tvalid_0's multi_logloss: 1.83246\n",
            "[43]\tvalid_0's multi_logloss: 1.82706\n",
            "[44]\tvalid_0's multi_logloss: 1.82192\n",
            "[45]\tvalid_0's multi_logloss: 1.81683\n",
            "[46]\tvalid_0's multi_logloss: 1.81151\n",
            "[47]\tvalid_0's multi_logloss: 1.80648\n",
            "[48]\tvalid_0's multi_logloss: 1.80137\n",
            "[49]\tvalid_0's multi_logloss: 1.79633\n",
            "[50]\tvalid_0's multi_logloss: 1.79165\n",
            "[51]\tvalid_0's multi_logloss: 1.78691\n",
            "[52]\tvalid_0's multi_logloss: 1.78238\n",
            "[53]\tvalid_0's multi_logloss: 1.77772\n",
            "[54]\tvalid_0's multi_logloss: 1.77319\n",
            "[55]\tvalid_0's multi_logloss: 1.76867\n",
            "[56]\tvalid_0's multi_logloss: 1.76419\n",
            "[57]\tvalid_0's multi_logloss: 1.75979\n",
            "[58]\tvalid_0's multi_logloss: 1.75534\n",
            "[59]\tvalid_0's multi_logloss: 1.75105\n",
            "[60]\tvalid_0's multi_logloss: 1.74682\n",
            "[61]\tvalid_0's multi_logloss: 1.74263\n",
            "[62]\tvalid_0's multi_logloss: 1.73862\n",
            "[63]\tvalid_0's multi_logloss: 1.73429\n",
            "[64]\tvalid_0's multi_logloss: 1.73007\n",
            "[65]\tvalid_0's multi_logloss: 1.72613\n",
            "[66]\tvalid_0's multi_logloss: 1.72218\n",
            "[67]\tvalid_0's multi_logloss: 1.71824\n",
            "[68]\tvalid_0's multi_logloss: 1.7144\n",
            "[69]\tvalid_0's multi_logloss: 1.71057\n",
            "[70]\tvalid_0's multi_logloss: 1.70657\n",
            "[71]\tvalid_0's multi_logloss: 1.70276\n",
            "[72]\tvalid_0's multi_logloss: 1.69896\n",
            "[73]\tvalid_0's multi_logloss: 1.6954\n",
            "[74]\tvalid_0's multi_logloss: 1.6918\n",
            "[75]\tvalid_0's multi_logloss: 1.6882\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 2.16001\n",
            "[2]\tvalid_0's multi_logloss: 2.14711\n",
            "[3]\tvalid_0's multi_logloss: 2.13461\n",
            "[4]\tvalid_0's multi_logloss: 2.12268\n",
            "[5]\tvalid_0's multi_logloss: 2.11076\n",
            "[6]\tvalid_0's multi_logloss: 2.09953\n",
            "[7]\tvalid_0's multi_logloss: 2.08829\n",
            "[8]\tvalid_0's multi_logloss: 2.07766\n",
            "[9]\tvalid_0's multi_logloss: 2.06735\n",
            "[10]\tvalid_0's multi_logloss: 2.05713\n",
            "[11]\tvalid_0's multi_logloss: 2.04747\n",
            "[12]\tvalid_0's multi_logloss: 2.03789\n",
            "[13]\tvalid_0's multi_logloss: 2.0287\n",
            "[14]\tvalid_0's multi_logloss: 2.01965\n",
            "[15]\tvalid_0's multi_logloss: 2.01106\n",
            "[16]\tvalid_0's multi_logloss: 2.00248\n",
            "[17]\tvalid_0's multi_logloss: 1.99423\n",
            "[18]\tvalid_0's multi_logloss: 1.98609\n",
            "[19]\tvalid_0's multi_logloss: 1.97836\n",
            "[20]\tvalid_0's multi_logloss: 1.97066\n",
            "[21]\tvalid_0's multi_logloss: 1.96325\n",
            "[22]\tvalid_0's multi_logloss: 1.95577\n",
            "[23]\tvalid_0's multi_logloss: 1.94865\n",
            "[24]\tvalid_0's multi_logloss: 1.94148\n",
            "[25]\tvalid_0's multi_logloss: 1.93442\n",
            "[26]\tvalid_0's multi_logloss: 1.92767\n",
            "[27]\tvalid_0's multi_logloss: 1.92089\n",
            "[28]\tvalid_0's multi_logloss: 1.91434\n",
            "[29]\tvalid_0's multi_logloss: 1.90788\n",
            "[30]\tvalid_0's multi_logloss: 1.90177\n",
            "[31]\tvalid_0's multi_logloss: 1.89553\n",
            "[32]\tvalid_0's multi_logloss: 1.88953\n",
            "[33]\tvalid_0's multi_logloss: 1.88367\n",
            "[34]\tvalid_0's multi_logloss: 1.87775\n",
            "[35]\tvalid_0's multi_logloss: 1.87206\n",
            "[36]\tvalid_0's multi_logloss: 1.86619\n",
            "[37]\tvalid_0's multi_logloss: 1.86063\n",
            "[38]\tvalid_0's multi_logloss: 1.85514\n",
            "[39]\tvalid_0's multi_logloss: 1.84978\n",
            "[40]\tvalid_0's multi_logloss: 1.8445\n",
            "[41]\tvalid_0's multi_logloss: 1.83925\n",
            "[42]\tvalid_0's multi_logloss: 1.83397\n",
            "[43]\tvalid_0's multi_logloss: 1.82882\n",
            "[44]\tvalid_0's multi_logloss: 1.82376\n",
            "[45]\tvalid_0's multi_logloss: 1.81864\n",
            "[46]\tvalid_0's multi_logloss: 1.81355\n",
            "[47]\tvalid_0's multi_logloss: 1.80876\n",
            "[48]\tvalid_0's multi_logloss: 1.80379\n",
            "[49]\tvalid_0's multi_logloss: 1.79892\n",
            "[50]\tvalid_0's multi_logloss: 1.79416\n",
            "[51]\tvalid_0's multi_logloss: 1.7894\n",
            "[52]\tvalid_0's multi_logloss: 1.78477\n",
            "[53]\tvalid_0's multi_logloss: 1.7802\n",
            "[54]\tvalid_0's multi_logloss: 1.77578\n",
            "[55]\tvalid_0's multi_logloss: 1.77124\n",
            "[56]\tvalid_0's multi_logloss: 1.76686\n",
            "[57]\tvalid_0's multi_logloss: 1.76252\n",
            "[58]\tvalid_0's multi_logloss: 1.75824\n",
            "[59]\tvalid_0's multi_logloss: 1.75391\n",
            "[60]\tvalid_0's multi_logloss: 1.74971\n",
            "[61]\tvalid_0's multi_logloss: 1.7455\n",
            "[62]\tvalid_0's multi_logloss: 1.74145\n",
            "[63]\tvalid_0's multi_logloss: 1.73747\n",
            "[64]\tvalid_0's multi_logloss: 1.73342\n",
            "[65]\tvalid_0's multi_logloss: 1.72953\n",
            "[66]\tvalid_0's multi_logloss: 1.72551\n",
            "[67]\tvalid_0's multi_logloss: 1.72168\n",
            "[68]\tvalid_0's multi_logloss: 1.71769\n",
            "[69]\tvalid_0's multi_logloss: 1.71386\n",
            "[70]\tvalid_0's multi_logloss: 1.71012\n",
            "[71]\tvalid_0's multi_logloss: 1.70637\n",
            "[72]\tvalid_0's multi_logloss: 1.70271\n",
            "[73]\tvalid_0's multi_logloss: 1.69912\n",
            "[74]\tvalid_0's multi_logloss: 1.69552\n",
            "[75]\tvalid_0's multi_logloss: 1.692\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 2.15931\n",
            "[2]\tvalid_0's multi_logloss: 2.14577\n",
            "[3]\tvalid_0's multi_logloss: 2.13305\n",
            "[4]\tvalid_0's multi_logloss: 2.12105\n",
            "[5]\tvalid_0's multi_logloss: 2.10955\n",
            "[6]\tvalid_0's multi_logloss: 2.09812\n",
            "[7]\tvalid_0's multi_logloss: 2.08724\n",
            "[8]\tvalid_0's multi_logloss: 2.07675\n",
            "[9]\tvalid_0's multi_logloss: 2.06661\n",
            "[10]\tvalid_0's multi_logloss: 2.05645\n",
            "[11]\tvalid_0's multi_logloss: 2.04659\n",
            "[12]\tvalid_0's multi_logloss: 2.03744\n",
            "[13]\tvalid_0's multi_logloss: 2.02824\n",
            "[14]\tvalid_0's multi_logloss: 2.0194\n",
            "[15]\tvalid_0's multi_logloss: 2.01064\n",
            "[16]\tvalid_0's multi_logloss: 2.00222\n",
            "[17]\tvalid_0's multi_logloss: 1.99388\n",
            "[18]\tvalid_0's multi_logloss: 1.98561\n",
            "[19]\tvalid_0's multi_logloss: 1.97754\n",
            "[20]\tvalid_0's multi_logloss: 1.96955\n",
            "[21]\tvalid_0's multi_logloss: 1.96211\n",
            "[22]\tvalid_0's multi_logloss: 1.95439\n",
            "[23]\tvalid_0's multi_logloss: 1.94696\n",
            "[24]\tvalid_0's multi_logloss: 1.93983\n",
            "[25]\tvalid_0's multi_logloss: 1.93271\n",
            "[26]\tvalid_0's multi_logloss: 1.92597\n",
            "[27]\tvalid_0's multi_logloss: 1.91896\n",
            "[28]\tvalid_0's multi_logloss: 1.91247\n",
            "[29]\tvalid_0's multi_logloss: 1.90614\n",
            "[30]\tvalid_0's multi_logloss: 1.89971\n",
            "[31]\tvalid_0's multi_logloss: 1.89346\n",
            "[32]\tvalid_0's multi_logloss: 1.88764\n",
            "[33]\tvalid_0's multi_logloss: 1.88147\n",
            "[34]\tvalid_0's multi_logloss: 1.87539\n",
            "[35]\tvalid_0's multi_logloss: 1.86938\n",
            "[36]\tvalid_0's multi_logloss: 1.86332\n",
            "[37]\tvalid_0's multi_logloss: 1.8576\n",
            "[38]\tvalid_0's multi_logloss: 1.85185\n",
            "[39]\tvalid_0's multi_logloss: 1.84626\n",
            "[40]\tvalid_0's multi_logloss: 1.84078\n",
            "[41]\tvalid_0's multi_logloss: 1.83527\n",
            "[42]\tvalid_0's multi_logloss: 1.82998\n",
            "[43]\tvalid_0's multi_logloss: 1.82469\n",
            "[44]\tvalid_0's multi_logloss: 1.81951\n",
            "[45]\tvalid_0's multi_logloss: 1.81414\n",
            "[46]\tvalid_0's multi_logloss: 1.80928\n",
            "[47]\tvalid_0's multi_logloss: 1.80409\n",
            "[48]\tvalid_0's multi_logloss: 1.79912\n",
            "[49]\tvalid_0's multi_logloss: 1.7941\n",
            "[50]\tvalid_0's multi_logloss: 1.78918\n",
            "[51]\tvalid_0's multi_logloss: 1.78446\n",
            "[52]\tvalid_0's multi_logloss: 1.77962\n",
            "[53]\tvalid_0's multi_logloss: 1.77508\n",
            "[54]\tvalid_0's multi_logloss: 1.77053\n",
            "[55]\tvalid_0's multi_logloss: 1.7659\n",
            "[56]\tvalid_0's multi_logloss: 1.76137\n",
            "[57]\tvalid_0's multi_logloss: 1.75716\n",
            "[58]\tvalid_0's multi_logloss: 1.75279\n",
            "[59]\tvalid_0's multi_logloss: 1.74842\n",
            "[60]\tvalid_0's multi_logloss: 1.74432\n",
            "[61]\tvalid_0's multi_logloss: 1.74016\n",
            "[62]\tvalid_0's multi_logloss: 1.73623\n",
            "[63]\tvalid_0's multi_logloss: 1.73204\n",
            "[64]\tvalid_0's multi_logloss: 1.72807\n",
            "[65]\tvalid_0's multi_logloss: 1.72419\n",
            "[66]\tvalid_0's multi_logloss: 1.7203\n",
            "[67]\tvalid_0's multi_logloss: 1.71641\n",
            "[68]\tvalid_0's multi_logloss: 1.71258\n",
            "[69]\tvalid_0's multi_logloss: 1.70875\n",
            "[70]\tvalid_0's multi_logloss: 1.70509\n",
            "[71]\tvalid_0's multi_logloss: 1.70142\n",
            "[72]\tvalid_0's multi_logloss: 1.69792\n",
            "[73]\tvalid_0's multi_logloss: 1.69419\n",
            "[74]\tvalid_0's multi_logloss: 1.69063\n",
            "[75]\tvalid_0's multi_logloss: 1.68698\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 2.15951\n",
            "[2]\tvalid_0's multi_logloss: 2.14627\n",
            "[3]\tvalid_0's multi_logloss: 2.13384\n",
            "[4]\tvalid_0's multi_logloss: 2.12183\n",
            "[5]\tvalid_0's multi_logloss: 2.11033\n",
            "[6]\tvalid_0's multi_logloss: 2.0992\n",
            "[7]\tvalid_0's multi_logloss: 2.08844\n",
            "[8]\tvalid_0's multi_logloss: 2.07821\n",
            "[9]\tvalid_0's multi_logloss: 2.068\n",
            "[10]\tvalid_0's multi_logloss: 2.05824\n",
            "[11]\tvalid_0's multi_logloss: 2.04879\n",
            "[12]\tvalid_0's multi_logloss: 2.03966\n",
            "[13]\tvalid_0's multi_logloss: 2.03071\n",
            "[14]\tvalid_0's multi_logloss: 2.02196\n",
            "[15]\tvalid_0's multi_logloss: 2.01361\n",
            "[16]\tvalid_0's multi_logloss: 2.00536\n",
            "[17]\tvalid_0's multi_logloss: 1.99741\n",
            "[18]\tvalid_0's multi_logloss: 1.98958\n",
            "[19]\tvalid_0's multi_logloss: 1.98184\n",
            "[20]\tvalid_0's multi_logloss: 1.97452\n",
            "[21]\tvalid_0's multi_logloss: 1.96717\n",
            "[22]\tvalid_0's multi_logloss: 1.9597\n",
            "[23]\tvalid_0's multi_logloss: 1.95284\n",
            "[24]\tvalid_0's multi_logloss: 1.94587\n",
            "[25]\tvalid_0's multi_logloss: 1.93879\n",
            "[26]\tvalid_0's multi_logloss: 1.93221\n",
            "[27]\tvalid_0's multi_logloss: 1.92551\n",
            "[28]\tvalid_0's multi_logloss: 1.91917\n",
            "[29]\tvalid_0's multi_logloss: 1.91265\n",
            "[30]\tvalid_0's multi_logloss: 1.90655\n",
            "[31]\tvalid_0's multi_logloss: 1.90014\n",
            "[32]\tvalid_0's multi_logloss: 1.89406\n",
            "[33]\tvalid_0's multi_logloss: 1.88795\n",
            "[34]\tvalid_0's multi_logloss: 1.88197\n",
            "[35]\tvalid_0's multi_logloss: 1.87622\n",
            "[36]\tvalid_0's multi_logloss: 1.87045\n",
            "[37]\tvalid_0's multi_logloss: 1.86468\n",
            "[38]\tvalid_0's multi_logloss: 1.859\n",
            "[39]\tvalid_0's multi_logloss: 1.85341\n",
            "[40]\tvalid_0's multi_logloss: 1.84795\n",
            "[41]\tvalid_0's multi_logloss: 1.84268\n",
            "[42]\tvalid_0's multi_logloss: 1.83738\n",
            "[43]\tvalid_0's multi_logloss: 1.83213\n",
            "[44]\tvalid_0's multi_logloss: 1.82698\n",
            "[45]\tvalid_0's multi_logloss: 1.82183\n",
            "[46]\tvalid_0's multi_logloss: 1.81686\n",
            "[47]\tvalid_0's multi_logloss: 1.81188\n",
            "[48]\tvalid_0's multi_logloss: 1.80689\n",
            "[49]\tvalid_0's multi_logloss: 1.80227\n",
            "[50]\tvalid_0's multi_logloss: 1.79753\n",
            "[51]\tvalid_0's multi_logloss: 1.79285\n",
            "[52]\tvalid_0's multi_logloss: 1.78814\n",
            "[53]\tvalid_0's multi_logloss: 1.78344\n",
            "[54]\tvalid_0's multi_logloss: 1.77905\n",
            "[55]\tvalid_0's multi_logloss: 1.7746\n",
            "[56]\tvalid_0's multi_logloss: 1.77027\n",
            "[57]\tvalid_0's multi_logloss: 1.76588\n",
            "[58]\tvalid_0's multi_logloss: 1.7615\n",
            "[59]\tvalid_0's multi_logloss: 1.75725\n",
            "[60]\tvalid_0's multi_logloss: 1.75313\n",
            "[61]\tvalid_0's multi_logloss: 1.74897\n",
            "[62]\tvalid_0's multi_logloss: 1.74493\n",
            "[63]\tvalid_0's multi_logloss: 1.74092\n",
            "[64]\tvalid_0's multi_logloss: 1.73692\n",
            "[65]\tvalid_0's multi_logloss: 1.73278\n",
            "[66]\tvalid_0's multi_logloss: 1.72875\n",
            "[67]\tvalid_0's multi_logloss: 1.72469\n",
            "[68]\tvalid_0's multi_logloss: 1.72084\n",
            "[69]\tvalid_0's multi_logloss: 1.717\n",
            "[70]\tvalid_0's multi_logloss: 1.71314\n",
            "[71]\tvalid_0's multi_logloss: 1.70935\n",
            "[72]\tvalid_0's multi_logloss: 1.70576\n",
            "[73]\tvalid_0's multi_logloss: 1.70206\n",
            "[74]\tvalid_0's multi_logloss: 1.69837\n",
            "[75]\tvalid_0's multi_logloss: 1.69465\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 2.16285\n",
            "[2]\tvalid_0's multi_logloss: 2.15285\n",
            "[3]\tvalid_0's multi_logloss: 2.14351\n",
            "[4]\tvalid_0's multi_logloss: 2.13435\n",
            "[5]\tvalid_0's multi_logloss: 2.12533\n",
            "[6]\tvalid_0's multi_logloss: 2.11656\n",
            "[7]\tvalid_0's multi_logloss: 2.10812\n",
            "[8]\tvalid_0's multi_logloss: 2.0998\n",
            "[9]\tvalid_0's multi_logloss: 2.09174\n",
            "[10]\tvalid_0's multi_logloss: 2.08394\n",
            "[11]\tvalid_0's multi_logloss: 2.07627\n",
            "[12]\tvalid_0's multi_logloss: 2.06916\n",
            "[13]\tvalid_0's multi_logloss: 2.06203\n",
            "[14]\tvalid_0's multi_logloss: 2.05488\n",
            "[15]\tvalid_0's multi_logloss: 2.04822\n",
            "[16]\tvalid_0's multi_logloss: 2.0416\n",
            "[17]\tvalid_0's multi_logloss: 2.035\n",
            "[18]\tvalid_0's multi_logloss: 2.02869\n",
            "[19]\tvalid_0's multi_logloss: 2.02276\n",
            "[20]\tvalid_0's multi_logloss: 2.01682\n",
            "[21]\tvalid_0's multi_logloss: 2.01078\n",
            "[22]\tvalid_0's multi_logloss: 2.00497\n",
            "[23]\tvalid_0's multi_logloss: 1.99923\n",
            "[24]\tvalid_0's multi_logloss: 1.99358\n",
            "[25]\tvalid_0's multi_logloss: 1.98776\n",
            "[26]\tvalid_0's multi_logloss: 1.98226\n",
            "[27]\tvalid_0's multi_logloss: 1.9768\n",
            "[28]\tvalid_0's multi_logloss: 1.97142\n",
            "[29]\tvalid_0's multi_logloss: 1.96601\n",
            "[30]\tvalid_0's multi_logloss: 1.96086\n",
            "[31]\tvalid_0's multi_logloss: 1.95575\n",
            "[32]\tvalid_0's multi_logloss: 1.95072\n",
            "[33]\tvalid_0's multi_logloss: 1.94586\n",
            "[34]\tvalid_0's multi_logloss: 1.94094\n",
            "[35]\tvalid_0's multi_logloss: 1.93601\n",
            "[36]\tvalid_0's multi_logloss: 1.93154\n",
            "[37]\tvalid_0's multi_logloss: 1.92669\n",
            "[38]\tvalid_0's multi_logloss: 1.92186\n",
            "[39]\tvalid_0's multi_logloss: 1.91732\n",
            "[40]\tvalid_0's multi_logloss: 1.91265\n",
            "[41]\tvalid_0's multi_logloss: 1.908\n",
            "[42]\tvalid_0's multi_logloss: 1.90363\n",
            "[43]\tvalid_0's multi_logloss: 1.8992\n",
            "[44]\tvalid_0's multi_logloss: 1.89476\n",
            "[45]\tvalid_0's multi_logloss: 1.89048\n",
            "[46]\tvalid_0's multi_logloss: 1.88611\n",
            "[47]\tvalid_0's multi_logloss: 1.88181\n",
            "[48]\tvalid_0's multi_logloss: 1.87794\n",
            "[49]\tvalid_0's multi_logloss: 1.87372\n",
            "[50]\tvalid_0's multi_logloss: 1.86974\n",
            "[51]\tvalid_0's multi_logloss: 1.86598\n",
            "[52]\tvalid_0's multi_logloss: 1.86183\n",
            "[53]\tvalid_0's multi_logloss: 1.85775\n",
            "[54]\tvalid_0's multi_logloss: 1.85422\n",
            "[55]\tvalid_0's multi_logloss: 1.85028\n",
            "[56]\tvalid_0's multi_logloss: 1.84642\n",
            "[57]\tvalid_0's multi_logloss: 1.84267\n",
            "[58]\tvalid_0's multi_logloss: 1.83904\n",
            "[59]\tvalid_0's multi_logloss: 1.83543\n",
            "[60]\tvalid_0's multi_logloss: 1.83177\n",
            "[61]\tvalid_0's multi_logloss: 1.82802\n",
            "[62]\tvalid_0's multi_logloss: 1.82458\n",
            "[63]\tvalid_0's multi_logloss: 1.82112\n",
            "[64]\tvalid_0's multi_logloss: 1.81759\n",
            "[65]\tvalid_0's multi_logloss: 1.81417\n",
            "[66]\tvalid_0's multi_logloss: 1.81063\n",
            "[67]\tvalid_0's multi_logloss: 1.80731\n",
            "[68]\tvalid_0's multi_logloss: 1.80385\n",
            "[69]\tvalid_0's multi_logloss: 1.80069\n",
            "[70]\tvalid_0's multi_logloss: 1.79745\n",
            "[71]\tvalid_0's multi_logloss: 1.79426\n",
            "[72]\tvalid_0's multi_logloss: 1.79119\n",
            "[73]\tvalid_0's multi_logloss: 1.78804\n",
            "[74]\tvalid_0's multi_logloss: 1.78505\n",
            "[75]\tvalid_0's multi_logloss: 1.7821\n",
            "[76]\tvalid_0's multi_logloss: 1.77915\n",
            "[77]\tvalid_0's multi_logloss: 1.77603\n",
            "[78]\tvalid_0's multi_logloss: 1.77306\n",
            "[79]\tvalid_0's multi_logloss: 1.77015\n",
            "[80]\tvalid_0's multi_logloss: 1.7672\n",
            "[81]\tvalid_0's multi_logloss: 1.76417\n",
            "[82]\tvalid_0's multi_logloss: 1.76129\n",
            "[83]\tvalid_0's multi_logloss: 1.75837\n",
            "[84]\tvalid_0's multi_logloss: 1.75539\n",
            "[85]\tvalid_0's multi_logloss: 1.75268\n",
            "[86]\tvalid_0's multi_logloss: 1.74996\n",
            "[87]\tvalid_0's multi_logloss: 1.74725\n",
            "[88]\tvalid_0's multi_logloss: 1.74422\n",
            "[89]\tvalid_0's multi_logloss: 1.74165\n",
            "[90]\tvalid_0's multi_logloss: 1.73886\n",
            "[91]\tvalid_0's multi_logloss: 1.7361\n",
            "[92]\tvalid_0's multi_logloss: 1.73341\n",
            "[93]\tvalid_0's multi_logloss: 1.73081\n",
            "[94]\tvalid_0's multi_logloss: 1.728\n",
            "[95]\tvalid_0's multi_logloss: 1.72539\n",
            "[96]\tvalid_0's multi_logloss: 1.7227\n",
            "[97]\tvalid_0's multi_logloss: 1.72008\n",
            "[98]\tvalid_0's multi_logloss: 1.71755\n",
            "[99]\tvalid_0's multi_logloss: 1.71497\n",
            "[100]\tvalid_0's multi_logloss: 1.71256\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 2.16266\n",
            "[2]\tvalid_0's multi_logloss: 2.15258\n",
            "[3]\tvalid_0's multi_logloss: 2.1425\n",
            "[4]\tvalid_0's multi_logloss: 2.13289\n",
            "[5]\tvalid_0's multi_logloss: 2.12382\n",
            "[6]\tvalid_0's multi_logloss: 2.11505\n",
            "[7]\tvalid_0's multi_logloss: 2.10674\n",
            "[8]\tvalid_0's multi_logloss: 2.09845\n",
            "[9]\tvalid_0's multi_logloss: 2.09041\n",
            "[10]\tvalid_0's multi_logloss: 2.08273\n",
            "[11]\tvalid_0's multi_logloss: 2.0752\n",
            "[12]\tvalid_0's multi_logloss: 2.06781\n",
            "[13]\tvalid_0's multi_logloss: 2.0608\n",
            "[14]\tvalid_0's multi_logloss: 2.05386\n",
            "[15]\tvalid_0's multi_logloss: 2.04713\n",
            "[16]\tvalid_0's multi_logloss: 2.04037\n",
            "[17]\tvalid_0's multi_logloss: 2.03394\n",
            "[18]\tvalid_0's multi_logloss: 2.0275\n",
            "[19]\tvalid_0's multi_logloss: 2.02126\n",
            "[20]\tvalid_0's multi_logloss: 2.01519\n",
            "[21]\tvalid_0's multi_logloss: 2.00892\n",
            "[22]\tvalid_0's multi_logloss: 2.00294\n",
            "[23]\tvalid_0's multi_logloss: 1.99718\n",
            "[24]\tvalid_0's multi_logloss: 1.99143\n",
            "[25]\tvalid_0's multi_logloss: 1.98576\n",
            "[26]\tvalid_0's multi_logloss: 1.98052\n",
            "[27]\tvalid_0's multi_logloss: 1.97508\n",
            "[28]\tvalid_0's multi_logloss: 1.96961\n",
            "[29]\tvalid_0's multi_logloss: 1.96435\n",
            "[30]\tvalid_0's multi_logloss: 1.95907\n",
            "[31]\tvalid_0's multi_logloss: 1.95382\n",
            "[32]\tvalid_0's multi_logloss: 1.94859\n",
            "[33]\tvalid_0's multi_logloss: 1.94343\n",
            "[34]\tvalid_0's multi_logloss: 1.93877\n",
            "[35]\tvalid_0's multi_logloss: 1.93386\n",
            "[36]\tvalid_0's multi_logloss: 1.92885\n",
            "[37]\tvalid_0's multi_logloss: 1.92414\n",
            "[38]\tvalid_0's multi_logloss: 1.9196\n",
            "[39]\tvalid_0's multi_logloss: 1.91481\n",
            "[40]\tvalid_0's multi_logloss: 1.91055\n",
            "[41]\tvalid_0's multi_logloss: 1.90595\n",
            "[42]\tvalid_0's multi_logloss: 1.90131\n",
            "[43]\tvalid_0's multi_logloss: 1.89708\n",
            "[44]\tvalid_0's multi_logloss: 1.89263\n",
            "[45]\tvalid_0's multi_logloss: 1.88854\n",
            "[46]\tvalid_0's multi_logloss: 1.8841\n",
            "[47]\tvalid_0's multi_logloss: 1.87987\n",
            "[48]\tvalid_0's multi_logloss: 1.87575\n",
            "[49]\tvalid_0's multi_logloss: 1.87162\n",
            "[50]\tvalid_0's multi_logloss: 1.86749\n",
            "[51]\tvalid_0's multi_logloss: 1.86359\n",
            "[52]\tvalid_0's multi_logloss: 1.85973\n",
            "[53]\tvalid_0's multi_logloss: 1.85582\n",
            "[54]\tvalid_0's multi_logloss: 1.85197\n",
            "[55]\tvalid_0's multi_logloss: 1.84797\n",
            "[56]\tvalid_0's multi_logloss: 1.84427\n",
            "[57]\tvalid_0's multi_logloss: 1.84056\n",
            "[58]\tvalid_0's multi_logloss: 1.83689\n",
            "[59]\tvalid_0's multi_logloss: 1.8332\n",
            "[60]\tvalid_0's multi_logloss: 1.82956\n",
            "[61]\tvalid_0's multi_logloss: 1.82588\n",
            "[62]\tvalid_0's multi_logloss: 1.82239\n",
            "[63]\tvalid_0's multi_logloss: 1.81889\n",
            "[64]\tvalid_0's multi_logloss: 1.81538\n",
            "[65]\tvalid_0's multi_logloss: 1.81205\n",
            "[66]\tvalid_0's multi_logloss: 1.80852\n",
            "[67]\tvalid_0's multi_logloss: 1.80514\n",
            "[68]\tvalid_0's multi_logloss: 1.80165\n",
            "[69]\tvalid_0's multi_logloss: 1.79856\n",
            "[70]\tvalid_0's multi_logloss: 1.79536\n",
            "[71]\tvalid_0's multi_logloss: 1.79193\n",
            "[72]\tvalid_0's multi_logloss: 1.78885\n",
            "[73]\tvalid_0's multi_logloss: 1.78556\n",
            "[74]\tvalid_0's multi_logloss: 1.78253\n",
            "[75]\tvalid_0's multi_logloss: 1.77948\n",
            "[76]\tvalid_0's multi_logloss: 1.77634\n",
            "[77]\tvalid_0's multi_logloss: 1.77332\n",
            "[78]\tvalid_0's multi_logloss: 1.77016\n",
            "[79]\tvalid_0's multi_logloss: 1.76703\n",
            "[80]\tvalid_0's multi_logloss: 1.764\n",
            "[81]\tvalid_0's multi_logloss: 1.76115\n",
            "[82]\tvalid_0's multi_logloss: 1.75806\n",
            "[83]\tvalid_0's multi_logloss: 1.75479\n",
            "[84]\tvalid_0's multi_logloss: 1.75197\n",
            "[85]\tvalid_0's multi_logloss: 1.74908\n",
            "[86]\tvalid_0's multi_logloss: 1.74626\n",
            "[87]\tvalid_0's multi_logloss: 1.74325\n",
            "[88]\tvalid_0's multi_logloss: 1.74054\n",
            "[89]\tvalid_0's multi_logloss: 1.73761\n",
            "[90]\tvalid_0's multi_logloss: 1.73495\n",
            "[91]\tvalid_0's multi_logloss: 1.73219\n",
            "[92]\tvalid_0's multi_logloss: 1.72955\n",
            "[93]\tvalid_0's multi_logloss: 1.72679\n",
            "[94]\tvalid_0's multi_logloss: 1.72416\n",
            "[95]\tvalid_0's multi_logloss: 1.7214\n",
            "[96]\tvalid_0's multi_logloss: 1.7188\n",
            "[97]\tvalid_0's multi_logloss: 1.71617\n",
            "[98]\tvalid_0's multi_logloss: 1.71362\n",
            "[99]\tvalid_0's multi_logloss: 1.71099\n",
            "[100]\tvalid_0's multi_logloss: 1.70848\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 2.16299\n",
            "[2]\tvalid_0's multi_logloss: 2.15312\n",
            "[3]\tvalid_0's multi_logloss: 2.14357\n",
            "[4]\tvalid_0's multi_logloss: 2.13455\n",
            "[5]\tvalid_0's multi_logloss: 2.12573\n",
            "[6]\tvalid_0's multi_logloss: 2.117\n",
            "[7]\tvalid_0's multi_logloss: 2.10846\n",
            "[8]\tvalid_0's multi_logloss: 2.10034\n",
            "[9]\tvalid_0's multi_logloss: 2.09234\n",
            "[10]\tvalid_0's multi_logloss: 2.08458\n",
            "[11]\tvalid_0's multi_logloss: 2.07688\n",
            "[12]\tvalid_0's multi_logloss: 2.06984\n",
            "[13]\tvalid_0's multi_logloss: 2.06251\n",
            "[14]\tvalid_0's multi_logloss: 2.05529\n",
            "[15]\tvalid_0's multi_logloss: 2.04862\n",
            "[16]\tvalid_0's multi_logloss: 2.04215\n",
            "[17]\tvalid_0's multi_logloss: 2.03566\n",
            "[18]\tvalid_0's multi_logloss: 2.02926\n",
            "[19]\tvalid_0's multi_logloss: 2.02325\n",
            "[20]\tvalid_0's multi_logloss: 2.01698\n",
            "[21]\tvalid_0's multi_logloss: 2.01114\n",
            "[22]\tvalid_0's multi_logloss: 2.00557\n",
            "[23]\tvalid_0's multi_logloss: 1.99975\n",
            "[24]\tvalid_0's multi_logloss: 1.9941\n",
            "[25]\tvalid_0's multi_logloss: 1.98868\n",
            "[26]\tvalid_0's multi_logloss: 1.98326\n",
            "[27]\tvalid_0's multi_logloss: 1.97775\n",
            "[28]\tvalid_0's multi_logloss: 1.9724\n",
            "[29]\tvalid_0's multi_logloss: 1.9674\n",
            "[30]\tvalid_0's multi_logloss: 1.96207\n",
            "[31]\tvalid_0's multi_logloss: 1.95693\n",
            "[32]\tvalid_0's multi_logloss: 1.95198\n",
            "[33]\tvalid_0's multi_logloss: 1.94709\n",
            "[34]\tvalid_0's multi_logloss: 1.9421\n",
            "[35]\tvalid_0's multi_logloss: 1.93742\n",
            "[36]\tvalid_0's multi_logloss: 1.9327\n",
            "[37]\tvalid_0's multi_logloss: 1.92786\n",
            "[38]\tvalid_0's multi_logloss: 1.92347\n",
            "[39]\tvalid_0's multi_logloss: 1.91901\n",
            "[40]\tvalid_0's multi_logloss: 1.91449\n",
            "[41]\tvalid_0's multi_logloss: 1.91028\n",
            "[42]\tvalid_0's multi_logloss: 1.90585\n",
            "[43]\tvalid_0's multi_logloss: 1.90139\n",
            "[44]\tvalid_0's multi_logloss: 1.89723\n",
            "[45]\tvalid_0's multi_logloss: 1.89294\n",
            "[46]\tvalid_0's multi_logloss: 1.88867\n",
            "[47]\tvalid_0's multi_logloss: 1.88456\n",
            "[48]\tvalid_0's multi_logloss: 1.88039\n",
            "[49]\tvalid_0's multi_logloss: 1.8763\n",
            "[50]\tvalid_0's multi_logloss: 1.87237\n",
            "[51]\tvalid_0's multi_logloss: 1.86837\n",
            "[52]\tvalid_0's multi_logloss: 1.86425\n",
            "[53]\tvalid_0's multi_logloss: 1.86032\n",
            "[54]\tvalid_0's multi_logloss: 1.85632\n",
            "[55]\tvalid_0's multi_logloss: 1.85246\n",
            "[56]\tvalid_0's multi_logloss: 1.84868\n",
            "[57]\tvalid_0's multi_logloss: 1.84505\n",
            "[58]\tvalid_0's multi_logloss: 1.84117\n",
            "[59]\tvalid_0's multi_logloss: 1.83782\n",
            "[60]\tvalid_0's multi_logloss: 1.83421\n",
            "[61]\tvalid_0's multi_logloss: 1.83056\n",
            "[62]\tvalid_0's multi_logloss: 1.82711\n",
            "[63]\tvalid_0's multi_logloss: 1.82364\n",
            "[64]\tvalid_0's multi_logloss: 1.81992\n",
            "[65]\tvalid_0's multi_logloss: 1.81642\n",
            "[66]\tvalid_0's multi_logloss: 1.81308\n",
            "[67]\tvalid_0's multi_logloss: 1.80971\n",
            "[68]\tvalid_0's multi_logloss: 1.80634\n",
            "[69]\tvalid_0's multi_logloss: 1.80302\n",
            "[70]\tvalid_0's multi_logloss: 1.79985\n",
            "[71]\tvalid_0's multi_logloss: 1.79659\n",
            "[72]\tvalid_0's multi_logloss: 1.79347\n",
            "[73]\tvalid_0's multi_logloss: 1.79031\n",
            "[74]\tvalid_0's multi_logloss: 1.78709\n",
            "[75]\tvalid_0's multi_logloss: 1.78392\n",
            "[76]\tvalid_0's multi_logloss: 1.78077\n",
            "[77]\tvalid_0's multi_logloss: 1.77784\n",
            "[78]\tvalid_0's multi_logloss: 1.77476\n",
            "[79]\tvalid_0's multi_logloss: 1.7716\n",
            "[80]\tvalid_0's multi_logloss: 1.76863\n",
            "[81]\tvalid_0's multi_logloss: 1.76579\n",
            "[82]\tvalid_0's multi_logloss: 1.76303\n",
            "[83]\tvalid_0's multi_logloss: 1.76003\n",
            "[84]\tvalid_0's multi_logloss: 1.75713\n",
            "[85]\tvalid_0's multi_logloss: 1.75426\n",
            "[86]\tvalid_0's multi_logloss: 1.75149\n",
            "[87]\tvalid_0's multi_logloss: 1.74882\n",
            "[88]\tvalid_0's multi_logloss: 1.74592\n",
            "[89]\tvalid_0's multi_logloss: 1.74307\n",
            "[90]\tvalid_0's multi_logloss: 1.74044\n",
            "[91]\tvalid_0's multi_logloss: 1.73769\n",
            "[92]\tvalid_0's multi_logloss: 1.73509\n",
            "[93]\tvalid_0's multi_logloss: 1.73252\n",
            "[94]\tvalid_0's multi_logloss: 1.7299\n",
            "[95]\tvalid_0's multi_logloss: 1.72726\n",
            "[96]\tvalid_0's multi_logloss: 1.72456\n",
            "[97]\tvalid_0's multi_logloss: 1.72189\n",
            "[98]\tvalid_0's multi_logloss: 1.71943\n",
            "[99]\tvalid_0's multi_logloss: 1.71699\n",
            "[100]\tvalid_0's multi_logloss: 1.71441\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 2.16257\n",
            "[2]\tvalid_0's multi_logloss: 2.1524\n",
            "[3]\tvalid_0's multi_logloss: 2.14288\n",
            "[4]\tvalid_0's multi_logloss: 2.1334\n",
            "[5]\tvalid_0's multi_logloss: 2.12426\n",
            "[6]\tvalid_0's multi_logloss: 2.11565\n",
            "[7]\tvalid_0's multi_logloss: 2.10706\n",
            "[8]\tvalid_0's multi_logloss: 2.09891\n",
            "[9]\tvalid_0's multi_logloss: 2.09084\n",
            "[10]\tvalid_0's multi_logloss: 2.08301\n",
            "[11]\tvalid_0's multi_logloss: 2.0755\n",
            "[12]\tvalid_0's multi_logloss: 2.068\n",
            "[13]\tvalid_0's multi_logloss: 2.06091\n",
            "[14]\tvalid_0's multi_logloss: 2.05396\n",
            "[15]\tvalid_0's multi_logloss: 2.04725\n",
            "[16]\tvalid_0's multi_logloss: 2.04071\n",
            "[17]\tvalid_0's multi_logloss: 2.03398\n",
            "[18]\tvalid_0's multi_logloss: 2.02755\n",
            "[19]\tvalid_0's multi_logloss: 2.02142\n",
            "[20]\tvalid_0's multi_logloss: 2.01513\n",
            "[21]\tvalid_0's multi_logloss: 2.00879\n",
            "[22]\tvalid_0's multi_logloss: 2.00306\n",
            "[23]\tvalid_0's multi_logloss: 1.99722\n",
            "[24]\tvalid_0's multi_logloss: 1.99139\n",
            "[25]\tvalid_0's multi_logloss: 1.98596\n",
            "[26]\tvalid_0's multi_logloss: 1.98039\n",
            "[27]\tvalid_0's multi_logloss: 1.97483\n",
            "[28]\tvalid_0's multi_logloss: 1.96952\n",
            "[29]\tvalid_0's multi_logloss: 1.96396\n",
            "[30]\tvalid_0's multi_logloss: 1.95867\n",
            "[31]\tvalid_0's multi_logloss: 1.95365\n",
            "[32]\tvalid_0's multi_logloss: 1.94849\n",
            "[33]\tvalid_0's multi_logloss: 1.94337\n",
            "[34]\tvalid_0's multi_logloss: 1.93839\n",
            "[35]\tvalid_0's multi_logloss: 1.93322\n",
            "[36]\tvalid_0's multi_logloss: 1.92859\n",
            "[37]\tvalid_0's multi_logloss: 1.92355\n",
            "[38]\tvalid_0's multi_logloss: 1.91892\n",
            "[39]\tvalid_0's multi_logloss: 1.91424\n",
            "[40]\tvalid_0's multi_logloss: 1.90979\n",
            "[41]\tvalid_0's multi_logloss: 1.90525\n",
            "[42]\tvalid_0's multi_logloss: 1.90083\n",
            "[43]\tvalid_0's multi_logloss: 1.8965\n",
            "[44]\tvalid_0's multi_logloss: 1.89205\n",
            "[45]\tvalid_0's multi_logloss: 1.88794\n",
            "[46]\tvalid_0's multi_logloss: 1.8837\n",
            "[47]\tvalid_0's multi_logloss: 1.87951\n",
            "[48]\tvalid_0's multi_logloss: 1.87526\n",
            "[49]\tvalid_0's multi_logloss: 1.8713\n",
            "[50]\tvalid_0's multi_logloss: 1.8673\n",
            "[51]\tvalid_0's multi_logloss: 1.86345\n",
            "[52]\tvalid_0's multi_logloss: 1.85958\n",
            "[53]\tvalid_0's multi_logloss: 1.85564\n",
            "[54]\tvalid_0's multi_logloss: 1.8519\n",
            "[55]\tvalid_0's multi_logloss: 1.84822\n",
            "[56]\tvalid_0's multi_logloss: 1.8445\n",
            "[57]\tvalid_0's multi_logloss: 1.84084\n",
            "[58]\tvalid_0's multi_logloss: 1.83712\n",
            "[59]\tvalid_0's multi_logloss: 1.83328\n",
            "[60]\tvalid_0's multi_logloss: 1.82987\n",
            "[61]\tvalid_0's multi_logloss: 1.82621\n",
            "[62]\tvalid_0's multi_logloss: 1.82257\n",
            "[63]\tvalid_0's multi_logloss: 1.81902\n",
            "[64]\tvalid_0's multi_logloss: 1.81559\n",
            "[65]\tvalid_0's multi_logloss: 1.81233\n",
            "[66]\tvalid_0's multi_logloss: 1.80888\n",
            "[67]\tvalid_0's multi_logloss: 1.80558\n",
            "[68]\tvalid_0's multi_logloss: 1.80223\n",
            "[69]\tvalid_0's multi_logloss: 1.79916\n",
            "[70]\tvalid_0's multi_logloss: 1.79586\n",
            "[71]\tvalid_0's multi_logloss: 1.79247\n",
            "[72]\tvalid_0's multi_logloss: 1.78927\n",
            "[73]\tvalid_0's multi_logloss: 1.78609\n",
            "[74]\tvalid_0's multi_logloss: 1.7829\n",
            "[75]\tvalid_0's multi_logloss: 1.78\n",
            "[76]\tvalid_0's multi_logloss: 1.77683\n",
            "[77]\tvalid_0's multi_logloss: 1.7737\n",
            "[78]\tvalid_0's multi_logloss: 1.77074\n",
            "[79]\tvalid_0's multi_logloss: 1.76772\n",
            "[80]\tvalid_0's multi_logloss: 1.76486\n",
            "[81]\tvalid_0's multi_logloss: 1.76196\n",
            "[82]\tvalid_0's multi_logloss: 1.75913\n",
            "[83]\tvalid_0's multi_logloss: 1.75627\n",
            "[84]\tvalid_0's multi_logloss: 1.75349\n",
            "[85]\tvalid_0's multi_logloss: 1.75067\n",
            "[86]\tvalid_0's multi_logloss: 1.74795\n",
            "[87]\tvalid_0's multi_logloss: 1.74509\n",
            "[88]\tvalid_0's multi_logloss: 1.74241\n",
            "[89]\tvalid_0's multi_logloss: 1.7397\n",
            "[90]\tvalid_0's multi_logloss: 1.73696\n",
            "[91]\tvalid_0's multi_logloss: 1.7342\n",
            "[92]\tvalid_0's multi_logloss: 1.73145\n",
            "[93]\tvalid_0's multi_logloss: 1.72866\n",
            "[94]\tvalid_0's multi_logloss: 1.726\n",
            "[95]\tvalid_0's multi_logloss: 1.7234\n",
            "[96]\tvalid_0's multi_logloss: 1.72077\n",
            "[97]\tvalid_0's multi_logloss: 1.71831\n",
            "[98]\tvalid_0's multi_logloss: 1.71574\n",
            "[99]\tvalid_0's multi_logloss: 1.71319\n",
            "[100]\tvalid_0's multi_logloss: 1.71057\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 2.16266\n",
            "[2]\tvalid_0's multi_logloss: 2.1523\n",
            "[3]\tvalid_0's multi_logloss: 2.14265\n",
            "[4]\tvalid_0's multi_logloss: 2.13325\n",
            "[5]\tvalid_0's multi_logloss: 2.12434\n",
            "[6]\tvalid_0's multi_logloss: 2.11565\n",
            "[7]\tvalid_0's multi_logloss: 2.10712\n",
            "[8]\tvalid_0's multi_logloss: 2.09882\n",
            "[9]\tvalid_0's multi_logloss: 2.09084\n",
            "[10]\tvalid_0's multi_logloss: 2.08308\n",
            "[11]\tvalid_0's multi_logloss: 2.07572\n",
            "[12]\tvalid_0's multi_logloss: 2.06853\n",
            "[13]\tvalid_0's multi_logloss: 2.06157\n",
            "[14]\tvalid_0's multi_logloss: 2.05454\n",
            "[15]\tvalid_0's multi_logloss: 2.04785\n",
            "[16]\tvalid_0's multi_logloss: 2.04144\n",
            "[17]\tvalid_0's multi_logloss: 2.03493\n",
            "[18]\tvalid_0's multi_logloss: 2.02877\n",
            "[19]\tvalid_0's multi_logloss: 2.02273\n",
            "[20]\tvalid_0's multi_logloss: 2.01681\n",
            "[21]\tvalid_0's multi_logloss: 2.01096\n",
            "[22]\tvalid_0's multi_logloss: 2.00508\n",
            "[23]\tvalid_0's multi_logloss: 1.99955\n",
            "[24]\tvalid_0's multi_logloss: 1.99401\n",
            "[25]\tvalid_0's multi_logloss: 1.98836\n",
            "[26]\tvalid_0's multi_logloss: 1.98302\n",
            "[27]\tvalid_0's multi_logloss: 1.97776\n",
            "[28]\tvalid_0's multi_logloss: 1.97248\n",
            "[29]\tvalid_0's multi_logloss: 1.96749\n",
            "[30]\tvalid_0's multi_logloss: 1.96212\n",
            "[31]\tvalid_0's multi_logloss: 1.95705\n",
            "[32]\tvalid_0's multi_logloss: 1.95234\n",
            "[33]\tvalid_0's multi_logloss: 1.94733\n",
            "[34]\tvalid_0's multi_logloss: 1.94244\n",
            "[35]\tvalid_0's multi_logloss: 1.93771\n",
            "[36]\tvalid_0's multi_logloss: 1.93285\n",
            "[37]\tvalid_0's multi_logloss: 1.92812\n",
            "[38]\tvalid_0's multi_logloss: 1.92328\n",
            "[39]\tvalid_0's multi_logloss: 1.91877\n",
            "[40]\tvalid_0's multi_logloss: 1.91428\n",
            "[41]\tvalid_0's multi_logloss: 1.90946\n",
            "[42]\tvalid_0's multi_logloss: 1.90493\n",
            "[43]\tvalid_0's multi_logloss: 1.9006\n",
            "[44]\tvalid_0's multi_logloss: 1.89612\n",
            "[45]\tvalid_0's multi_logloss: 1.89193\n",
            "[46]\tvalid_0's multi_logloss: 1.88748\n",
            "[47]\tvalid_0's multi_logloss: 1.88348\n",
            "[48]\tvalid_0's multi_logloss: 1.87951\n",
            "[49]\tvalid_0's multi_logloss: 1.87533\n",
            "[50]\tvalid_0's multi_logloss: 1.87131\n",
            "[51]\tvalid_0's multi_logloss: 1.86753\n",
            "[52]\tvalid_0's multi_logloss: 1.86371\n",
            "[53]\tvalid_0's multi_logloss: 1.85984\n",
            "[54]\tvalid_0's multi_logloss: 1.85599\n",
            "[55]\tvalid_0's multi_logloss: 1.85222\n",
            "[56]\tvalid_0's multi_logloss: 1.84849\n",
            "[57]\tvalid_0's multi_logloss: 1.84477\n",
            "[58]\tvalid_0's multi_logloss: 1.84114\n",
            "[59]\tvalid_0's multi_logloss: 1.83747\n",
            "[60]\tvalid_0's multi_logloss: 1.83397\n",
            "[61]\tvalid_0's multi_logloss: 1.83021\n",
            "[62]\tvalid_0's multi_logloss: 1.82668\n",
            "[63]\tvalid_0's multi_logloss: 1.82327\n",
            "[64]\tvalid_0's multi_logloss: 1.81967\n",
            "[65]\tvalid_0's multi_logloss: 1.81617\n",
            "[66]\tvalid_0's multi_logloss: 1.81271\n",
            "[67]\tvalid_0's multi_logloss: 1.80934\n",
            "[68]\tvalid_0's multi_logloss: 1.80593\n",
            "[69]\tvalid_0's multi_logloss: 1.80266\n",
            "[70]\tvalid_0's multi_logloss: 1.79935\n",
            "[71]\tvalid_0's multi_logloss: 1.79604\n",
            "[72]\tvalid_0's multi_logloss: 1.79275\n",
            "[73]\tvalid_0's multi_logloss: 1.78958\n",
            "[74]\tvalid_0's multi_logloss: 1.78645\n",
            "[75]\tvalid_0's multi_logloss: 1.7831\n",
            "[76]\tvalid_0's multi_logloss: 1.78011\n",
            "[77]\tvalid_0's multi_logloss: 1.77679\n",
            "[78]\tvalid_0's multi_logloss: 1.77406\n",
            "[79]\tvalid_0's multi_logloss: 1.77116\n",
            "[80]\tvalid_0's multi_logloss: 1.7682\n",
            "[81]\tvalid_0's multi_logloss: 1.76532\n",
            "[82]\tvalid_0's multi_logloss: 1.76245\n",
            "[83]\tvalid_0's multi_logloss: 1.75939\n",
            "[84]\tvalid_0's multi_logloss: 1.75639\n",
            "[85]\tvalid_0's multi_logloss: 1.75352\n",
            "[86]\tvalid_0's multi_logloss: 1.75071\n",
            "[87]\tvalid_0's multi_logloss: 1.748\n",
            "[88]\tvalid_0's multi_logloss: 1.74514\n",
            "[89]\tvalid_0's multi_logloss: 1.74233\n",
            "[90]\tvalid_0's multi_logloss: 1.7397\n",
            "[91]\tvalid_0's multi_logloss: 1.73699\n",
            "[92]\tvalid_0's multi_logloss: 1.73444\n",
            "[93]\tvalid_0's multi_logloss: 1.73179\n",
            "[94]\tvalid_0's multi_logloss: 1.72937\n",
            "[95]\tvalid_0's multi_logloss: 1.72653\n",
            "[96]\tvalid_0's multi_logloss: 1.72388\n",
            "[97]\tvalid_0's multi_logloss: 1.72121\n",
            "[98]\tvalid_0's multi_logloss: 1.7187\n",
            "[99]\tvalid_0's multi_logloss: 1.7161\n",
            "[100]\tvalid_0's multi_logloss: 1.71369\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 2.15945\n",
            "[2]\tvalid_0's multi_logloss: 2.14654\n",
            "[3]\tvalid_0's multi_logloss: 2.13412\n",
            "[4]\tvalid_0's multi_logloss: 2.12222\n",
            "[5]\tvalid_0's multi_logloss: 2.11113\n",
            "[6]\tvalid_0's multi_logloss: 2.09969\n",
            "[7]\tvalid_0's multi_logloss: 2.08905\n",
            "[8]\tvalid_0's multi_logloss: 2.07851\n",
            "[9]\tvalid_0's multi_logloss: 2.06826\n",
            "[10]\tvalid_0's multi_logloss: 2.05834\n",
            "[11]\tvalid_0's multi_logloss: 2.04861\n",
            "[12]\tvalid_0's multi_logloss: 2.03929\n",
            "[13]\tvalid_0's multi_logloss: 2.02998\n",
            "[14]\tvalid_0's multi_logloss: 2.02139\n",
            "[15]\tvalid_0's multi_logloss: 2.01282\n",
            "[16]\tvalid_0's multi_logloss: 2.00419\n",
            "[17]\tvalid_0's multi_logloss: 1.99593\n",
            "[18]\tvalid_0's multi_logloss: 1.98784\n",
            "[19]\tvalid_0's multi_logloss: 1.98002\n",
            "[20]\tvalid_0's multi_logloss: 1.97226\n",
            "[21]\tvalid_0's multi_logloss: 1.96481\n",
            "[22]\tvalid_0's multi_logloss: 1.95739\n",
            "[23]\tvalid_0's multi_logloss: 1.95007\n",
            "[24]\tvalid_0's multi_logloss: 1.9431\n",
            "[25]\tvalid_0's multi_logloss: 1.93605\n",
            "[26]\tvalid_0's multi_logloss: 1.92939\n",
            "[27]\tvalid_0's multi_logloss: 1.92276\n",
            "[28]\tvalid_0's multi_logloss: 1.91601\n",
            "[29]\tvalid_0's multi_logloss: 1.90972\n",
            "[30]\tvalid_0's multi_logloss: 1.90354\n",
            "[31]\tvalid_0's multi_logloss: 1.89705\n",
            "[32]\tvalid_0's multi_logloss: 1.89093\n",
            "[33]\tvalid_0's multi_logloss: 1.88481\n",
            "[34]\tvalid_0's multi_logloss: 1.8786\n",
            "[35]\tvalid_0's multi_logloss: 1.87274\n",
            "[36]\tvalid_0's multi_logloss: 1.86692\n",
            "[37]\tvalid_0's multi_logloss: 1.86088\n",
            "[38]\tvalid_0's multi_logloss: 1.85528\n",
            "[39]\tvalid_0's multi_logloss: 1.8498\n",
            "[40]\tvalid_0's multi_logloss: 1.84439\n",
            "[41]\tvalid_0's multi_logloss: 1.83904\n",
            "[42]\tvalid_0's multi_logloss: 1.83356\n",
            "[43]\tvalid_0's multi_logloss: 1.82838\n",
            "[44]\tvalid_0's multi_logloss: 1.82324\n",
            "[45]\tvalid_0's multi_logloss: 1.81814\n",
            "[46]\tvalid_0's multi_logloss: 1.81303\n",
            "[47]\tvalid_0's multi_logloss: 1.80814\n",
            "[48]\tvalid_0's multi_logloss: 1.80336\n",
            "[49]\tvalid_0's multi_logloss: 1.7984\n",
            "[50]\tvalid_0's multi_logloss: 1.79349\n",
            "[51]\tvalid_0's multi_logloss: 1.78879\n",
            "[52]\tvalid_0's multi_logloss: 1.7841\n",
            "[53]\tvalid_0's multi_logloss: 1.7795\n",
            "[54]\tvalid_0's multi_logloss: 1.7749\n",
            "[55]\tvalid_0's multi_logloss: 1.77053\n",
            "[56]\tvalid_0's multi_logloss: 1.7661\n",
            "[57]\tvalid_0's multi_logloss: 1.7617\n",
            "[58]\tvalid_0's multi_logloss: 1.75709\n",
            "[59]\tvalid_0's multi_logloss: 1.75301\n",
            "[60]\tvalid_0's multi_logloss: 1.74866\n",
            "[61]\tvalid_0's multi_logloss: 1.74444\n",
            "[62]\tvalid_0's multi_logloss: 1.74056\n",
            "[63]\tvalid_0's multi_logloss: 1.73643\n",
            "[64]\tvalid_0's multi_logloss: 1.7325\n",
            "[65]\tvalid_0's multi_logloss: 1.72854\n",
            "[66]\tvalid_0's multi_logloss: 1.72467\n",
            "[67]\tvalid_0's multi_logloss: 1.72071\n",
            "[68]\tvalid_0's multi_logloss: 1.71696\n",
            "[69]\tvalid_0's multi_logloss: 1.7132\n",
            "[70]\tvalid_0's multi_logloss: 1.7092\n",
            "[71]\tvalid_0's multi_logloss: 1.70554\n",
            "[72]\tvalid_0's multi_logloss: 1.7018\n",
            "[73]\tvalid_0's multi_logloss: 1.69813\n",
            "[74]\tvalid_0's multi_logloss: 1.69452\n",
            "[75]\tvalid_0's multi_logloss: 1.69095\n",
            "[76]\tvalid_0's multi_logloss: 1.68747\n",
            "[77]\tvalid_0's multi_logloss: 1.684\n",
            "[78]\tvalid_0's multi_logloss: 1.68045\n",
            "[79]\tvalid_0's multi_logloss: 1.67704\n",
            "[80]\tvalid_0's multi_logloss: 1.6738\n",
            "[81]\tvalid_0's multi_logloss: 1.67039\n",
            "[82]\tvalid_0's multi_logloss: 1.66717\n",
            "[83]\tvalid_0's multi_logloss: 1.66386\n",
            "[84]\tvalid_0's multi_logloss: 1.66053\n",
            "[85]\tvalid_0's multi_logloss: 1.65731\n",
            "[86]\tvalid_0's multi_logloss: 1.65421\n",
            "[87]\tvalid_0's multi_logloss: 1.65106\n",
            "[88]\tvalid_0's multi_logloss: 1.64818\n",
            "[89]\tvalid_0's multi_logloss: 1.64509\n",
            "[90]\tvalid_0's multi_logloss: 1.64198\n",
            "[91]\tvalid_0's multi_logloss: 1.63895\n",
            "[92]\tvalid_0's multi_logloss: 1.63607\n",
            "[93]\tvalid_0's multi_logloss: 1.63322\n",
            "[94]\tvalid_0's multi_logloss: 1.63026\n",
            "[95]\tvalid_0's multi_logloss: 1.62738\n",
            "[96]\tvalid_0's multi_logloss: 1.62454\n",
            "[97]\tvalid_0's multi_logloss: 1.62155\n",
            "[98]\tvalid_0's multi_logloss: 1.61871\n",
            "[99]\tvalid_0's multi_logloss: 1.61581\n",
            "[100]\tvalid_0's multi_logloss: 1.61312\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 2.15954\n",
            "[2]\tvalid_0's multi_logloss: 2.1463\n",
            "[3]\tvalid_0's multi_logloss: 2.13383\n",
            "[4]\tvalid_0's multi_logloss: 2.12194\n",
            "[5]\tvalid_0's multi_logloss: 2.11015\n",
            "[6]\tvalid_0's multi_logloss: 2.09885\n",
            "[7]\tvalid_0's multi_logloss: 2.08792\n",
            "[8]\tvalid_0's multi_logloss: 2.07744\n",
            "[9]\tvalid_0's multi_logloss: 2.06708\n",
            "[10]\tvalid_0's multi_logloss: 2.05707\n",
            "[11]\tvalid_0's multi_logloss: 2.04755\n",
            "[12]\tvalid_0's multi_logloss: 2.03821\n",
            "[13]\tvalid_0's multi_logloss: 2.0291\n",
            "[14]\tvalid_0's multi_logloss: 2.02029\n",
            "[15]\tvalid_0's multi_logloss: 2.01197\n",
            "[16]\tvalid_0's multi_logloss: 2.00363\n",
            "[17]\tvalid_0's multi_logloss: 1.99548\n",
            "[18]\tvalid_0's multi_logloss: 1.98761\n",
            "[19]\tvalid_0's multi_logloss: 1.97987\n",
            "[20]\tvalid_0's multi_logloss: 1.97225\n",
            "[21]\tvalid_0's multi_logloss: 1.96485\n",
            "[22]\tvalid_0's multi_logloss: 1.95755\n",
            "[23]\tvalid_0's multi_logloss: 1.95042\n",
            "[24]\tvalid_0's multi_logloss: 1.94334\n",
            "[25]\tvalid_0's multi_logloss: 1.93635\n",
            "[26]\tvalid_0's multi_logloss: 1.92944\n",
            "[27]\tvalid_0's multi_logloss: 1.92296\n",
            "[28]\tvalid_0's multi_logloss: 1.91644\n",
            "[29]\tvalid_0's multi_logloss: 1.90974\n",
            "[30]\tvalid_0's multi_logloss: 1.9033\n",
            "[31]\tvalid_0's multi_logloss: 1.89714\n",
            "[32]\tvalid_0's multi_logloss: 1.89058\n",
            "[33]\tvalid_0's multi_logloss: 1.8845\n",
            "[34]\tvalid_0's multi_logloss: 1.8783\n",
            "[35]\tvalid_0's multi_logloss: 1.87228\n",
            "[36]\tvalid_0's multi_logloss: 1.86639\n",
            "[37]\tvalid_0's multi_logloss: 1.86058\n",
            "[38]\tvalid_0's multi_logloss: 1.8549\n",
            "[39]\tvalid_0's multi_logloss: 1.84912\n",
            "[40]\tvalid_0's multi_logloss: 1.8435\n",
            "[41]\tvalid_0's multi_logloss: 1.83791\n",
            "[42]\tvalid_0's multi_logloss: 1.83246\n",
            "[43]\tvalid_0's multi_logloss: 1.82706\n",
            "[44]\tvalid_0's multi_logloss: 1.82192\n",
            "[45]\tvalid_0's multi_logloss: 1.81683\n",
            "[46]\tvalid_0's multi_logloss: 1.81151\n",
            "[47]\tvalid_0's multi_logloss: 1.80648\n",
            "[48]\tvalid_0's multi_logloss: 1.80137\n",
            "[49]\tvalid_0's multi_logloss: 1.79633\n",
            "[50]\tvalid_0's multi_logloss: 1.79165\n",
            "[51]\tvalid_0's multi_logloss: 1.78691\n",
            "[52]\tvalid_0's multi_logloss: 1.78238\n",
            "[53]\tvalid_0's multi_logloss: 1.77772\n",
            "[54]\tvalid_0's multi_logloss: 1.77319\n",
            "[55]\tvalid_0's multi_logloss: 1.76867\n",
            "[56]\tvalid_0's multi_logloss: 1.76419\n",
            "[57]\tvalid_0's multi_logloss: 1.75979\n",
            "[58]\tvalid_0's multi_logloss: 1.75534\n",
            "[59]\tvalid_0's multi_logloss: 1.75105\n",
            "[60]\tvalid_0's multi_logloss: 1.74682\n",
            "[61]\tvalid_0's multi_logloss: 1.74263\n",
            "[62]\tvalid_0's multi_logloss: 1.73862\n",
            "[63]\tvalid_0's multi_logloss: 1.73429\n",
            "[64]\tvalid_0's multi_logloss: 1.73007\n",
            "[65]\tvalid_0's multi_logloss: 1.72613\n",
            "[66]\tvalid_0's multi_logloss: 1.72218\n",
            "[67]\tvalid_0's multi_logloss: 1.71824\n",
            "[68]\tvalid_0's multi_logloss: 1.7144\n",
            "[69]\tvalid_0's multi_logloss: 1.71057\n",
            "[70]\tvalid_0's multi_logloss: 1.70657\n",
            "[71]\tvalid_0's multi_logloss: 1.70276\n",
            "[72]\tvalid_0's multi_logloss: 1.69896\n",
            "[73]\tvalid_0's multi_logloss: 1.6954\n",
            "[74]\tvalid_0's multi_logloss: 1.6918\n",
            "[75]\tvalid_0's multi_logloss: 1.6882\n",
            "[76]\tvalid_0's multi_logloss: 1.6847\n",
            "[77]\tvalid_0's multi_logloss: 1.6813\n",
            "[78]\tvalid_0's multi_logloss: 1.67776\n",
            "[79]\tvalid_0's multi_logloss: 1.67414\n",
            "[80]\tvalid_0's multi_logloss: 1.67093\n",
            "[81]\tvalid_0's multi_logloss: 1.66766\n",
            "[82]\tvalid_0's multi_logloss: 1.66418\n",
            "[83]\tvalid_0's multi_logloss: 1.66086\n",
            "[84]\tvalid_0's multi_logloss: 1.65757\n",
            "[85]\tvalid_0's multi_logloss: 1.6544\n",
            "[86]\tvalid_0's multi_logloss: 1.65121\n",
            "[87]\tvalid_0's multi_logloss: 1.64796\n",
            "[88]\tvalid_0's multi_logloss: 1.64478\n",
            "[89]\tvalid_0's multi_logloss: 1.64153\n",
            "[90]\tvalid_0's multi_logloss: 1.6384\n",
            "[91]\tvalid_0's multi_logloss: 1.63525\n",
            "[92]\tvalid_0's multi_logloss: 1.6319\n",
            "[93]\tvalid_0's multi_logloss: 1.62899\n",
            "[94]\tvalid_0's multi_logloss: 1.62602\n",
            "[95]\tvalid_0's multi_logloss: 1.62283\n",
            "[96]\tvalid_0's multi_logloss: 1.61994\n",
            "[97]\tvalid_0's multi_logloss: 1.61693\n",
            "[98]\tvalid_0's multi_logloss: 1.61404\n",
            "[99]\tvalid_0's multi_logloss: 1.6112\n",
            "[100]\tvalid_0's multi_logloss: 1.60832\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 2.16001\n",
            "[2]\tvalid_0's multi_logloss: 2.14711\n",
            "[3]\tvalid_0's multi_logloss: 2.13461\n",
            "[4]\tvalid_0's multi_logloss: 2.12268\n",
            "[5]\tvalid_0's multi_logloss: 2.11076\n",
            "[6]\tvalid_0's multi_logloss: 2.09953\n",
            "[7]\tvalid_0's multi_logloss: 2.08829\n",
            "[8]\tvalid_0's multi_logloss: 2.07766\n",
            "[9]\tvalid_0's multi_logloss: 2.06735\n",
            "[10]\tvalid_0's multi_logloss: 2.05713\n",
            "[11]\tvalid_0's multi_logloss: 2.04747\n",
            "[12]\tvalid_0's multi_logloss: 2.03789\n",
            "[13]\tvalid_0's multi_logloss: 2.0287\n",
            "[14]\tvalid_0's multi_logloss: 2.01965\n",
            "[15]\tvalid_0's multi_logloss: 2.01106\n",
            "[16]\tvalid_0's multi_logloss: 2.00248\n",
            "[17]\tvalid_0's multi_logloss: 1.99423\n",
            "[18]\tvalid_0's multi_logloss: 1.98609\n",
            "[19]\tvalid_0's multi_logloss: 1.97836\n",
            "[20]\tvalid_0's multi_logloss: 1.97066\n",
            "[21]\tvalid_0's multi_logloss: 1.96325\n",
            "[22]\tvalid_0's multi_logloss: 1.95577\n",
            "[23]\tvalid_0's multi_logloss: 1.94865\n",
            "[24]\tvalid_0's multi_logloss: 1.94148\n",
            "[25]\tvalid_0's multi_logloss: 1.93442\n",
            "[26]\tvalid_0's multi_logloss: 1.92767\n",
            "[27]\tvalid_0's multi_logloss: 1.92089\n",
            "[28]\tvalid_0's multi_logloss: 1.91434\n",
            "[29]\tvalid_0's multi_logloss: 1.90788\n",
            "[30]\tvalid_0's multi_logloss: 1.90177\n",
            "[31]\tvalid_0's multi_logloss: 1.89553\n",
            "[32]\tvalid_0's multi_logloss: 1.88953\n",
            "[33]\tvalid_0's multi_logloss: 1.88367\n",
            "[34]\tvalid_0's multi_logloss: 1.87775\n",
            "[35]\tvalid_0's multi_logloss: 1.87206\n",
            "[36]\tvalid_0's multi_logloss: 1.86619\n",
            "[37]\tvalid_0's multi_logloss: 1.86063\n",
            "[38]\tvalid_0's multi_logloss: 1.85514\n",
            "[39]\tvalid_0's multi_logloss: 1.84978\n",
            "[40]\tvalid_0's multi_logloss: 1.8445\n",
            "[41]\tvalid_0's multi_logloss: 1.83925\n",
            "[42]\tvalid_0's multi_logloss: 1.83397\n",
            "[43]\tvalid_0's multi_logloss: 1.82882\n",
            "[44]\tvalid_0's multi_logloss: 1.82376\n",
            "[45]\tvalid_0's multi_logloss: 1.81864\n",
            "[46]\tvalid_0's multi_logloss: 1.81355\n",
            "[47]\tvalid_0's multi_logloss: 1.80876\n",
            "[48]\tvalid_0's multi_logloss: 1.80379\n",
            "[49]\tvalid_0's multi_logloss: 1.79892\n",
            "[50]\tvalid_0's multi_logloss: 1.79416\n",
            "[51]\tvalid_0's multi_logloss: 1.7894\n",
            "[52]\tvalid_0's multi_logloss: 1.78477\n",
            "[53]\tvalid_0's multi_logloss: 1.7802\n",
            "[54]\tvalid_0's multi_logloss: 1.77578\n",
            "[55]\tvalid_0's multi_logloss: 1.77124\n",
            "[56]\tvalid_0's multi_logloss: 1.76686\n",
            "[57]\tvalid_0's multi_logloss: 1.76252\n",
            "[58]\tvalid_0's multi_logloss: 1.75824\n",
            "[59]\tvalid_0's multi_logloss: 1.75391\n",
            "[60]\tvalid_0's multi_logloss: 1.74971\n",
            "[61]\tvalid_0's multi_logloss: 1.7455\n",
            "[62]\tvalid_0's multi_logloss: 1.74145\n",
            "[63]\tvalid_0's multi_logloss: 1.73747\n",
            "[64]\tvalid_0's multi_logloss: 1.73342\n",
            "[65]\tvalid_0's multi_logloss: 1.72953\n",
            "[66]\tvalid_0's multi_logloss: 1.72551\n",
            "[67]\tvalid_0's multi_logloss: 1.72168\n",
            "[68]\tvalid_0's multi_logloss: 1.71769\n",
            "[69]\tvalid_0's multi_logloss: 1.71386\n",
            "[70]\tvalid_0's multi_logloss: 1.71012\n",
            "[71]\tvalid_0's multi_logloss: 1.70637\n",
            "[72]\tvalid_0's multi_logloss: 1.70271\n",
            "[73]\tvalid_0's multi_logloss: 1.69912\n",
            "[74]\tvalid_0's multi_logloss: 1.69552\n",
            "[75]\tvalid_0's multi_logloss: 1.692\n",
            "[76]\tvalid_0's multi_logloss: 1.68842\n",
            "[77]\tvalid_0's multi_logloss: 1.68484\n",
            "[78]\tvalid_0's multi_logloss: 1.68149\n",
            "[79]\tvalid_0's multi_logloss: 1.67813\n",
            "[80]\tvalid_0's multi_logloss: 1.67481\n",
            "[81]\tvalid_0's multi_logloss: 1.67148\n",
            "[82]\tvalid_0's multi_logloss: 1.66819\n",
            "[83]\tvalid_0's multi_logloss: 1.6651\n",
            "[84]\tvalid_0's multi_logloss: 1.66178\n",
            "[85]\tvalid_0's multi_logloss: 1.6586\n",
            "[86]\tvalid_0's multi_logloss: 1.65555\n",
            "[87]\tvalid_0's multi_logloss: 1.65236\n",
            "[88]\tvalid_0's multi_logloss: 1.64924\n",
            "[89]\tvalid_0's multi_logloss: 1.64614\n",
            "[90]\tvalid_0's multi_logloss: 1.64307\n",
            "[91]\tvalid_0's multi_logloss: 1.64004\n",
            "[92]\tvalid_0's multi_logloss: 1.63707\n",
            "[93]\tvalid_0's multi_logloss: 1.63407\n",
            "[94]\tvalid_0's multi_logloss: 1.63103\n",
            "[95]\tvalid_0's multi_logloss: 1.62801\n",
            "[96]\tvalid_0's multi_logloss: 1.62508\n",
            "[97]\tvalid_0's multi_logloss: 1.62223\n",
            "[98]\tvalid_0's multi_logloss: 1.61938\n",
            "[99]\tvalid_0's multi_logloss: 1.61658\n",
            "[100]\tvalid_0's multi_logloss: 1.61369\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 2.15931\n",
            "[2]\tvalid_0's multi_logloss: 2.14577\n",
            "[3]\tvalid_0's multi_logloss: 2.13305\n",
            "[4]\tvalid_0's multi_logloss: 2.12105\n",
            "[5]\tvalid_0's multi_logloss: 2.10955\n",
            "[6]\tvalid_0's multi_logloss: 2.09812\n",
            "[7]\tvalid_0's multi_logloss: 2.08724\n",
            "[8]\tvalid_0's multi_logloss: 2.07675\n",
            "[9]\tvalid_0's multi_logloss: 2.06661\n",
            "[10]\tvalid_0's multi_logloss: 2.05645\n",
            "[11]\tvalid_0's multi_logloss: 2.04659\n",
            "[12]\tvalid_0's multi_logloss: 2.03744\n",
            "[13]\tvalid_0's multi_logloss: 2.02824\n",
            "[14]\tvalid_0's multi_logloss: 2.0194\n",
            "[15]\tvalid_0's multi_logloss: 2.01064\n",
            "[16]\tvalid_0's multi_logloss: 2.00222\n",
            "[17]\tvalid_0's multi_logloss: 1.99388\n",
            "[18]\tvalid_0's multi_logloss: 1.98561\n",
            "[19]\tvalid_0's multi_logloss: 1.97754\n",
            "[20]\tvalid_0's multi_logloss: 1.96955\n",
            "[21]\tvalid_0's multi_logloss: 1.96211\n",
            "[22]\tvalid_0's multi_logloss: 1.95439\n",
            "[23]\tvalid_0's multi_logloss: 1.94696\n",
            "[24]\tvalid_0's multi_logloss: 1.93983\n",
            "[25]\tvalid_0's multi_logloss: 1.93271\n",
            "[26]\tvalid_0's multi_logloss: 1.92597\n",
            "[27]\tvalid_0's multi_logloss: 1.91896\n",
            "[28]\tvalid_0's multi_logloss: 1.91247\n",
            "[29]\tvalid_0's multi_logloss: 1.90614\n",
            "[30]\tvalid_0's multi_logloss: 1.89971\n",
            "[31]\tvalid_0's multi_logloss: 1.89346\n",
            "[32]\tvalid_0's multi_logloss: 1.88764\n",
            "[33]\tvalid_0's multi_logloss: 1.88147\n",
            "[34]\tvalid_0's multi_logloss: 1.87539\n",
            "[35]\tvalid_0's multi_logloss: 1.86938\n",
            "[36]\tvalid_0's multi_logloss: 1.86332\n",
            "[37]\tvalid_0's multi_logloss: 1.8576\n",
            "[38]\tvalid_0's multi_logloss: 1.85185\n",
            "[39]\tvalid_0's multi_logloss: 1.84626\n",
            "[40]\tvalid_0's multi_logloss: 1.84078\n",
            "[41]\tvalid_0's multi_logloss: 1.83527\n",
            "[42]\tvalid_0's multi_logloss: 1.82998\n",
            "[43]\tvalid_0's multi_logloss: 1.82469\n",
            "[44]\tvalid_0's multi_logloss: 1.81951\n",
            "[45]\tvalid_0's multi_logloss: 1.81414\n",
            "[46]\tvalid_0's multi_logloss: 1.80928\n",
            "[47]\tvalid_0's multi_logloss: 1.80409\n",
            "[48]\tvalid_0's multi_logloss: 1.79912\n",
            "[49]\tvalid_0's multi_logloss: 1.7941\n",
            "[50]\tvalid_0's multi_logloss: 1.78918\n",
            "[51]\tvalid_0's multi_logloss: 1.78446\n",
            "[52]\tvalid_0's multi_logloss: 1.77962\n",
            "[53]\tvalid_0's multi_logloss: 1.77508\n",
            "[54]\tvalid_0's multi_logloss: 1.77053\n",
            "[55]\tvalid_0's multi_logloss: 1.7659\n",
            "[56]\tvalid_0's multi_logloss: 1.76137\n",
            "[57]\tvalid_0's multi_logloss: 1.75716\n",
            "[58]\tvalid_0's multi_logloss: 1.75279\n",
            "[59]\tvalid_0's multi_logloss: 1.74842\n",
            "[60]\tvalid_0's multi_logloss: 1.74432\n",
            "[61]\tvalid_0's multi_logloss: 1.74016\n",
            "[62]\tvalid_0's multi_logloss: 1.73623\n",
            "[63]\tvalid_0's multi_logloss: 1.73204\n",
            "[64]\tvalid_0's multi_logloss: 1.72807\n",
            "[65]\tvalid_0's multi_logloss: 1.72419\n",
            "[66]\tvalid_0's multi_logloss: 1.7203\n",
            "[67]\tvalid_0's multi_logloss: 1.71641\n",
            "[68]\tvalid_0's multi_logloss: 1.71258\n",
            "[69]\tvalid_0's multi_logloss: 1.70875\n",
            "[70]\tvalid_0's multi_logloss: 1.70509\n",
            "[71]\tvalid_0's multi_logloss: 1.70142\n",
            "[72]\tvalid_0's multi_logloss: 1.69792\n",
            "[73]\tvalid_0's multi_logloss: 1.69419\n",
            "[74]\tvalid_0's multi_logloss: 1.69063\n",
            "[75]\tvalid_0's multi_logloss: 1.68698\n",
            "[76]\tvalid_0's multi_logloss: 1.68368\n",
            "[77]\tvalid_0's multi_logloss: 1.6803\n",
            "[78]\tvalid_0's multi_logloss: 1.67683\n",
            "[79]\tvalid_0's multi_logloss: 1.67353\n",
            "[80]\tvalid_0's multi_logloss: 1.67033\n",
            "[81]\tvalid_0's multi_logloss: 1.66706\n",
            "[82]\tvalid_0's multi_logloss: 1.6639\n",
            "[83]\tvalid_0's multi_logloss: 1.66068\n",
            "[84]\tvalid_0's multi_logloss: 1.65736\n",
            "[85]\tvalid_0's multi_logloss: 1.65418\n",
            "[86]\tvalid_0's multi_logloss: 1.65117\n",
            "[87]\tvalid_0's multi_logloss: 1.64803\n",
            "[88]\tvalid_0's multi_logloss: 1.6448\n",
            "[89]\tvalid_0's multi_logloss: 1.64183\n",
            "[90]\tvalid_0's multi_logloss: 1.63863\n",
            "[91]\tvalid_0's multi_logloss: 1.63563\n",
            "[92]\tvalid_0's multi_logloss: 1.63256\n",
            "[93]\tvalid_0's multi_logloss: 1.62955\n",
            "[94]\tvalid_0's multi_logloss: 1.62674\n",
            "[95]\tvalid_0's multi_logloss: 1.62372\n",
            "[96]\tvalid_0's multi_logloss: 1.62068\n",
            "[97]\tvalid_0's multi_logloss: 1.61787\n",
            "[98]\tvalid_0's multi_logloss: 1.61506\n",
            "[99]\tvalid_0's multi_logloss: 1.61224\n",
            "[100]\tvalid_0's multi_logloss: 1.6094\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 2.15951\n",
            "[2]\tvalid_0's multi_logloss: 2.14627\n",
            "[3]\tvalid_0's multi_logloss: 2.13384\n",
            "[4]\tvalid_0's multi_logloss: 2.12183\n",
            "[5]\tvalid_0's multi_logloss: 2.11033\n",
            "[6]\tvalid_0's multi_logloss: 2.0992\n",
            "[7]\tvalid_0's multi_logloss: 2.08844\n",
            "[8]\tvalid_0's multi_logloss: 2.07821\n",
            "[9]\tvalid_0's multi_logloss: 2.068\n",
            "[10]\tvalid_0's multi_logloss: 2.05824\n",
            "[11]\tvalid_0's multi_logloss: 2.04879\n",
            "[12]\tvalid_0's multi_logloss: 2.03966\n",
            "[13]\tvalid_0's multi_logloss: 2.03071\n",
            "[14]\tvalid_0's multi_logloss: 2.02196\n",
            "[15]\tvalid_0's multi_logloss: 2.01361\n",
            "[16]\tvalid_0's multi_logloss: 2.00536\n",
            "[17]\tvalid_0's multi_logloss: 1.99741\n",
            "[18]\tvalid_0's multi_logloss: 1.98958\n",
            "[19]\tvalid_0's multi_logloss: 1.98184\n",
            "[20]\tvalid_0's multi_logloss: 1.97452\n",
            "[21]\tvalid_0's multi_logloss: 1.96717\n",
            "[22]\tvalid_0's multi_logloss: 1.9597\n",
            "[23]\tvalid_0's multi_logloss: 1.95284\n",
            "[24]\tvalid_0's multi_logloss: 1.94587\n",
            "[25]\tvalid_0's multi_logloss: 1.93879\n",
            "[26]\tvalid_0's multi_logloss: 1.93221\n",
            "[27]\tvalid_0's multi_logloss: 1.92551\n",
            "[28]\tvalid_0's multi_logloss: 1.91917\n",
            "[29]\tvalid_0's multi_logloss: 1.91265\n",
            "[30]\tvalid_0's multi_logloss: 1.90655\n",
            "[31]\tvalid_0's multi_logloss: 1.90014\n",
            "[32]\tvalid_0's multi_logloss: 1.89406\n",
            "[33]\tvalid_0's multi_logloss: 1.88795\n",
            "[34]\tvalid_0's multi_logloss: 1.88197\n",
            "[35]\tvalid_0's multi_logloss: 1.87622\n",
            "[36]\tvalid_0's multi_logloss: 1.87045\n",
            "[37]\tvalid_0's multi_logloss: 1.86468\n",
            "[38]\tvalid_0's multi_logloss: 1.859\n",
            "[39]\tvalid_0's multi_logloss: 1.85341\n",
            "[40]\tvalid_0's multi_logloss: 1.84795\n",
            "[41]\tvalid_0's multi_logloss: 1.84268\n",
            "[42]\tvalid_0's multi_logloss: 1.83738\n",
            "[43]\tvalid_0's multi_logloss: 1.83213\n",
            "[44]\tvalid_0's multi_logloss: 1.82698\n",
            "[45]\tvalid_0's multi_logloss: 1.82183\n",
            "[46]\tvalid_0's multi_logloss: 1.81686\n",
            "[47]\tvalid_0's multi_logloss: 1.81188\n",
            "[48]\tvalid_0's multi_logloss: 1.80689\n",
            "[49]\tvalid_0's multi_logloss: 1.80227\n",
            "[50]\tvalid_0's multi_logloss: 1.79753\n",
            "[51]\tvalid_0's multi_logloss: 1.79285\n",
            "[52]\tvalid_0's multi_logloss: 1.78814\n",
            "[53]\tvalid_0's multi_logloss: 1.78344\n",
            "[54]\tvalid_0's multi_logloss: 1.77905\n",
            "[55]\tvalid_0's multi_logloss: 1.7746\n",
            "[56]\tvalid_0's multi_logloss: 1.77027\n",
            "[57]\tvalid_0's multi_logloss: 1.76588\n",
            "[58]\tvalid_0's multi_logloss: 1.7615\n",
            "[59]\tvalid_0's multi_logloss: 1.75725\n",
            "[60]\tvalid_0's multi_logloss: 1.75313\n",
            "[61]\tvalid_0's multi_logloss: 1.74897\n",
            "[62]\tvalid_0's multi_logloss: 1.74493\n",
            "[63]\tvalid_0's multi_logloss: 1.74092\n",
            "[64]\tvalid_0's multi_logloss: 1.73692\n",
            "[65]\tvalid_0's multi_logloss: 1.73278\n",
            "[66]\tvalid_0's multi_logloss: 1.72875\n",
            "[67]\tvalid_0's multi_logloss: 1.72469\n",
            "[68]\tvalid_0's multi_logloss: 1.72084\n",
            "[69]\tvalid_0's multi_logloss: 1.717\n",
            "[70]\tvalid_0's multi_logloss: 1.71314\n",
            "[71]\tvalid_0's multi_logloss: 1.70935\n",
            "[72]\tvalid_0's multi_logloss: 1.70576\n",
            "[73]\tvalid_0's multi_logloss: 1.70206\n",
            "[74]\tvalid_0's multi_logloss: 1.69837\n",
            "[75]\tvalid_0's multi_logloss: 1.69465\n",
            "[76]\tvalid_0's multi_logloss: 1.69113\n",
            "[77]\tvalid_0's multi_logloss: 1.6875\n",
            "[78]\tvalid_0's multi_logloss: 1.68389\n",
            "[79]\tvalid_0's multi_logloss: 1.68047\n",
            "[80]\tvalid_0's multi_logloss: 1.67697\n",
            "[81]\tvalid_0's multi_logloss: 1.67376\n",
            "[82]\tvalid_0's multi_logloss: 1.67046\n",
            "[83]\tvalid_0's multi_logloss: 1.66727\n",
            "[84]\tvalid_0's multi_logloss: 1.66389\n",
            "[85]\tvalid_0's multi_logloss: 1.66055\n",
            "[86]\tvalid_0's multi_logloss: 1.65734\n",
            "[87]\tvalid_0's multi_logloss: 1.6542\n",
            "[88]\tvalid_0's multi_logloss: 1.65096\n",
            "[89]\tvalid_0's multi_logloss: 1.64783\n",
            "[90]\tvalid_0's multi_logloss: 1.64478\n",
            "[91]\tvalid_0's multi_logloss: 1.64173\n",
            "[92]\tvalid_0's multi_logloss: 1.63882\n",
            "[93]\tvalid_0's multi_logloss: 1.63575\n",
            "[94]\tvalid_0's multi_logloss: 1.63277\n",
            "[95]\tvalid_0's multi_logloss: 1.62971\n",
            "[96]\tvalid_0's multi_logloss: 1.62677\n",
            "[97]\tvalid_0's multi_logloss: 1.62389\n",
            "[98]\tvalid_0's multi_logloss: 1.62104\n",
            "[99]\tvalid_0's multi_logloss: 1.6182\n",
            "[100]\tvalid_0's multi_logloss: 1.61533\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 2.07255\n",
            "[2]\tvalid_0's multi_logloss: 2.00097\n",
            "[3]\tvalid_0's multi_logloss: 1.94598\n",
            "[4]\tvalid_0's multi_logloss: 1.89947\n",
            "[5]\tvalid_0's multi_logloss: 1.85667\n",
            "[6]\tvalid_0's multi_logloss: 1.81832\n",
            "[7]\tvalid_0's multi_logloss: 1.78344\n",
            "[8]\tvalid_0's multi_logloss: 1.75238\n",
            "[9]\tvalid_0's multi_logloss: 1.72398\n",
            "[10]\tvalid_0's multi_logloss: 1.69933\n",
            "[11]\tvalid_0's multi_logloss: 1.67733\n",
            "[12]\tvalid_0's multi_logloss: 1.65678\n",
            "[13]\tvalid_0's multi_logloss: 1.63532\n",
            "[14]\tvalid_0's multi_logloss: 1.6168\n",
            "[15]\tvalid_0's multi_logloss: 1.59901\n",
            "[16]\tvalid_0's multi_logloss: 1.58232\n",
            "[17]\tvalid_0's multi_logloss: 1.56766\n",
            "[18]\tvalid_0's multi_logloss: 1.55281\n",
            "[19]\tvalid_0's multi_logloss: 1.53752\n",
            "[20]\tvalid_0's multi_logloss: 1.5245\n",
            "[21]\tvalid_0's multi_logloss: 1.51179\n",
            "[22]\tvalid_0's multi_logloss: 1.49981\n",
            "[23]\tvalid_0's multi_logloss: 1.48815\n",
            "[24]\tvalid_0's multi_logloss: 1.47864\n",
            "[25]\tvalid_0's multi_logloss: 1.46735\n",
            "[26]\tvalid_0's multi_logloss: 1.45762\n",
            "[27]\tvalid_0's multi_logloss: 1.44723\n",
            "[28]\tvalid_0's multi_logloss: 1.4375\n",
            "[29]\tvalid_0's multi_logloss: 1.42972\n",
            "[30]\tvalid_0's multi_logloss: 1.42182\n",
            "[31]\tvalid_0's multi_logloss: 1.41445\n",
            "[32]\tvalid_0's multi_logloss: 1.40702\n",
            "[33]\tvalid_0's multi_logloss: 1.39967\n",
            "[34]\tvalid_0's multi_logloss: 1.39265\n",
            "[35]\tvalid_0's multi_logloss: 1.38673\n",
            "[36]\tvalid_0's multi_logloss: 1.38043\n",
            "[37]\tvalid_0's multi_logloss: 1.37283\n",
            "[38]\tvalid_0's multi_logloss: 1.36686\n",
            "[39]\tvalid_0's multi_logloss: 1.36136\n",
            "[40]\tvalid_0's multi_logloss: 1.35595\n",
            "[41]\tvalid_0's multi_logloss: 1.34964\n",
            "[42]\tvalid_0's multi_logloss: 1.3445\n",
            "[43]\tvalid_0's multi_logloss: 1.33992\n",
            "[44]\tvalid_0's multi_logloss: 1.33583\n",
            "[45]\tvalid_0's multi_logloss: 1.33004\n",
            "[46]\tvalid_0's multi_logloss: 1.3263\n",
            "[47]\tvalid_0's multi_logloss: 1.32085\n",
            "[48]\tvalid_0's multi_logloss: 1.31645\n",
            "[49]\tvalid_0's multi_logloss: 1.31253\n",
            "[50]\tvalid_0's multi_logloss: 1.30751\n",
            "[51]\tvalid_0's multi_logloss: 1.30359\n",
            "[52]\tvalid_0's multi_logloss: 1.30001\n",
            "[53]\tvalid_0's multi_logloss: 1.29625\n",
            "[54]\tvalid_0's multi_logloss: 1.29184\n",
            "[55]\tvalid_0's multi_logloss: 1.28851\n",
            "[56]\tvalid_0's multi_logloss: 1.28501\n",
            "[57]\tvalid_0's multi_logloss: 1.28133\n",
            "[58]\tvalid_0's multi_logloss: 1.27791\n",
            "[59]\tvalid_0's multi_logloss: 1.275\n",
            "[60]\tvalid_0's multi_logloss: 1.27183\n",
            "[61]\tvalid_0's multi_logloss: 1.26888\n",
            "[62]\tvalid_0's multi_logloss: 1.26638\n",
            "[63]\tvalid_0's multi_logloss: 1.26352\n",
            "[64]\tvalid_0's multi_logloss: 1.25988\n",
            "[65]\tvalid_0's multi_logloss: 1.25659\n",
            "[66]\tvalid_0's multi_logloss: 1.25319\n",
            "[67]\tvalid_0's multi_logloss: 1.25053\n",
            "[68]\tvalid_0's multi_logloss: 1.24823\n",
            "[69]\tvalid_0's multi_logloss: 1.24575\n",
            "[70]\tvalid_0's multi_logloss: 1.24275\n",
            "[71]\tvalid_0's multi_logloss: 1.24062\n",
            "[72]\tvalid_0's multi_logloss: 1.23829\n",
            "[73]\tvalid_0's multi_logloss: 1.23614\n",
            "[74]\tvalid_0's multi_logloss: 1.23399\n",
            "[75]\tvalid_0's multi_logloss: 1.23207\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 2.07087\n",
            "[2]\tvalid_0's multi_logloss: 2.00287\n",
            "[3]\tvalid_0's multi_logloss: 1.94709\n",
            "[4]\tvalid_0's multi_logloss: 1.89947\n",
            "[5]\tvalid_0's multi_logloss: 1.85592\n",
            "[6]\tvalid_0's multi_logloss: 1.81751\n",
            "[7]\tvalid_0's multi_logloss: 1.78457\n",
            "[8]\tvalid_0's multi_logloss: 1.75454\n",
            "[9]\tvalid_0's multi_logloss: 1.72534\n",
            "[10]\tvalid_0's multi_logloss: 1.70122\n",
            "[11]\tvalid_0's multi_logloss: 1.67711\n",
            "[12]\tvalid_0's multi_logloss: 1.6544\n",
            "[13]\tvalid_0's multi_logloss: 1.63334\n",
            "[14]\tvalid_0's multi_logloss: 1.61223\n",
            "[15]\tvalid_0's multi_logloss: 1.59481\n",
            "[16]\tvalid_0's multi_logloss: 1.5783\n",
            "[17]\tvalid_0's multi_logloss: 1.56331\n",
            "[18]\tvalid_0's multi_logloss: 1.54874\n",
            "[19]\tvalid_0's multi_logloss: 1.53404\n",
            "[20]\tvalid_0's multi_logloss: 1.52017\n",
            "[21]\tvalid_0's multi_logloss: 1.50754\n",
            "[22]\tvalid_0's multi_logloss: 1.49581\n",
            "[23]\tvalid_0's multi_logloss: 1.48465\n",
            "[24]\tvalid_0's multi_logloss: 1.47417\n",
            "[25]\tvalid_0's multi_logloss: 1.46297\n",
            "[26]\tvalid_0's multi_logloss: 1.45288\n",
            "[27]\tvalid_0's multi_logloss: 1.44396\n",
            "[28]\tvalid_0's multi_logloss: 1.4349\n",
            "[29]\tvalid_0's multi_logloss: 1.42671\n",
            "[30]\tvalid_0's multi_logloss: 1.41822\n",
            "[31]\tvalid_0's multi_logloss: 1.40945\n",
            "[32]\tvalid_0's multi_logloss: 1.40161\n",
            "[33]\tvalid_0's multi_logloss: 1.39317\n",
            "[34]\tvalid_0's multi_logloss: 1.38598\n",
            "[35]\tvalid_0's multi_logloss: 1.37924\n",
            "[36]\tvalid_0's multi_logloss: 1.37325\n",
            "[37]\tvalid_0's multi_logloss: 1.36698\n",
            "[38]\tvalid_0's multi_logloss: 1.36056\n",
            "[39]\tvalid_0's multi_logloss: 1.35496\n",
            "[40]\tvalid_0's multi_logloss: 1.34882\n",
            "[41]\tvalid_0's multi_logloss: 1.34356\n",
            "[42]\tvalid_0's multi_logloss: 1.33858\n",
            "[43]\tvalid_0's multi_logloss: 1.33321\n",
            "[44]\tvalid_0's multi_logloss: 1.32832\n",
            "[45]\tvalid_0's multi_logloss: 1.32423\n",
            "[46]\tvalid_0's multi_logloss: 1.3193\n",
            "[47]\tvalid_0's multi_logloss: 1.31542\n",
            "[48]\tvalid_0's multi_logloss: 1.31083\n",
            "[49]\tvalid_0's multi_logloss: 1.30598\n",
            "[50]\tvalid_0's multi_logloss: 1.30184\n",
            "[51]\tvalid_0's multi_logloss: 1.29768\n",
            "[52]\tvalid_0's multi_logloss: 1.29429\n",
            "[53]\tvalid_0's multi_logloss: 1.29058\n",
            "[54]\tvalid_0's multi_logloss: 1.28748\n",
            "[55]\tvalid_0's multi_logloss: 1.2833\n",
            "[56]\tvalid_0's multi_logloss: 1.28026\n",
            "[57]\tvalid_0's multi_logloss: 1.2771\n",
            "[58]\tvalid_0's multi_logloss: 1.27373\n",
            "[59]\tvalid_0's multi_logloss: 1.27029\n",
            "[60]\tvalid_0's multi_logloss: 1.26683\n",
            "[61]\tvalid_0's multi_logloss: 1.26344\n",
            "[62]\tvalid_0's multi_logloss: 1.25992\n",
            "[63]\tvalid_0's multi_logloss: 1.25643\n",
            "[64]\tvalid_0's multi_logloss: 1.25292\n",
            "[65]\tvalid_0's multi_logloss: 1.24949\n",
            "[66]\tvalid_0's multi_logloss: 1.24701\n",
            "[67]\tvalid_0's multi_logloss: 1.24433\n",
            "[68]\tvalid_0's multi_logloss: 1.24178\n",
            "[69]\tvalid_0's multi_logloss: 1.23913\n",
            "[70]\tvalid_0's multi_logloss: 1.2367\n",
            "[71]\tvalid_0's multi_logloss: 1.2348\n",
            "[72]\tvalid_0's multi_logloss: 1.23296\n",
            "[73]\tvalid_0's multi_logloss: 1.23093\n",
            "[74]\tvalid_0's multi_logloss: 1.22869\n",
            "[75]\tvalid_0's multi_logloss: 1.22673\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 2.07394\n",
            "[2]\tvalid_0's multi_logloss: 2.00363\n",
            "[3]\tvalid_0's multi_logloss: 1.94766\n",
            "[4]\tvalid_0's multi_logloss: 1.90137\n",
            "[5]\tvalid_0's multi_logloss: 1.86032\n",
            "[6]\tvalid_0's multi_logloss: 1.82271\n",
            "[7]\tvalid_0's multi_logloss: 1.78901\n",
            "[8]\tvalid_0's multi_logloss: 1.75841\n",
            "[9]\tvalid_0's multi_logloss: 1.7313\n",
            "[10]\tvalid_0's multi_logloss: 1.70492\n",
            "[11]\tvalid_0's multi_logloss: 1.68199\n",
            "[12]\tvalid_0's multi_logloss: 1.65974\n",
            "[13]\tvalid_0's multi_logloss: 1.63901\n",
            "[14]\tvalid_0's multi_logloss: 1.6192\n",
            "[15]\tvalid_0's multi_logloss: 1.60173\n",
            "[16]\tvalid_0's multi_logloss: 1.58428\n",
            "[17]\tvalid_0's multi_logloss: 1.56821\n",
            "[18]\tvalid_0's multi_logloss: 1.55274\n",
            "[19]\tvalid_0's multi_logloss: 1.53946\n",
            "[20]\tvalid_0's multi_logloss: 1.52703\n",
            "[21]\tvalid_0's multi_logloss: 1.51427\n",
            "[22]\tvalid_0's multi_logloss: 1.50322\n",
            "[23]\tvalid_0's multi_logloss: 1.49163\n",
            "[24]\tvalid_0's multi_logloss: 1.48086\n",
            "[25]\tvalid_0's multi_logloss: 1.46988\n",
            "[26]\tvalid_0's multi_logloss: 1.46042\n",
            "[27]\tvalid_0's multi_logloss: 1.45159\n",
            "[28]\tvalid_0's multi_logloss: 1.44261\n",
            "[29]\tvalid_0's multi_logloss: 1.43341\n",
            "[30]\tvalid_0's multi_logloss: 1.42478\n",
            "[31]\tvalid_0's multi_logloss: 1.41688\n",
            "[32]\tvalid_0's multi_logloss: 1.40919\n",
            "[33]\tvalid_0's multi_logloss: 1.4014\n",
            "[34]\tvalid_0's multi_logloss: 1.39368\n",
            "[35]\tvalid_0's multi_logloss: 1.38672\n",
            "[36]\tvalid_0's multi_logloss: 1.38031\n",
            "[37]\tvalid_0's multi_logloss: 1.3744\n",
            "[38]\tvalid_0's multi_logloss: 1.36894\n",
            "[39]\tvalid_0's multi_logloss: 1.36287\n",
            "[40]\tvalid_0's multi_logloss: 1.35752\n",
            "[41]\tvalid_0's multi_logloss: 1.35249\n",
            "[42]\tvalid_0's multi_logloss: 1.34737\n",
            "[43]\tvalid_0's multi_logloss: 1.34225\n",
            "[44]\tvalid_0's multi_logloss: 1.3369\n",
            "[45]\tvalid_0's multi_logloss: 1.33276\n",
            "[46]\tvalid_0's multi_logloss: 1.32849\n",
            "[47]\tvalid_0's multi_logloss: 1.32464\n",
            "[48]\tvalid_0's multi_logloss: 1.31956\n",
            "[49]\tvalid_0's multi_logloss: 1.31462\n",
            "[50]\tvalid_0's multi_logloss: 1.31071\n",
            "[51]\tvalid_0's multi_logloss: 1.30699\n",
            "[52]\tvalid_0's multi_logloss: 1.30328\n",
            "[53]\tvalid_0's multi_logloss: 1.29976\n",
            "[54]\tvalid_0's multi_logloss: 1.29623\n",
            "[55]\tvalid_0's multi_logloss: 1.2935\n",
            "[56]\tvalid_0's multi_logloss: 1.28973\n",
            "[57]\tvalid_0's multi_logloss: 1.28648\n",
            "[58]\tvalid_0's multi_logloss: 1.28315\n",
            "[59]\tvalid_0's multi_logloss: 1.27984\n",
            "[60]\tvalid_0's multi_logloss: 1.27642\n",
            "[61]\tvalid_0's multi_logloss: 1.27365\n",
            "[62]\tvalid_0's multi_logloss: 1.27052\n",
            "[63]\tvalid_0's multi_logloss: 1.26738\n",
            "[64]\tvalid_0's multi_logloss: 1.26386\n",
            "[65]\tvalid_0's multi_logloss: 1.26153\n",
            "[66]\tvalid_0's multi_logloss: 1.25893\n",
            "[67]\tvalid_0's multi_logloss: 1.25601\n",
            "[68]\tvalid_0's multi_logloss: 1.25374\n",
            "[69]\tvalid_0's multi_logloss: 1.25136\n",
            "[70]\tvalid_0's multi_logloss: 1.24926\n",
            "[71]\tvalid_0's multi_logloss: 1.24698\n",
            "[72]\tvalid_0's multi_logloss: 1.24436\n",
            "[73]\tvalid_0's multi_logloss: 1.24247\n",
            "[74]\tvalid_0's multi_logloss: 1.24011\n",
            "[75]\tvalid_0's multi_logloss: 1.23823\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 2.06996\n",
            "[2]\tvalid_0's multi_logloss: 1.99902\n",
            "[3]\tvalid_0's multi_logloss: 1.94197\n",
            "[4]\tvalid_0's multi_logloss: 1.89465\n",
            "[5]\tvalid_0's multi_logloss: 1.85165\n",
            "[6]\tvalid_0's multi_logloss: 1.81594\n",
            "[7]\tvalid_0's multi_logloss: 1.78189\n",
            "[8]\tvalid_0's multi_logloss: 1.75146\n",
            "[9]\tvalid_0's multi_logloss: 1.72451\n",
            "[10]\tvalid_0's multi_logloss: 1.6987\n",
            "[11]\tvalid_0's multi_logloss: 1.67379\n",
            "[12]\tvalid_0's multi_logloss: 1.65165\n",
            "[13]\tvalid_0's multi_logloss: 1.62977\n",
            "[14]\tvalid_0's multi_logloss: 1.61082\n",
            "[15]\tvalid_0's multi_logloss: 1.59392\n",
            "[16]\tvalid_0's multi_logloss: 1.57757\n",
            "[17]\tvalid_0's multi_logloss: 1.56132\n",
            "[18]\tvalid_0's multi_logloss: 1.54803\n",
            "[19]\tvalid_0's multi_logloss: 1.53373\n",
            "[20]\tvalid_0's multi_logloss: 1.51971\n",
            "[21]\tvalid_0's multi_logloss: 1.50733\n",
            "[22]\tvalid_0's multi_logloss: 1.49506\n",
            "[23]\tvalid_0's multi_logloss: 1.48415\n",
            "[24]\tvalid_0's multi_logloss: 1.47315\n",
            "[25]\tvalid_0's multi_logloss: 1.46369\n",
            "[26]\tvalid_0's multi_logloss: 1.45422\n",
            "[27]\tvalid_0's multi_logloss: 1.44451\n",
            "[28]\tvalid_0's multi_logloss: 1.43624\n",
            "[29]\tvalid_0's multi_logloss: 1.42721\n",
            "[30]\tvalid_0's multi_logloss: 1.41896\n",
            "[31]\tvalid_0's multi_logloss: 1.41015\n",
            "[32]\tvalid_0's multi_logloss: 1.40236\n",
            "[33]\tvalid_0's multi_logloss: 1.39467\n",
            "[34]\tvalid_0's multi_logloss: 1.38837\n",
            "[35]\tvalid_0's multi_logloss: 1.38107\n",
            "[36]\tvalid_0's multi_logloss: 1.37539\n",
            "[37]\tvalid_0's multi_logloss: 1.36884\n",
            "[38]\tvalid_0's multi_logloss: 1.36332\n",
            "[39]\tvalid_0's multi_logloss: 1.35764\n",
            "[40]\tvalid_0's multi_logloss: 1.35179\n",
            "[41]\tvalid_0's multi_logloss: 1.34562\n",
            "[42]\tvalid_0's multi_logloss: 1.33981\n",
            "[43]\tvalid_0's multi_logloss: 1.33491\n",
            "[44]\tvalid_0's multi_logloss: 1.33017\n",
            "[45]\tvalid_0's multi_logloss: 1.32501\n",
            "[46]\tvalid_0's multi_logloss: 1.31937\n",
            "[47]\tvalid_0's multi_logloss: 1.31505\n",
            "[48]\tvalid_0's multi_logloss: 1.31054\n",
            "[49]\tvalid_0's multi_logloss: 1.30569\n",
            "[50]\tvalid_0's multi_logloss: 1.30141\n",
            "[51]\tvalid_0's multi_logloss: 1.29747\n",
            "[52]\tvalid_0's multi_logloss: 1.29403\n",
            "[53]\tvalid_0's multi_logloss: 1.29002\n",
            "[54]\tvalid_0's multi_logloss: 1.28575\n",
            "[55]\tvalid_0's multi_logloss: 1.28243\n",
            "[56]\tvalid_0's multi_logloss: 1.27873\n",
            "[57]\tvalid_0's multi_logloss: 1.27511\n",
            "[58]\tvalid_0's multi_logloss: 1.27173\n",
            "[59]\tvalid_0's multi_logloss: 1.26895\n",
            "[60]\tvalid_0's multi_logloss: 1.26515\n",
            "[61]\tvalid_0's multi_logloss: 1.26134\n",
            "[62]\tvalid_0's multi_logloss: 1.25847\n",
            "[63]\tvalid_0's multi_logloss: 1.25542\n",
            "[64]\tvalid_0's multi_logloss: 1.25257\n",
            "[65]\tvalid_0's multi_logloss: 1.25042\n",
            "[66]\tvalid_0's multi_logloss: 1.24748\n",
            "[67]\tvalid_0's multi_logloss: 1.24436\n",
            "[68]\tvalid_0's multi_logloss: 1.2421\n",
            "[69]\tvalid_0's multi_logloss: 1.23928\n",
            "[70]\tvalid_0's multi_logloss: 1.23645\n",
            "[71]\tvalid_0's multi_logloss: 1.23387\n",
            "[72]\tvalid_0's multi_logloss: 1.23144\n",
            "[73]\tvalid_0's multi_logloss: 1.22916\n",
            "[74]\tvalid_0's multi_logloss: 1.22725\n",
            "[75]\tvalid_0's multi_logloss: 1.22519\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 2.07062\n",
            "[2]\tvalid_0's multi_logloss: 2.00201\n",
            "[3]\tvalid_0's multi_logloss: 1.9488\n",
            "[4]\tvalid_0's multi_logloss: 1.90122\n",
            "[5]\tvalid_0's multi_logloss: 1.85827\n",
            "[6]\tvalid_0's multi_logloss: 1.81911\n",
            "[7]\tvalid_0's multi_logloss: 1.78489\n",
            "[8]\tvalid_0's multi_logloss: 1.75378\n",
            "[9]\tvalid_0's multi_logloss: 1.72628\n",
            "[10]\tvalid_0's multi_logloss: 1.70139\n",
            "[11]\tvalid_0's multi_logloss: 1.67678\n",
            "[12]\tvalid_0's multi_logloss: 1.65595\n",
            "[13]\tvalid_0's multi_logloss: 1.63529\n",
            "[14]\tvalid_0's multi_logloss: 1.61501\n",
            "[15]\tvalid_0's multi_logloss: 1.5973\n",
            "[16]\tvalid_0's multi_logloss: 1.58047\n",
            "[17]\tvalid_0's multi_logloss: 1.56464\n",
            "[18]\tvalid_0's multi_logloss: 1.55021\n",
            "[19]\tvalid_0's multi_logloss: 1.53562\n",
            "[20]\tvalid_0's multi_logloss: 1.52065\n",
            "[21]\tvalid_0's multi_logloss: 1.50909\n",
            "[22]\tvalid_0's multi_logloss: 1.49576\n",
            "[23]\tvalid_0's multi_logloss: 1.48445\n",
            "[24]\tvalid_0's multi_logloss: 1.47289\n",
            "[25]\tvalid_0's multi_logloss: 1.4629\n",
            "[26]\tvalid_0's multi_logloss: 1.45222\n",
            "[27]\tvalid_0's multi_logloss: 1.44271\n",
            "[28]\tvalid_0's multi_logloss: 1.43422\n",
            "[29]\tvalid_0's multi_logloss: 1.42585\n",
            "[30]\tvalid_0's multi_logloss: 1.41703\n",
            "[31]\tvalid_0's multi_logloss: 1.41024\n",
            "[32]\tvalid_0's multi_logloss: 1.40312\n",
            "[33]\tvalid_0's multi_logloss: 1.39567\n",
            "[34]\tvalid_0's multi_logloss: 1.3889\n",
            "[35]\tvalid_0's multi_logloss: 1.38217\n",
            "[36]\tvalid_0's multi_logloss: 1.37536\n",
            "[37]\tvalid_0's multi_logloss: 1.36946\n",
            "[38]\tvalid_0's multi_logloss: 1.36336\n",
            "[39]\tvalid_0's multi_logloss: 1.35729\n",
            "[40]\tvalid_0's multi_logloss: 1.35179\n",
            "[41]\tvalid_0's multi_logloss: 1.34595\n",
            "[42]\tvalid_0's multi_logloss: 1.34117\n",
            "[43]\tvalid_0's multi_logloss: 1.33548\n",
            "[44]\tvalid_0's multi_logloss: 1.33061\n",
            "[45]\tvalid_0's multi_logloss: 1.32555\n",
            "[46]\tvalid_0's multi_logloss: 1.32119\n",
            "[47]\tvalid_0's multi_logloss: 1.31643\n",
            "[48]\tvalid_0's multi_logloss: 1.31241\n",
            "[49]\tvalid_0's multi_logloss: 1.30846\n",
            "[50]\tvalid_0's multi_logloss: 1.30438\n",
            "[51]\tvalid_0's multi_logloss: 1.29994\n",
            "[52]\tvalid_0's multi_logloss: 1.29577\n",
            "[53]\tvalid_0's multi_logloss: 1.29197\n",
            "[54]\tvalid_0's multi_logloss: 1.28807\n",
            "[55]\tvalid_0's multi_logloss: 1.28426\n",
            "[56]\tvalid_0's multi_logloss: 1.27996\n",
            "[57]\tvalid_0's multi_logloss: 1.27672\n",
            "[58]\tvalid_0's multi_logloss: 1.27326\n",
            "[59]\tvalid_0's multi_logloss: 1.26966\n",
            "[60]\tvalid_0's multi_logloss: 1.26628\n",
            "[61]\tvalid_0's multi_logloss: 1.26398\n",
            "[62]\tvalid_0's multi_logloss: 1.26053\n",
            "[63]\tvalid_0's multi_logloss: 1.25816\n",
            "[64]\tvalid_0's multi_logloss: 1.25524\n",
            "[65]\tvalid_0's multi_logloss: 1.25206\n",
            "[66]\tvalid_0's multi_logloss: 1.24939\n",
            "[67]\tvalid_0's multi_logloss: 1.24691\n",
            "[68]\tvalid_0's multi_logloss: 1.24447\n",
            "[69]\tvalid_0's multi_logloss: 1.24225\n",
            "[70]\tvalid_0's multi_logloss: 1.23936\n",
            "[71]\tvalid_0's multi_logloss: 1.23664\n",
            "[72]\tvalid_0's multi_logloss: 1.23422\n",
            "[73]\tvalid_0's multi_logloss: 1.23198\n",
            "[74]\tvalid_0's multi_logloss: 1.22923\n",
            "[75]\tvalid_0's multi_logloss: 1.22651\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 2.04072\n",
            "[2]\tvalid_0's multi_logloss: 1.95184\n",
            "[3]\tvalid_0's multi_logloss: 1.88241\n",
            "[4]\tvalid_0's multi_logloss: 1.82616\n",
            "[5]\tvalid_0's multi_logloss: 1.7776\n",
            "[6]\tvalid_0's multi_logloss: 1.73345\n",
            "[7]\tvalid_0's multi_logloss: 1.69482\n",
            "[8]\tvalid_0's multi_logloss: 1.66189\n",
            "[9]\tvalid_0's multi_logloss: 1.63288\n",
            "[10]\tvalid_0's multi_logloss: 1.60556\n",
            "[11]\tvalid_0's multi_logloss: 1.57852\n",
            "[12]\tvalid_0's multi_logloss: 1.55408\n",
            "[13]\tvalid_0's multi_logloss: 1.53228\n",
            "[14]\tvalid_0's multi_logloss: 1.51086\n",
            "[15]\tvalid_0's multi_logloss: 1.49162\n",
            "[16]\tvalid_0's multi_logloss: 1.47376\n",
            "[17]\tvalid_0's multi_logloss: 1.45755\n",
            "[18]\tvalid_0's multi_logloss: 1.44267\n",
            "[19]\tvalid_0's multi_logloss: 1.4288\n",
            "[20]\tvalid_0's multi_logloss: 1.41599\n",
            "[21]\tvalid_0's multi_logloss: 1.40253\n",
            "[22]\tvalid_0's multi_logloss: 1.38908\n",
            "[23]\tvalid_0's multi_logloss: 1.37794\n",
            "[24]\tvalid_0's multi_logloss: 1.3663\n",
            "[25]\tvalid_0's multi_logloss: 1.35566\n",
            "[26]\tvalid_0's multi_logloss: 1.34631\n",
            "[27]\tvalid_0's multi_logloss: 1.3373\n",
            "[28]\tvalid_0's multi_logloss: 1.32848\n",
            "[29]\tvalid_0's multi_logloss: 1.32062\n",
            "[30]\tvalid_0's multi_logloss: 1.31265\n",
            "[31]\tvalid_0's multi_logloss: 1.30525\n",
            "[32]\tvalid_0's multi_logloss: 1.29809\n",
            "[33]\tvalid_0's multi_logloss: 1.29111\n",
            "[34]\tvalid_0's multi_logloss: 1.28389\n",
            "[35]\tvalid_0's multi_logloss: 1.27809\n",
            "[36]\tvalid_0's multi_logloss: 1.27233\n",
            "[37]\tvalid_0's multi_logloss: 1.26693\n",
            "[38]\tvalid_0's multi_logloss: 1.26106\n",
            "[39]\tvalid_0's multi_logloss: 1.25615\n",
            "[40]\tvalid_0's multi_logloss: 1.25039\n",
            "[41]\tvalid_0's multi_logloss: 1.24627\n",
            "[42]\tvalid_0's multi_logloss: 1.2409\n",
            "[43]\tvalid_0's multi_logloss: 1.23652\n",
            "[44]\tvalid_0's multi_logloss: 1.23235\n",
            "[45]\tvalid_0's multi_logloss: 1.22788\n",
            "[46]\tvalid_0's multi_logloss: 1.22412\n",
            "[47]\tvalid_0's multi_logloss: 1.22024\n",
            "[48]\tvalid_0's multi_logloss: 1.21624\n",
            "[49]\tvalid_0's multi_logloss: 1.21235\n",
            "[50]\tvalid_0's multi_logloss: 1.20834\n",
            "[51]\tvalid_0's multi_logloss: 1.20518\n",
            "[52]\tvalid_0's multi_logloss: 1.20195\n",
            "[53]\tvalid_0's multi_logloss: 1.19845\n",
            "[54]\tvalid_0's multi_logloss: 1.19531\n",
            "[55]\tvalid_0's multi_logloss: 1.19127\n",
            "[56]\tvalid_0's multi_logloss: 1.18863\n",
            "[57]\tvalid_0's multi_logloss: 1.18612\n",
            "[58]\tvalid_0's multi_logloss: 1.1828\n",
            "[59]\tvalid_0's multi_logloss: 1.18047\n",
            "[60]\tvalid_0's multi_logloss: 1.17811\n",
            "[61]\tvalid_0's multi_logloss: 1.17548\n",
            "[62]\tvalid_0's multi_logloss: 1.17309\n",
            "[63]\tvalid_0's multi_logloss: 1.17112\n",
            "[64]\tvalid_0's multi_logloss: 1.16856\n",
            "[65]\tvalid_0's multi_logloss: 1.16655\n",
            "[66]\tvalid_0's multi_logloss: 1.16387\n",
            "[67]\tvalid_0's multi_logloss: 1.16135\n",
            "[68]\tvalid_0's multi_logloss: 1.15955\n",
            "[69]\tvalid_0's multi_logloss: 1.15738\n",
            "[70]\tvalid_0's multi_logloss: 1.15547\n",
            "[71]\tvalid_0's multi_logloss: 1.15324\n",
            "[72]\tvalid_0's multi_logloss: 1.15217\n",
            "[73]\tvalid_0's multi_logloss: 1.15029\n",
            "[74]\tvalid_0's multi_logloss: 1.1484\n",
            "[75]\tvalid_0's multi_logloss: 1.14646\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 2.04184\n",
            "[2]\tvalid_0's multi_logloss: 1.95576\n",
            "[3]\tvalid_0's multi_logloss: 1.88901\n",
            "[4]\tvalid_0's multi_logloss: 1.82824\n",
            "[5]\tvalid_0's multi_logloss: 1.77967\n",
            "[6]\tvalid_0's multi_logloss: 1.7375\n",
            "[7]\tvalid_0's multi_logloss: 1.69797\n",
            "[8]\tvalid_0's multi_logloss: 1.66221\n",
            "[9]\tvalid_0's multi_logloss: 1.62991\n",
            "[10]\tvalid_0's multi_logloss: 1.60288\n",
            "[11]\tvalid_0's multi_logloss: 1.57654\n",
            "[12]\tvalid_0's multi_logloss: 1.55317\n",
            "[13]\tvalid_0's multi_logloss: 1.53086\n",
            "[14]\tvalid_0's multi_logloss: 1.51036\n",
            "[15]\tvalid_0's multi_logloss: 1.49198\n",
            "[16]\tvalid_0's multi_logloss: 1.4737\n",
            "[17]\tvalid_0's multi_logloss: 1.45763\n",
            "[18]\tvalid_0's multi_logloss: 1.44229\n",
            "[19]\tvalid_0's multi_logloss: 1.42752\n",
            "[20]\tvalid_0's multi_logloss: 1.41347\n",
            "[21]\tvalid_0's multi_logloss: 1.40117\n",
            "[22]\tvalid_0's multi_logloss: 1.38877\n",
            "[23]\tvalid_0's multi_logloss: 1.37733\n",
            "[24]\tvalid_0's multi_logloss: 1.366\n",
            "[25]\tvalid_0's multi_logloss: 1.3557\n",
            "[26]\tvalid_0's multi_logloss: 1.34674\n",
            "[27]\tvalid_0's multi_logloss: 1.33716\n",
            "[28]\tvalid_0's multi_logloss: 1.32899\n",
            "[29]\tvalid_0's multi_logloss: 1.31954\n",
            "[30]\tvalid_0's multi_logloss: 1.31141\n",
            "[31]\tvalid_0's multi_logloss: 1.30425\n",
            "[32]\tvalid_0's multi_logloss: 1.29623\n",
            "[33]\tvalid_0's multi_logloss: 1.29037\n",
            "[34]\tvalid_0's multi_logloss: 1.28349\n",
            "[35]\tvalid_0's multi_logloss: 1.27719\n",
            "[36]\tvalid_0's multi_logloss: 1.27174\n",
            "[37]\tvalid_0's multi_logloss: 1.26681\n",
            "[38]\tvalid_0's multi_logloss: 1.26167\n",
            "[39]\tvalid_0's multi_logloss: 1.25608\n",
            "[40]\tvalid_0's multi_logloss: 1.25052\n",
            "[41]\tvalid_0's multi_logloss: 1.24541\n",
            "[42]\tvalid_0's multi_logloss: 1.2401\n",
            "[43]\tvalid_0's multi_logloss: 1.2356\n",
            "[44]\tvalid_0's multi_logloss: 1.23112\n",
            "[45]\tvalid_0's multi_logloss: 1.22676\n",
            "[46]\tvalid_0's multi_logloss: 1.222\n",
            "[47]\tvalid_0's multi_logloss: 1.21803\n",
            "[48]\tvalid_0's multi_logloss: 1.21407\n",
            "[49]\tvalid_0's multi_logloss: 1.21056\n",
            "[50]\tvalid_0's multi_logloss: 1.20682\n",
            "[51]\tvalid_0's multi_logloss: 1.20433\n",
            "[52]\tvalid_0's multi_logloss: 1.20075\n",
            "[53]\tvalid_0's multi_logloss: 1.19711\n",
            "[54]\tvalid_0's multi_logloss: 1.19358\n",
            "[55]\tvalid_0's multi_logloss: 1.19047\n",
            "[56]\tvalid_0's multi_logloss: 1.18846\n",
            "[57]\tvalid_0's multi_logloss: 1.18563\n",
            "[58]\tvalid_0's multi_logloss: 1.18296\n",
            "[59]\tvalid_0's multi_logloss: 1.18033\n",
            "[60]\tvalid_0's multi_logloss: 1.17704\n",
            "[61]\tvalid_0's multi_logloss: 1.17439\n",
            "[62]\tvalid_0's multi_logloss: 1.17224\n",
            "[63]\tvalid_0's multi_logloss: 1.16957\n",
            "[64]\tvalid_0's multi_logloss: 1.16704\n",
            "[65]\tvalid_0's multi_logloss: 1.16426\n",
            "[66]\tvalid_0's multi_logloss: 1.16215\n",
            "[67]\tvalid_0's multi_logloss: 1.1599\n",
            "[68]\tvalid_0's multi_logloss: 1.15791\n",
            "[69]\tvalid_0's multi_logloss: 1.15557\n",
            "[70]\tvalid_0's multi_logloss: 1.15321\n",
            "[71]\tvalid_0's multi_logloss: 1.15136\n",
            "[72]\tvalid_0's multi_logloss: 1.15008\n",
            "[73]\tvalid_0's multi_logloss: 1.14739\n",
            "[74]\tvalid_0's multi_logloss: 1.14644\n",
            "[75]\tvalid_0's multi_logloss: 1.14467\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 2.04607\n",
            "[2]\tvalid_0's multi_logloss: 1.95546\n",
            "[3]\tvalid_0's multi_logloss: 1.88658\n",
            "[4]\tvalid_0's multi_logloss: 1.83081\n",
            "[5]\tvalid_0's multi_logloss: 1.78217\n",
            "[6]\tvalid_0's multi_logloss: 1.73747\n",
            "[7]\tvalid_0's multi_logloss: 1.69914\n",
            "[8]\tvalid_0's multi_logloss: 1.66571\n",
            "[9]\tvalid_0's multi_logloss: 1.6341\n",
            "[10]\tvalid_0's multi_logloss: 1.60668\n",
            "[11]\tvalid_0's multi_logloss: 1.5803\n",
            "[12]\tvalid_0's multi_logloss: 1.55606\n",
            "[13]\tvalid_0's multi_logloss: 1.53308\n",
            "[14]\tvalid_0's multi_logloss: 1.51409\n",
            "[15]\tvalid_0's multi_logloss: 1.49619\n",
            "[16]\tvalid_0's multi_logloss: 1.47922\n",
            "[17]\tvalid_0's multi_logloss: 1.46245\n",
            "[18]\tvalid_0's multi_logloss: 1.44631\n",
            "[19]\tvalid_0's multi_logloss: 1.43213\n",
            "[20]\tvalid_0's multi_logloss: 1.41844\n",
            "[21]\tvalid_0's multi_logloss: 1.40503\n",
            "[22]\tvalid_0's multi_logloss: 1.39313\n",
            "[23]\tvalid_0's multi_logloss: 1.38087\n",
            "[24]\tvalid_0's multi_logloss: 1.3697\n",
            "[25]\tvalid_0's multi_logloss: 1.35906\n",
            "[26]\tvalid_0's multi_logloss: 1.34899\n",
            "[27]\tvalid_0's multi_logloss: 1.34042\n",
            "[28]\tvalid_0's multi_logloss: 1.33138\n",
            "[29]\tvalid_0's multi_logloss: 1.32315\n",
            "[30]\tvalid_0's multi_logloss: 1.31516\n",
            "[31]\tvalid_0's multi_logloss: 1.30803\n",
            "[32]\tvalid_0's multi_logloss: 1.30121\n",
            "[33]\tvalid_0's multi_logloss: 1.29428\n",
            "[34]\tvalid_0's multi_logloss: 1.28824\n",
            "[35]\tvalid_0's multi_logloss: 1.28254\n",
            "[36]\tvalid_0's multi_logloss: 1.27667\n",
            "[37]\tvalid_0's multi_logloss: 1.27068\n",
            "[38]\tvalid_0's multi_logloss: 1.26508\n",
            "[39]\tvalid_0's multi_logloss: 1.25976\n",
            "[40]\tvalid_0's multi_logloss: 1.25462\n",
            "[41]\tvalid_0's multi_logloss: 1.24933\n",
            "[42]\tvalid_0's multi_logloss: 1.24511\n",
            "[43]\tvalid_0's multi_logloss: 1.24033\n",
            "[44]\tvalid_0's multi_logloss: 1.23582\n",
            "[45]\tvalid_0's multi_logloss: 1.23171\n",
            "[46]\tvalid_0's multi_logloss: 1.228\n",
            "[47]\tvalid_0's multi_logloss: 1.224\n",
            "[48]\tvalid_0's multi_logloss: 1.21977\n",
            "[49]\tvalid_0's multi_logloss: 1.21619\n",
            "[50]\tvalid_0's multi_logloss: 1.21326\n",
            "[51]\tvalid_0's multi_logloss: 1.20986\n",
            "[52]\tvalid_0's multi_logloss: 1.20651\n",
            "[53]\tvalid_0's multi_logloss: 1.20286\n",
            "[54]\tvalid_0's multi_logloss: 1.20094\n",
            "[55]\tvalid_0's multi_logloss: 1.19771\n",
            "[56]\tvalid_0's multi_logloss: 1.19459\n",
            "[57]\tvalid_0's multi_logloss: 1.19243\n",
            "[58]\tvalid_0's multi_logloss: 1.18981\n",
            "[59]\tvalid_0's multi_logloss: 1.1872\n",
            "[60]\tvalid_0's multi_logloss: 1.18477\n",
            "[61]\tvalid_0's multi_logloss: 1.18238\n",
            "[62]\tvalid_0's multi_logloss: 1.17951\n",
            "[63]\tvalid_0's multi_logloss: 1.17705\n",
            "[64]\tvalid_0's multi_logloss: 1.17505\n",
            "[65]\tvalid_0's multi_logloss: 1.17268\n",
            "[66]\tvalid_0's multi_logloss: 1.16994\n",
            "[67]\tvalid_0's multi_logloss: 1.16842\n",
            "[68]\tvalid_0's multi_logloss: 1.16627\n",
            "[69]\tvalid_0's multi_logloss: 1.16402\n",
            "[70]\tvalid_0's multi_logloss: 1.16139\n",
            "[71]\tvalid_0's multi_logloss: 1.15929\n",
            "[72]\tvalid_0's multi_logloss: 1.15788\n",
            "[73]\tvalid_0's multi_logloss: 1.15645\n",
            "[74]\tvalid_0's multi_logloss: 1.15465\n",
            "[75]\tvalid_0's multi_logloss: 1.15303\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 2.03953\n",
            "[2]\tvalid_0's multi_logloss: 1.94737\n",
            "[3]\tvalid_0's multi_logloss: 1.87915\n",
            "[4]\tvalid_0's multi_logloss: 1.82126\n",
            "[5]\tvalid_0's multi_logloss: 1.77167\n",
            "[6]\tvalid_0's multi_logloss: 1.72868\n",
            "[7]\tvalid_0's multi_logloss: 1.68825\n",
            "[8]\tvalid_0's multi_logloss: 1.65434\n",
            "[9]\tvalid_0's multi_logloss: 1.62357\n",
            "[10]\tvalid_0's multi_logloss: 1.596\n",
            "[11]\tvalid_0's multi_logloss: 1.5693\n",
            "[12]\tvalid_0's multi_logloss: 1.54615\n",
            "[13]\tvalid_0's multi_logloss: 1.52417\n",
            "[14]\tvalid_0's multi_logloss: 1.50513\n",
            "[15]\tvalid_0's multi_logloss: 1.48625\n",
            "[16]\tvalid_0's multi_logloss: 1.46817\n",
            "[17]\tvalid_0's multi_logloss: 1.45139\n",
            "[18]\tvalid_0's multi_logloss: 1.43608\n",
            "[19]\tvalid_0's multi_logloss: 1.42226\n",
            "[20]\tvalid_0's multi_logloss: 1.40865\n",
            "[21]\tvalid_0's multi_logloss: 1.39674\n",
            "[22]\tvalid_0's multi_logloss: 1.3843\n",
            "[23]\tvalid_0's multi_logloss: 1.37261\n",
            "[24]\tvalid_0's multi_logloss: 1.36199\n",
            "[25]\tvalid_0's multi_logloss: 1.35066\n",
            "[26]\tvalid_0's multi_logloss: 1.34107\n",
            "[27]\tvalid_0's multi_logloss: 1.33204\n",
            "[28]\tvalid_0's multi_logloss: 1.32368\n",
            "[29]\tvalid_0's multi_logloss: 1.31431\n",
            "[30]\tvalid_0's multi_logloss: 1.30635\n",
            "[31]\tvalid_0's multi_logloss: 1.29847\n",
            "[32]\tvalid_0's multi_logloss: 1.2917\n",
            "[33]\tvalid_0's multi_logloss: 1.28463\n",
            "[34]\tvalid_0's multi_logloss: 1.27774\n",
            "[35]\tvalid_0's multi_logloss: 1.27132\n",
            "[36]\tvalid_0's multi_logloss: 1.26489\n",
            "[37]\tvalid_0's multi_logloss: 1.25988\n",
            "[38]\tvalid_0's multi_logloss: 1.25434\n",
            "[39]\tvalid_0's multi_logloss: 1.24896\n",
            "[40]\tvalid_0's multi_logloss: 1.2433\n",
            "[41]\tvalid_0's multi_logloss: 1.2383\n",
            "[42]\tvalid_0's multi_logloss: 1.23367\n",
            "[43]\tvalid_0's multi_logloss: 1.22915\n",
            "[44]\tvalid_0's multi_logloss: 1.22531\n",
            "[45]\tvalid_0's multi_logloss: 1.22089\n",
            "[46]\tvalid_0's multi_logloss: 1.21608\n",
            "[47]\tvalid_0's multi_logloss: 1.2116\n",
            "[48]\tvalid_0's multi_logloss: 1.20833\n",
            "[49]\tvalid_0's multi_logloss: 1.20505\n",
            "[50]\tvalid_0's multi_logloss: 1.20139\n",
            "[51]\tvalid_0's multi_logloss: 1.19718\n",
            "[52]\tvalid_0's multi_logloss: 1.19364\n",
            "[53]\tvalid_0's multi_logloss: 1.19017\n",
            "[54]\tvalid_0's multi_logloss: 1.18739\n",
            "[55]\tvalid_0's multi_logloss: 1.18397\n",
            "[56]\tvalid_0's multi_logloss: 1.18116\n",
            "[57]\tvalid_0's multi_logloss: 1.17827\n",
            "[58]\tvalid_0's multi_logloss: 1.1756\n",
            "[59]\tvalid_0's multi_logloss: 1.17362\n",
            "[60]\tvalid_0's multi_logloss: 1.17083\n",
            "[61]\tvalid_0's multi_logloss: 1.16838\n",
            "[62]\tvalid_0's multi_logloss: 1.16587\n",
            "[63]\tvalid_0's multi_logloss: 1.16377\n",
            "[64]\tvalid_0's multi_logloss: 1.16217\n",
            "[65]\tvalid_0's multi_logloss: 1.16057\n",
            "[66]\tvalid_0's multi_logloss: 1.15865\n",
            "[67]\tvalid_0's multi_logloss: 1.15614\n",
            "[68]\tvalid_0's multi_logloss: 1.15423\n",
            "[69]\tvalid_0's multi_logloss: 1.15261\n",
            "[70]\tvalid_0's multi_logloss: 1.15042\n",
            "[71]\tvalid_0's multi_logloss: 1.14809\n",
            "[72]\tvalid_0's multi_logloss: 1.14622\n",
            "[73]\tvalid_0's multi_logloss: 1.14445\n",
            "[74]\tvalid_0's multi_logloss: 1.14303\n",
            "[75]\tvalid_0's multi_logloss: 1.14108\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 2.04122\n",
            "[2]\tvalid_0's multi_logloss: 1.95584\n",
            "[3]\tvalid_0's multi_logloss: 1.88796\n",
            "[4]\tvalid_0's multi_logloss: 1.83372\n",
            "[5]\tvalid_0's multi_logloss: 1.78456\n",
            "[6]\tvalid_0's multi_logloss: 1.73885\n",
            "[7]\tvalid_0's multi_logloss: 1.7003\n",
            "[8]\tvalid_0's multi_logloss: 1.665\n",
            "[9]\tvalid_0's multi_logloss: 1.63328\n",
            "[10]\tvalid_0's multi_logloss: 1.60487\n",
            "[11]\tvalid_0's multi_logloss: 1.57877\n",
            "[12]\tvalid_0's multi_logloss: 1.55441\n",
            "[13]\tvalid_0's multi_logloss: 1.5329\n",
            "[14]\tvalid_0's multi_logloss: 1.51116\n",
            "[15]\tvalid_0's multi_logloss: 1.49216\n",
            "[16]\tvalid_0's multi_logloss: 1.47267\n",
            "[17]\tvalid_0's multi_logloss: 1.45502\n",
            "[18]\tvalid_0's multi_logloss: 1.44018\n",
            "[19]\tvalid_0's multi_logloss: 1.42436\n",
            "[20]\tvalid_0's multi_logloss: 1.40987\n",
            "[21]\tvalid_0's multi_logloss: 1.39663\n",
            "[22]\tvalid_0's multi_logloss: 1.38356\n",
            "[23]\tvalid_0's multi_logloss: 1.37096\n",
            "[24]\tvalid_0's multi_logloss: 1.35991\n",
            "[25]\tvalid_0's multi_logloss: 1.35023\n",
            "[26]\tvalid_0's multi_logloss: 1.34155\n",
            "[27]\tvalid_0's multi_logloss: 1.33265\n",
            "[28]\tvalid_0's multi_logloss: 1.32365\n",
            "[29]\tvalid_0's multi_logloss: 1.31479\n",
            "[30]\tvalid_0's multi_logloss: 1.30722\n",
            "[31]\tvalid_0's multi_logloss: 1.29926\n",
            "[32]\tvalid_0's multi_logloss: 1.29208\n",
            "[33]\tvalid_0's multi_logloss: 1.28504\n",
            "[34]\tvalid_0's multi_logloss: 1.27816\n",
            "[35]\tvalid_0's multi_logloss: 1.27158\n",
            "[36]\tvalid_0's multi_logloss: 1.26587\n",
            "[37]\tvalid_0's multi_logloss: 1.26066\n",
            "[38]\tvalid_0's multi_logloss: 1.25614\n",
            "[39]\tvalid_0's multi_logloss: 1.25122\n",
            "[40]\tvalid_0's multi_logloss: 1.24705\n",
            "[41]\tvalid_0's multi_logloss: 1.24224\n",
            "[42]\tvalid_0's multi_logloss: 1.23765\n",
            "[43]\tvalid_0's multi_logloss: 1.23234\n",
            "[44]\tvalid_0's multi_logloss: 1.22889\n",
            "[45]\tvalid_0's multi_logloss: 1.22472\n",
            "[46]\tvalid_0's multi_logloss: 1.22053\n",
            "[47]\tvalid_0's multi_logloss: 1.21702\n",
            "[48]\tvalid_0's multi_logloss: 1.21351\n",
            "[49]\tvalid_0's multi_logloss: 1.2094\n",
            "[50]\tvalid_0's multi_logloss: 1.2059\n",
            "[51]\tvalid_0's multi_logloss: 1.20206\n",
            "[52]\tvalid_0's multi_logloss: 1.19825\n",
            "[53]\tvalid_0's multi_logloss: 1.1948\n",
            "[54]\tvalid_0's multi_logloss: 1.19152\n",
            "[55]\tvalid_0's multi_logloss: 1.18843\n",
            "[56]\tvalid_0's multi_logloss: 1.18537\n",
            "[57]\tvalid_0's multi_logloss: 1.18228\n",
            "[58]\tvalid_0's multi_logloss: 1.17897\n",
            "[59]\tvalid_0's multi_logloss: 1.17598\n",
            "[60]\tvalid_0's multi_logloss: 1.17337\n",
            "[61]\tvalid_0's multi_logloss: 1.17068\n",
            "[62]\tvalid_0's multi_logloss: 1.16834\n",
            "[63]\tvalid_0's multi_logloss: 1.16599\n",
            "[64]\tvalid_0's multi_logloss: 1.16408\n",
            "[65]\tvalid_0's multi_logloss: 1.16101\n",
            "[66]\tvalid_0's multi_logloss: 1.15891\n",
            "[67]\tvalid_0's multi_logloss: 1.15674\n",
            "[68]\tvalid_0's multi_logloss: 1.1551\n",
            "[69]\tvalid_0's multi_logloss: 1.15321\n",
            "[70]\tvalid_0's multi_logloss: 1.15075\n",
            "[71]\tvalid_0's multi_logloss: 1.14883\n",
            "[72]\tvalid_0's multi_logloss: 1.14675\n",
            "[73]\tvalid_0's multi_logloss: 1.1456\n",
            "[74]\tvalid_0's multi_logloss: 1.14438\n",
            "[75]\tvalid_0's multi_logloss: 1.14297\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 2.07255\n",
            "[2]\tvalid_0's multi_logloss: 2.00097\n",
            "[3]\tvalid_0's multi_logloss: 1.94598\n",
            "[4]\tvalid_0's multi_logloss: 1.89947\n",
            "[5]\tvalid_0's multi_logloss: 1.85667\n",
            "[6]\tvalid_0's multi_logloss: 1.81832\n",
            "[7]\tvalid_0's multi_logloss: 1.78344\n",
            "[8]\tvalid_0's multi_logloss: 1.75238\n",
            "[9]\tvalid_0's multi_logloss: 1.72398\n",
            "[10]\tvalid_0's multi_logloss: 1.69933\n",
            "[11]\tvalid_0's multi_logloss: 1.67733\n",
            "[12]\tvalid_0's multi_logloss: 1.65678\n",
            "[13]\tvalid_0's multi_logloss: 1.63532\n",
            "[14]\tvalid_0's multi_logloss: 1.6168\n",
            "[15]\tvalid_0's multi_logloss: 1.59901\n",
            "[16]\tvalid_0's multi_logloss: 1.58232\n",
            "[17]\tvalid_0's multi_logloss: 1.56766\n",
            "[18]\tvalid_0's multi_logloss: 1.55281\n",
            "[19]\tvalid_0's multi_logloss: 1.53752\n",
            "[20]\tvalid_0's multi_logloss: 1.5245\n",
            "[21]\tvalid_0's multi_logloss: 1.51179\n",
            "[22]\tvalid_0's multi_logloss: 1.49981\n",
            "[23]\tvalid_0's multi_logloss: 1.48815\n",
            "[24]\tvalid_0's multi_logloss: 1.47864\n",
            "[25]\tvalid_0's multi_logloss: 1.46735\n",
            "[26]\tvalid_0's multi_logloss: 1.45762\n",
            "[27]\tvalid_0's multi_logloss: 1.44723\n",
            "[28]\tvalid_0's multi_logloss: 1.4375\n",
            "[29]\tvalid_0's multi_logloss: 1.42972\n",
            "[30]\tvalid_0's multi_logloss: 1.42182\n",
            "[31]\tvalid_0's multi_logloss: 1.41445\n",
            "[32]\tvalid_0's multi_logloss: 1.40702\n",
            "[33]\tvalid_0's multi_logloss: 1.39967\n",
            "[34]\tvalid_0's multi_logloss: 1.39265\n",
            "[35]\tvalid_0's multi_logloss: 1.38673\n",
            "[36]\tvalid_0's multi_logloss: 1.38043\n",
            "[37]\tvalid_0's multi_logloss: 1.37283\n",
            "[38]\tvalid_0's multi_logloss: 1.36686\n",
            "[39]\tvalid_0's multi_logloss: 1.36136\n",
            "[40]\tvalid_0's multi_logloss: 1.35595\n",
            "[41]\tvalid_0's multi_logloss: 1.34964\n",
            "[42]\tvalid_0's multi_logloss: 1.3445\n",
            "[43]\tvalid_0's multi_logloss: 1.33992\n",
            "[44]\tvalid_0's multi_logloss: 1.33583\n",
            "[45]\tvalid_0's multi_logloss: 1.33004\n",
            "[46]\tvalid_0's multi_logloss: 1.3263\n",
            "[47]\tvalid_0's multi_logloss: 1.32085\n",
            "[48]\tvalid_0's multi_logloss: 1.31645\n",
            "[49]\tvalid_0's multi_logloss: 1.31253\n",
            "[50]\tvalid_0's multi_logloss: 1.30751\n",
            "[51]\tvalid_0's multi_logloss: 1.30359\n",
            "[52]\tvalid_0's multi_logloss: 1.30001\n",
            "[53]\tvalid_0's multi_logloss: 1.29625\n",
            "[54]\tvalid_0's multi_logloss: 1.29184\n",
            "[55]\tvalid_0's multi_logloss: 1.28851\n",
            "[56]\tvalid_0's multi_logloss: 1.28501\n",
            "[57]\tvalid_0's multi_logloss: 1.28133\n",
            "[58]\tvalid_0's multi_logloss: 1.27791\n",
            "[59]\tvalid_0's multi_logloss: 1.275\n",
            "[60]\tvalid_0's multi_logloss: 1.27183\n",
            "[61]\tvalid_0's multi_logloss: 1.26888\n",
            "[62]\tvalid_0's multi_logloss: 1.26638\n",
            "[63]\tvalid_0's multi_logloss: 1.26352\n",
            "[64]\tvalid_0's multi_logloss: 1.25988\n",
            "[65]\tvalid_0's multi_logloss: 1.25659\n",
            "[66]\tvalid_0's multi_logloss: 1.25319\n",
            "[67]\tvalid_0's multi_logloss: 1.25053\n",
            "[68]\tvalid_0's multi_logloss: 1.24823\n",
            "[69]\tvalid_0's multi_logloss: 1.24575\n",
            "[70]\tvalid_0's multi_logloss: 1.24275\n",
            "[71]\tvalid_0's multi_logloss: 1.24062\n",
            "[72]\tvalid_0's multi_logloss: 1.23829\n",
            "[73]\tvalid_0's multi_logloss: 1.23614\n",
            "[74]\tvalid_0's multi_logloss: 1.23399\n",
            "[75]\tvalid_0's multi_logloss: 1.23207\n",
            "[76]\tvalid_0's multi_logloss: 1.22967\n",
            "[77]\tvalid_0's multi_logloss: 1.22787\n",
            "[78]\tvalid_0's multi_logloss: 1.22626\n",
            "[79]\tvalid_0's multi_logloss: 1.22372\n",
            "[80]\tvalid_0's multi_logloss: 1.22185\n",
            "[81]\tvalid_0's multi_logloss: 1.21991\n",
            "[82]\tvalid_0's multi_logloss: 1.21848\n",
            "[83]\tvalid_0's multi_logloss: 1.21679\n",
            "[84]\tvalid_0's multi_logloss: 1.21484\n",
            "[85]\tvalid_0's multi_logloss: 1.21299\n",
            "[86]\tvalid_0's multi_logloss: 1.2111\n",
            "[87]\tvalid_0's multi_logloss: 1.20927\n",
            "[88]\tvalid_0's multi_logloss: 1.20775\n",
            "[89]\tvalid_0's multi_logloss: 1.20598\n",
            "[90]\tvalid_0's multi_logloss: 1.20437\n",
            "[91]\tvalid_0's multi_logloss: 1.20327\n",
            "[92]\tvalid_0's multi_logloss: 1.20125\n",
            "[93]\tvalid_0's multi_logloss: 1.19951\n",
            "[94]\tvalid_0's multi_logloss: 1.19765\n",
            "[95]\tvalid_0's multi_logloss: 1.19628\n",
            "[96]\tvalid_0's multi_logloss: 1.19456\n",
            "[97]\tvalid_0's multi_logloss: 1.19306\n",
            "[98]\tvalid_0's multi_logloss: 1.19158\n",
            "[99]\tvalid_0's multi_logloss: 1.19021\n",
            "[100]\tvalid_0's multi_logloss: 1.18874\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 2.07087\n",
            "[2]\tvalid_0's multi_logloss: 2.00287\n",
            "[3]\tvalid_0's multi_logloss: 1.94709\n",
            "[4]\tvalid_0's multi_logloss: 1.89947\n",
            "[5]\tvalid_0's multi_logloss: 1.85592\n",
            "[6]\tvalid_0's multi_logloss: 1.81751\n",
            "[7]\tvalid_0's multi_logloss: 1.78457\n",
            "[8]\tvalid_0's multi_logloss: 1.75454\n",
            "[9]\tvalid_0's multi_logloss: 1.72534\n",
            "[10]\tvalid_0's multi_logloss: 1.70122\n",
            "[11]\tvalid_0's multi_logloss: 1.67711\n",
            "[12]\tvalid_0's multi_logloss: 1.6544\n",
            "[13]\tvalid_0's multi_logloss: 1.63334\n",
            "[14]\tvalid_0's multi_logloss: 1.61223\n",
            "[15]\tvalid_0's multi_logloss: 1.59481\n",
            "[16]\tvalid_0's multi_logloss: 1.5783\n",
            "[17]\tvalid_0's multi_logloss: 1.56331\n",
            "[18]\tvalid_0's multi_logloss: 1.54874\n",
            "[19]\tvalid_0's multi_logloss: 1.53404\n",
            "[20]\tvalid_0's multi_logloss: 1.52017\n",
            "[21]\tvalid_0's multi_logloss: 1.50754\n",
            "[22]\tvalid_0's multi_logloss: 1.49581\n",
            "[23]\tvalid_0's multi_logloss: 1.48465\n",
            "[24]\tvalid_0's multi_logloss: 1.47417\n",
            "[25]\tvalid_0's multi_logloss: 1.46297\n",
            "[26]\tvalid_0's multi_logloss: 1.45288\n",
            "[27]\tvalid_0's multi_logloss: 1.44396\n",
            "[28]\tvalid_0's multi_logloss: 1.4349\n",
            "[29]\tvalid_0's multi_logloss: 1.42671\n",
            "[30]\tvalid_0's multi_logloss: 1.41822\n",
            "[31]\tvalid_0's multi_logloss: 1.40945\n",
            "[32]\tvalid_0's multi_logloss: 1.40161\n",
            "[33]\tvalid_0's multi_logloss: 1.39317\n",
            "[34]\tvalid_0's multi_logloss: 1.38598\n",
            "[35]\tvalid_0's multi_logloss: 1.37924\n",
            "[36]\tvalid_0's multi_logloss: 1.37325\n",
            "[37]\tvalid_0's multi_logloss: 1.36698\n",
            "[38]\tvalid_0's multi_logloss: 1.36056\n",
            "[39]\tvalid_0's multi_logloss: 1.35496\n",
            "[40]\tvalid_0's multi_logloss: 1.34882\n",
            "[41]\tvalid_0's multi_logloss: 1.34356\n",
            "[42]\tvalid_0's multi_logloss: 1.33858\n",
            "[43]\tvalid_0's multi_logloss: 1.33321\n",
            "[44]\tvalid_0's multi_logloss: 1.32832\n",
            "[45]\tvalid_0's multi_logloss: 1.32423\n",
            "[46]\tvalid_0's multi_logloss: 1.3193\n",
            "[47]\tvalid_0's multi_logloss: 1.31542\n",
            "[48]\tvalid_0's multi_logloss: 1.31083\n",
            "[49]\tvalid_0's multi_logloss: 1.30598\n",
            "[50]\tvalid_0's multi_logloss: 1.30184\n",
            "[51]\tvalid_0's multi_logloss: 1.29768\n",
            "[52]\tvalid_0's multi_logloss: 1.29429\n",
            "[53]\tvalid_0's multi_logloss: 1.29058\n",
            "[54]\tvalid_0's multi_logloss: 1.28748\n",
            "[55]\tvalid_0's multi_logloss: 1.2833\n",
            "[56]\tvalid_0's multi_logloss: 1.28026\n",
            "[57]\tvalid_0's multi_logloss: 1.2771\n",
            "[58]\tvalid_0's multi_logloss: 1.27373\n",
            "[59]\tvalid_0's multi_logloss: 1.27029\n",
            "[60]\tvalid_0's multi_logloss: 1.26683\n",
            "[61]\tvalid_0's multi_logloss: 1.26344\n",
            "[62]\tvalid_0's multi_logloss: 1.25992\n",
            "[63]\tvalid_0's multi_logloss: 1.25643\n",
            "[64]\tvalid_0's multi_logloss: 1.25292\n",
            "[65]\tvalid_0's multi_logloss: 1.24949\n",
            "[66]\tvalid_0's multi_logloss: 1.24701\n",
            "[67]\tvalid_0's multi_logloss: 1.24433\n",
            "[68]\tvalid_0's multi_logloss: 1.24178\n",
            "[69]\tvalid_0's multi_logloss: 1.23913\n",
            "[70]\tvalid_0's multi_logloss: 1.2367\n",
            "[71]\tvalid_0's multi_logloss: 1.2348\n",
            "[72]\tvalid_0's multi_logloss: 1.23296\n",
            "[73]\tvalid_0's multi_logloss: 1.23093\n",
            "[74]\tvalid_0's multi_logloss: 1.22869\n",
            "[75]\tvalid_0's multi_logloss: 1.22673\n",
            "[76]\tvalid_0's multi_logloss: 1.22455\n",
            "[77]\tvalid_0's multi_logloss: 1.22249\n",
            "[78]\tvalid_0's multi_logloss: 1.22009\n",
            "[79]\tvalid_0's multi_logloss: 1.21797\n",
            "[80]\tvalid_0's multi_logloss: 1.21581\n",
            "[81]\tvalid_0's multi_logloss: 1.21389\n",
            "[82]\tvalid_0's multi_logloss: 1.21227\n",
            "[83]\tvalid_0's multi_logloss: 1.21093\n",
            "[84]\tvalid_0's multi_logloss: 1.20887\n",
            "[85]\tvalid_0's multi_logloss: 1.2075\n",
            "[86]\tvalid_0's multi_logloss: 1.20627\n",
            "[87]\tvalid_0's multi_logloss: 1.20417\n",
            "[88]\tvalid_0's multi_logloss: 1.20235\n",
            "[89]\tvalid_0's multi_logloss: 1.20053\n",
            "[90]\tvalid_0's multi_logloss: 1.19876\n",
            "[91]\tvalid_0's multi_logloss: 1.19679\n",
            "[92]\tvalid_0's multi_logloss: 1.19518\n",
            "[93]\tvalid_0's multi_logloss: 1.19311\n",
            "[94]\tvalid_0's multi_logloss: 1.19166\n",
            "[95]\tvalid_0's multi_logloss: 1.18978\n",
            "[96]\tvalid_0's multi_logloss: 1.1882\n",
            "[97]\tvalid_0's multi_logloss: 1.18742\n",
            "[98]\tvalid_0's multi_logloss: 1.18587\n",
            "[99]\tvalid_0's multi_logloss: 1.18464\n",
            "[100]\tvalid_0's multi_logloss: 1.18345\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 2.07394\n",
            "[2]\tvalid_0's multi_logloss: 2.00363\n",
            "[3]\tvalid_0's multi_logloss: 1.94766\n",
            "[4]\tvalid_0's multi_logloss: 1.90137\n",
            "[5]\tvalid_0's multi_logloss: 1.86032\n",
            "[6]\tvalid_0's multi_logloss: 1.82271\n",
            "[7]\tvalid_0's multi_logloss: 1.78901\n",
            "[8]\tvalid_0's multi_logloss: 1.75841\n",
            "[9]\tvalid_0's multi_logloss: 1.7313\n",
            "[10]\tvalid_0's multi_logloss: 1.70492\n",
            "[11]\tvalid_0's multi_logloss: 1.68199\n",
            "[12]\tvalid_0's multi_logloss: 1.65974\n",
            "[13]\tvalid_0's multi_logloss: 1.63901\n",
            "[14]\tvalid_0's multi_logloss: 1.6192\n",
            "[15]\tvalid_0's multi_logloss: 1.60173\n",
            "[16]\tvalid_0's multi_logloss: 1.58428\n",
            "[17]\tvalid_0's multi_logloss: 1.56821\n",
            "[18]\tvalid_0's multi_logloss: 1.55274\n",
            "[19]\tvalid_0's multi_logloss: 1.53946\n",
            "[20]\tvalid_0's multi_logloss: 1.52703\n",
            "[21]\tvalid_0's multi_logloss: 1.51427\n",
            "[22]\tvalid_0's multi_logloss: 1.50322\n",
            "[23]\tvalid_0's multi_logloss: 1.49163\n",
            "[24]\tvalid_0's multi_logloss: 1.48086\n",
            "[25]\tvalid_0's multi_logloss: 1.46988\n",
            "[26]\tvalid_0's multi_logloss: 1.46042\n",
            "[27]\tvalid_0's multi_logloss: 1.45159\n",
            "[28]\tvalid_0's multi_logloss: 1.44261\n",
            "[29]\tvalid_0's multi_logloss: 1.43341\n",
            "[30]\tvalid_0's multi_logloss: 1.42478\n",
            "[31]\tvalid_0's multi_logloss: 1.41688\n",
            "[32]\tvalid_0's multi_logloss: 1.40919\n",
            "[33]\tvalid_0's multi_logloss: 1.4014\n",
            "[34]\tvalid_0's multi_logloss: 1.39368\n",
            "[35]\tvalid_0's multi_logloss: 1.38672\n",
            "[36]\tvalid_0's multi_logloss: 1.38031\n",
            "[37]\tvalid_0's multi_logloss: 1.3744\n",
            "[38]\tvalid_0's multi_logloss: 1.36894\n",
            "[39]\tvalid_0's multi_logloss: 1.36287\n",
            "[40]\tvalid_0's multi_logloss: 1.35752\n",
            "[41]\tvalid_0's multi_logloss: 1.35249\n",
            "[42]\tvalid_0's multi_logloss: 1.34737\n",
            "[43]\tvalid_0's multi_logloss: 1.34225\n",
            "[44]\tvalid_0's multi_logloss: 1.3369\n",
            "[45]\tvalid_0's multi_logloss: 1.33276\n",
            "[46]\tvalid_0's multi_logloss: 1.32849\n",
            "[47]\tvalid_0's multi_logloss: 1.32464\n",
            "[48]\tvalid_0's multi_logloss: 1.31956\n",
            "[49]\tvalid_0's multi_logloss: 1.31462\n",
            "[50]\tvalid_0's multi_logloss: 1.31071\n",
            "[51]\tvalid_0's multi_logloss: 1.30699\n",
            "[52]\tvalid_0's multi_logloss: 1.30328\n",
            "[53]\tvalid_0's multi_logloss: 1.29976\n",
            "[54]\tvalid_0's multi_logloss: 1.29623\n",
            "[55]\tvalid_0's multi_logloss: 1.2935\n",
            "[56]\tvalid_0's multi_logloss: 1.28973\n",
            "[57]\tvalid_0's multi_logloss: 1.28648\n",
            "[58]\tvalid_0's multi_logloss: 1.28315\n",
            "[59]\tvalid_0's multi_logloss: 1.27984\n",
            "[60]\tvalid_0's multi_logloss: 1.27642\n",
            "[61]\tvalid_0's multi_logloss: 1.27365\n",
            "[62]\tvalid_0's multi_logloss: 1.27052\n",
            "[63]\tvalid_0's multi_logloss: 1.26738\n",
            "[64]\tvalid_0's multi_logloss: 1.26386\n",
            "[65]\tvalid_0's multi_logloss: 1.26153\n",
            "[66]\tvalid_0's multi_logloss: 1.25893\n",
            "[67]\tvalid_0's multi_logloss: 1.25601\n",
            "[68]\tvalid_0's multi_logloss: 1.25374\n",
            "[69]\tvalid_0's multi_logloss: 1.25136\n",
            "[70]\tvalid_0's multi_logloss: 1.24926\n",
            "[71]\tvalid_0's multi_logloss: 1.24698\n",
            "[72]\tvalid_0's multi_logloss: 1.24436\n",
            "[73]\tvalid_0's multi_logloss: 1.24247\n",
            "[74]\tvalid_0's multi_logloss: 1.24011\n",
            "[75]\tvalid_0's multi_logloss: 1.23823\n",
            "[76]\tvalid_0's multi_logloss: 1.23652\n",
            "[77]\tvalid_0's multi_logloss: 1.23451\n",
            "[78]\tvalid_0's multi_logloss: 1.23266\n",
            "[79]\tvalid_0's multi_logloss: 1.23055\n",
            "[80]\tvalid_0's multi_logloss: 1.22881\n",
            "[81]\tvalid_0's multi_logloss: 1.22685\n",
            "[82]\tvalid_0's multi_logloss: 1.22534\n",
            "[83]\tvalid_0's multi_logloss: 1.22373\n",
            "[84]\tvalid_0's multi_logloss: 1.22229\n",
            "[85]\tvalid_0's multi_logloss: 1.22067\n",
            "[86]\tvalid_0's multi_logloss: 1.21849\n",
            "[87]\tvalid_0's multi_logloss: 1.21699\n",
            "[88]\tvalid_0's multi_logloss: 1.21492\n",
            "[89]\tvalid_0's multi_logloss: 1.21288\n",
            "[90]\tvalid_0's multi_logloss: 1.21112\n",
            "[91]\tvalid_0's multi_logloss: 1.20988\n",
            "[92]\tvalid_0's multi_logloss: 1.20811\n",
            "[93]\tvalid_0's multi_logloss: 1.20682\n",
            "[94]\tvalid_0's multi_logloss: 1.20539\n",
            "[95]\tvalid_0's multi_logloss: 1.20355\n",
            "[96]\tvalid_0's multi_logloss: 1.20217\n",
            "[97]\tvalid_0's multi_logloss: 1.20097\n",
            "[98]\tvalid_0's multi_logloss: 1.19926\n",
            "[99]\tvalid_0's multi_logloss: 1.19768\n",
            "[100]\tvalid_0's multi_logloss: 1.19633\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 2.06996\n",
            "[2]\tvalid_0's multi_logloss: 1.99902\n",
            "[3]\tvalid_0's multi_logloss: 1.94197\n",
            "[4]\tvalid_0's multi_logloss: 1.89465\n",
            "[5]\tvalid_0's multi_logloss: 1.85165\n",
            "[6]\tvalid_0's multi_logloss: 1.81594\n",
            "[7]\tvalid_0's multi_logloss: 1.78189\n",
            "[8]\tvalid_0's multi_logloss: 1.75146\n",
            "[9]\tvalid_0's multi_logloss: 1.72451\n",
            "[10]\tvalid_0's multi_logloss: 1.6987\n",
            "[11]\tvalid_0's multi_logloss: 1.67379\n",
            "[12]\tvalid_0's multi_logloss: 1.65165\n",
            "[13]\tvalid_0's multi_logloss: 1.62977\n",
            "[14]\tvalid_0's multi_logloss: 1.61082\n",
            "[15]\tvalid_0's multi_logloss: 1.59392\n",
            "[16]\tvalid_0's multi_logloss: 1.57757\n",
            "[17]\tvalid_0's multi_logloss: 1.56132\n",
            "[18]\tvalid_0's multi_logloss: 1.54803\n",
            "[19]\tvalid_0's multi_logloss: 1.53373\n",
            "[20]\tvalid_0's multi_logloss: 1.51971\n",
            "[21]\tvalid_0's multi_logloss: 1.50733\n",
            "[22]\tvalid_0's multi_logloss: 1.49506\n",
            "[23]\tvalid_0's multi_logloss: 1.48415\n",
            "[24]\tvalid_0's multi_logloss: 1.47315\n",
            "[25]\tvalid_0's multi_logloss: 1.46369\n",
            "[26]\tvalid_0's multi_logloss: 1.45422\n",
            "[27]\tvalid_0's multi_logloss: 1.44451\n",
            "[28]\tvalid_0's multi_logloss: 1.43624\n",
            "[29]\tvalid_0's multi_logloss: 1.42721\n",
            "[30]\tvalid_0's multi_logloss: 1.41896\n",
            "[31]\tvalid_0's multi_logloss: 1.41015\n",
            "[32]\tvalid_0's multi_logloss: 1.40236\n",
            "[33]\tvalid_0's multi_logloss: 1.39467\n",
            "[34]\tvalid_0's multi_logloss: 1.38837\n",
            "[35]\tvalid_0's multi_logloss: 1.38107\n",
            "[36]\tvalid_0's multi_logloss: 1.37539\n",
            "[37]\tvalid_0's multi_logloss: 1.36884\n",
            "[38]\tvalid_0's multi_logloss: 1.36332\n",
            "[39]\tvalid_0's multi_logloss: 1.35764\n",
            "[40]\tvalid_0's multi_logloss: 1.35179\n",
            "[41]\tvalid_0's multi_logloss: 1.34562\n",
            "[42]\tvalid_0's multi_logloss: 1.33981\n",
            "[43]\tvalid_0's multi_logloss: 1.33491\n",
            "[44]\tvalid_0's multi_logloss: 1.33017\n",
            "[45]\tvalid_0's multi_logloss: 1.32501\n",
            "[46]\tvalid_0's multi_logloss: 1.31937\n",
            "[47]\tvalid_0's multi_logloss: 1.31505\n",
            "[48]\tvalid_0's multi_logloss: 1.31054\n",
            "[49]\tvalid_0's multi_logloss: 1.30569\n",
            "[50]\tvalid_0's multi_logloss: 1.30141\n",
            "[51]\tvalid_0's multi_logloss: 1.29747\n",
            "[52]\tvalid_0's multi_logloss: 1.29403\n",
            "[53]\tvalid_0's multi_logloss: 1.29002\n",
            "[54]\tvalid_0's multi_logloss: 1.28575\n",
            "[55]\tvalid_0's multi_logloss: 1.28243\n",
            "[56]\tvalid_0's multi_logloss: 1.27873\n",
            "[57]\tvalid_0's multi_logloss: 1.27511\n",
            "[58]\tvalid_0's multi_logloss: 1.27173\n",
            "[59]\tvalid_0's multi_logloss: 1.26895\n",
            "[60]\tvalid_0's multi_logloss: 1.26515\n",
            "[61]\tvalid_0's multi_logloss: 1.26134\n",
            "[62]\tvalid_0's multi_logloss: 1.25847\n",
            "[63]\tvalid_0's multi_logloss: 1.25542\n",
            "[64]\tvalid_0's multi_logloss: 1.25257\n",
            "[65]\tvalid_0's multi_logloss: 1.25042\n",
            "[66]\tvalid_0's multi_logloss: 1.24748\n",
            "[67]\tvalid_0's multi_logloss: 1.24436\n",
            "[68]\tvalid_0's multi_logloss: 1.2421\n",
            "[69]\tvalid_0's multi_logloss: 1.23928\n",
            "[70]\tvalid_0's multi_logloss: 1.23645\n",
            "[71]\tvalid_0's multi_logloss: 1.23387\n",
            "[72]\tvalid_0's multi_logloss: 1.23144\n",
            "[73]\tvalid_0's multi_logloss: 1.22916\n",
            "[74]\tvalid_0's multi_logloss: 1.22725\n",
            "[75]\tvalid_0's multi_logloss: 1.22519\n",
            "[76]\tvalid_0's multi_logloss: 1.22277\n",
            "[77]\tvalid_0's multi_logloss: 1.22051\n",
            "[78]\tvalid_0's multi_logloss: 1.21819\n",
            "[79]\tvalid_0's multi_logloss: 1.21582\n",
            "[80]\tvalid_0's multi_logloss: 1.21355\n",
            "[81]\tvalid_0's multi_logloss: 1.21187\n",
            "[82]\tvalid_0's multi_logloss: 1.20997\n",
            "[83]\tvalid_0's multi_logloss: 1.20803\n",
            "[84]\tvalid_0's multi_logloss: 1.20635\n",
            "[85]\tvalid_0's multi_logloss: 1.20444\n",
            "[86]\tvalid_0's multi_logloss: 1.2025\n",
            "[87]\tvalid_0's multi_logloss: 1.20076\n",
            "[88]\tvalid_0's multi_logloss: 1.1991\n",
            "[89]\tvalid_0's multi_logloss: 1.19729\n",
            "[90]\tvalid_0's multi_logloss: 1.19532\n",
            "[91]\tvalid_0's multi_logloss: 1.19365\n",
            "[92]\tvalid_0's multi_logloss: 1.19236\n",
            "[93]\tvalid_0's multi_logloss: 1.19101\n",
            "[94]\tvalid_0's multi_logloss: 1.1895\n",
            "[95]\tvalid_0's multi_logloss: 1.18823\n",
            "[96]\tvalid_0's multi_logloss: 1.18644\n",
            "[97]\tvalid_0's multi_logloss: 1.18482\n",
            "[98]\tvalid_0's multi_logloss: 1.18327\n",
            "[99]\tvalid_0's multi_logloss: 1.18193\n",
            "[100]\tvalid_0's multi_logloss: 1.18062\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 2.07062\n",
            "[2]\tvalid_0's multi_logloss: 2.00201\n",
            "[3]\tvalid_0's multi_logloss: 1.9488\n",
            "[4]\tvalid_0's multi_logloss: 1.90122\n",
            "[5]\tvalid_0's multi_logloss: 1.85827\n",
            "[6]\tvalid_0's multi_logloss: 1.81911\n",
            "[7]\tvalid_0's multi_logloss: 1.78489\n",
            "[8]\tvalid_0's multi_logloss: 1.75378\n",
            "[9]\tvalid_0's multi_logloss: 1.72628\n",
            "[10]\tvalid_0's multi_logloss: 1.70139\n",
            "[11]\tvalid_0's multi_logloss: 1.67678\n",
            "[12]\tvalid_0's multi_logloss: 1.65595\n",
            "[13]\tvalid_0's multi_logloss: 1.63529\n",
            "[14]\tvalid_0's multi_logloss: 1.61501\n",
            "[15]\tvalid_0's multi_logloss: 1.5973\n",
            "[16]\tvalid_0's multi_logloss: 1.58047\n",
            "[17]\tvalid_0's multi_logloss: 1.56464\n",
            "[18]\tvalid_0's multi_logloss: 1.55021\n",
            "[19]\tvalid_0's multi_logloss: 1.53562\n",
            "[20]\tvalid_0's multi_logloss: 1.52065\n",
            "[21]\tvalid_0's multi_logloss: 1.50909\n",
            "[22]\tvalid_0's multi_logloss: 1.49576\n",
            "[23]\tvalid_0's multi_logloss: 1.48445\n",
            "[24]\tvalid_0's multi_logloss: 1.47289\n",
            "[25]\tvalid_0's multi_logloss: 1.4629\n",
            "[26]\tvalid_0's multi_logloss: 1.45222\n",
            "[27]\tvalid_0's multi_logloss: 1.44271\n",
            "[28]\tvalid_0's multi_logloss: 1.43422\n",
            "[29]\tvalid_0's multi_logloss: 1.42585\n",
            "[30]\tvalid_0's multi_logloss: 1.41703\n",
            "[31]\tvalid_0's multi_logloss: 1.41024\n",
            "[32]\tvalid_0's multi_logloss: 1.40312\n",
            "[33]\tvalid_0's multi_logloss: 1.39567\n",
            "[34]\tvalid_0's multi_logloss: 1.3889\n",
            "[35]\tvalid_0's multi_logloss: 1.38217\n",
            "[36]\tvalid_0's multi_logloss: 1.37536\n",
            "[37]\tvalid_0's multi_logloss: 1.36946\n",
            "[38]\tvalid_0's multi_logloss: 1.36336\n",
            "[39]\tvalid_0's multi_logloss: 1.35729\n",
            "[40]\tvalid_0's multi_logloss: 1.35179\n",
            "[41]\tvalid_0's multi_logloss: 1.34595\n",
            "[42]\tvalid_0's multi_logloss: 1.34117\n",
            "[43]\tvalid_0's multi_logloss: 1.33548\n",
            "[44]\tvalid_0's multi_logloss: 1.33061\n",
            "[45]\tvalid_0's multi_logloss: 1.32555\n",
            "[46]\tvalid_0's multi_logloss: 1.32119\n",
            "[47]\tvalid_0's multi_logloss: 1.31643\n",
            "[48]\tvalid_0's multi_logloss: 1.31241\n",
            "[49]\tvalid_0's multi_logloss: 1.30846\n",
            "[50]\tvalid_0's multi_logloss: 1.30438\n",
            "[51]\tvalid_0's multi_logloss: 1.29994\n",
            "[52]\tvalid_0's multi_logloss: 1.29577\n",
            "[53]\tvalid_0's multi_logloss: 1.29197\n",
            "[54]\tvalid_0's multi_logloss: 1.28807\n",
            "[55]\tvalid_0's multi_logloss: 1.28426\n",
            "[56]\tvalid_0's multi_logloss: 1.27996\n",
            "[57]\tvalid_0's multi_logloss: 1.27672\n",
            "[58]\tvalid_0's multi_logloss: 1.27326\n",
            "[59]\tvalid_0's multi_logloss: 1.26966\n",
            "[60]\tvalid_0's multi_logloss: 1.26628\n",
            "[61]\tvalid_0's multi_logloss: 1.26398\n",
            "[62]\tvalid_0's multi_logloss: 1.26053\n",
            "[63]\tvalid_0's multi_logloss: 1.25816\n",
            "[64]\tvalid_0's multi_logloss: 1.25524\n",
            "[65]\tvalid_0's multi_logloss: 1.25206\n",
            "[66]\tvalid_0's multi_logloss: 1.24939\n",
            "[67]\tvalid_0's multi_logloss: 1.24691\n",
            "[68]\tvalid_0's multi_logloss: 1.24447\n",
            "[69]\tvalid_0's multi_logloss: 1.24225\n",
            "[70]\tvalid_0's multi_logloss: 1.23936\n",
            "[71]\tvalid_0's multi_logloss: 1.23664\n",
            "[72]\tvalid_0's multi_logloss: 1.23422\n",
            "[73]\tvalid_0's multi_logloss: 1.23198\n",
            "[74]\tvalid_0's multi_logloss: 1.22923\n",
            "[75]\tvalid_0's multi_logloss: 1.22651\n",
            "[76]\tvalid_0's multi_logloss: 1.22441\n",
            "[77]\tvalid_0's multi_logloss: 1.22256\n",
            "[78]\tvalid_0's multi_logloss: 1.22089\n",
            "[79]\tvalid_0's multi_logloss: 1.21934\n",
            "[80]\tvalid_0's multi_logloss: 1.21777\n",
            "[81]\tvalid_0's multi_logloss: 1.21562\n",
            "[82]\tvalid_0's multi_logloss: 1.21381\n",
            "[83]\tvalid_0's multi_logloss: 1.21222\n",
            "[84]\tvalid_0's multi_logloss: 1.21072\n",
            "[85]\tvalid_0's multi_logloss: 1.2084\n",
            "[86]\tvalid_0's multi_logloss: 1.20611\n",
            "[87]\tvalid_0's multi_logloss: 1.20419\n",
            "[88]\tvalid_0's multi_logloss: 1.20248\n",
            "[89]\tvalid_0's multi_logloss: 1.20088\n",
            "[90]\tvalid_0's multi_logloss: 1.19912\n",
            "[91]\tvalid_0's multi_logloss: 1.19706\n",
            "[92]\tvalid_0's multi_logloss: 1.19516\n",
            "[93]\tvalid_0's multi_logloss: 1.19359\n",
            "[94]\tvalid_0's multi_logloss: 1.19237\n",
            "[95]\tvalid_0's multi_logloss: 1.19089\n",
            "[96]\tvalid_0's multi_logloss: 1.18974\n",
            "[97]\tvalid_0's multi_logloss: 1.18819\n",
            "[98]\tvalid_0's multi_logloss: 1.18696\n",
            "[99]\tvalid_0's multi_logloss: 1.18615\n",
            "[100]\tvalid_0's multi_logloss: 1.18504\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 2.04072\n",
            "[2]\tvalid_0's multi_logloss: 1.95184\n",
            "[3]\tvalid_0's multi_logloss: 1.88241\n",
            "[4]\tvalid_0's multi_logloss: 1.82616\n",
            "[5]\tvalid_0's multi_logloss: 1.7776\n",
            "[6]\tvalid_0's multi_logloss: 1.73345\n",
            "[7]\tvalid_0's multi_logloss: 1.69482\n",
            "[8]\tvalid_0's multi_logloss: 1.66189\n",
            "[9]\tvalid_0's multi_logloss: 1.63288\n",
            "[10]\tvalid_0's multi_logloss: 1.60556\n",
            "[11]\tvalid_0's multi_logloss: 1.57852\n",
            "[12]\tvalid_0's multi_logloss: 1.55408\n",
            "[13]\tvalid_0's multi_logloss: 1.53228\n",
            "[14]\tvalid_0's multi_logloss: 1.51086\n",
            "[15]\tvalid_0's multi_logloss: 1.49162\n",
            "[16]\tvalid_0's multi_logloss: 1.47376\n",
            "[17]\tvalid_0's multi_logloss: 1.45755\n",
            "[18]\tvalid_0's multi_logloss: 1.44267\n",
            "[19]\tvalid_0's multi_logloss: 1.4288\n",
            "[20]\tvalid_0's multi_logloss: 1.41599\n",
            "[21]\tvalid_0's multi_logloss: 1.40253\n",
            "[22]\tvalid_0's multi_logloss: 1.38908\n",
            "[23]\tvalid_0's multi_logloss: 1.37794\n",
            "[24]\tvalid_0's multi_logloss: 1.3663\n",
            "[25]\tvalid_0's multi_logloss: 1.35566\n",
            "[26]\tvalid_0's multi_logloss: 1.34631\n",
            "[27]\tvalid_0's multi_logloss: 1.3373\n",
            "[28]\tvalid_0's multi_logloss: 1.32848\n",
            "[29]\tvalid_0's multi_logloss: 1.32062\n",
            "[30]\tvalid_0's multi_logloss: 1.31265\n",
            "[31]\tvalid_0's multi_logloss: 1.30525\n",
            "[32]\tvalid_0's multi_logloss: 1.29809\n",
            "[33]\tvalid_0's multi_logloss: 1.29111\n",
            "[34]\tvalid_0's multi_logloss: 1.28389\n",
            "[35]\tvalid_0's multi_logloss: 1.27809\n",
            "[36]\tvalid_0's multi_logloss: 1.27233\n",
            "[37]\tvalid_0's multi_logloss: 1.26693\n",
            "[38]\tvalid_0's multi_logloss: 1.26106\n",
            "[39]\tvalid_0's multi_logloss: 1.25615\n",
            "[40]\tvalid_0's multi_logloss: 1.25039\n",
            "[41]\tvalid_0's multi_logloss: 1.24627\n",
            "[42]\tvalid_0's multi_logloss: 1.2409\n",
            "[43]\tvalid_0's multi_logloss: 1.23652\n",
            "[44]\tvalid_0's multi_logloss: 1.23235\n",
            "[45]\tvalid_0's multi_logloss: 1.22788\n",
            "[46]\tvalid_0's multi_logloss: 1.22412\n",
            "[47]\tvalid_0's multi_logloss: 1.22024\n",
            "[48]\tvalid_0's multi_logloss: 1.21624\n",
            "[49]\tvalid_0's multi_logloss: 1.21235\n",
            "[50]\tvalid_0's multi_logloss: 1.20834\n",
            "[51]\tvalid_0's multi_logloss: 1.20518\n",
            "[52]\tvalid_0's multi_logloss: 1.20195\n",
            "[53]\tvalid_0's multi_logloss: 1.19845\n",
            "[54]\tvalid_0's multi_logloss: 1.19531\n",
            "[55]\tvalid_0's multi_logloss: 1.19127\n",
            "[56]\tvalid_0's multi_logloss: 1.18863\n",
            "[57]\tvalid_0's multi_logloss: 1.18612\n",
            "[58]\tvalid_0's multi_logloss: 1.1828\n",
            "[59]\tvalid_0's multi_logloss: 1.18047\n",
            "[60]\tvalid_0's multi_logloss: 1.17811\n",
            "[61]\tvalid_0's multi_logloss: 1.17548\n",
            "[62]\tvalid_0's multi_logloss: 1.17309\n",
            "[63]\tvalid_0's multi_logloss: 1.17112\n",
            "[64]\tvalid_0's multi_logloss: 1.16856\n",
            "[65]\tvalid_0's multi_logloss: 1.16655\n",
            "[66]\tvalid_0's multi_logloss: 1.16387\n",
            "[67]\tvalid_0's multi_logloss: 1.16135\n",
            "[68]\tvalid_0's multi_logloss: 1.15955\n",
            "[69]\tvalid_0's multi_logloss: 1.15738\n",
            "[70]\tvalid_0's multi_logloss: 1.15547\n",
            "[71]\tvalid_0's multi_logloss: 1.15324\n",
            "[72]\tvalid_0's multi_logloss: 1.15217\n",
            "[73]\tvalid_0's multi_logloss: 1.15029\n",
            "[74]\tvalid_0's multi_logloss: 1.1484\n",
            "[75]\tvalid_0's multi_logloss: 1.14646\n",
            "[76]\tvalid_0's multi_logloss: 1.14427\n",
            "[77]\tvalid_0's multi_logloss: 1.14334\n",
            "[78]\tvalid_0's multi_logloss: 1.14101\n",
            "[79]\tvalid_0's multi_logloss: 1.1391\n",
            "[80]\tvalid_0's multi_logloss: 1.13807\n",
            "[81]\tvalid_0's multi_logloss: 1.1362\n",
            "[82]\tvalid_0's multi_logloss: 1.13476\n",
            "[83]\tvalid_0's multi_logloss: 1.13357\n",
            "[84]\tvalid_0's multi_logloss: 1.1323\n",
            "[85]\tvalid_0's multi_logloss: 1.13142\n",
            "[86]\tvalid_0's multi_logloss: 1.13004\n",
            "[87]\tvalid_0's multi_logloss: 1.12863\n",
            "[88]\tvalid_0's multi_logloss: 1.12744\n",
            "[89]\tvalid_0's multi_logloss: 1.12609\n",
            "[90]\tvalid_0's multi_logloss: 1.12505\n",
            "[91]\tvalid_0's multi_logloss: 1.12451\n",
            "[92]\tvalid_0's multi_logloss: 1.12424\n",
            "[93]\tvalid_0's multi_logloss: 1.12332\n",
            "[94]\tvalid_0's multi_logloss: 1.12269\n",
            "[95]\tvalid_0's multi_logloss: 1.12187\n",
            "[96]\tvalid_0's multi_logloss: 1.12114\n",
            "[97]\tvalid_0's multi_logloss: 1.1193\n",
            "[98]\tvalid_0's multi_logloss: 1.11862\n",
            "[99]\tvalid_0's multi_logloss: 1.11759\n",
            "[100]\tvalid_0's multi_logloss: 1.11682\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 2.04184\n",
            "[2]\tvalid_0's multi_logloss: 1.95576\n",
            "[3]\tvalid_0's multi_logloss: 1.88901\n",
            "[4]\tvalid_0's multi_logloss: 1.82824\n",
            "[5]\tvalid_0's multi_logloss: 1.77967\n",
            "[6]\tvalid_0's multi_logloss: 1.7375\n",
            "[7]\tvalid_0's multi_logloss: 1.69797\n",
            "[8]\tvalid_0's multi_logloss: 1.66221\n",
            "[9]\tvalid_0's multi_logloss: 1.62991\n",
            "[10]\tvalid_0's multi_logloss: 1.60288\n",
            "[11]\tvalid_0's multi_logloss: 1.57654\n",
            "[12]\tvalid_0's multi_logloss: 1.55317\n",
            "[13]\tvalid_0's multi_logloss: 1.53086\n",
            "[14]\tvalid_0's multi_logloss: 1.51036\n",
            "[15]\tvalid_0's multi_logloss: 1.49198\n",
            "[16]\tvalid_0's multi_logloss: 1.4737\n",
            "[17]\tvalid_0's multi_logloss: 1.45763\n",
            "[18]\tvalid_0's multi_logloss: 1.44229\n",
            "[19]\tvalid_0's multi_logloss: 1.42752\n",
            "[20]\tvalid_0's multi_logloss: 1.41347\n",
            "[21]\tvalid_0's multi_logloss: 1.40117\n",
            "[22]\tvalid_0's multi_logloss: 1.38877\n",
            "[23]\tvalid_0's multi_logloss: 1.37733\n",
            "[24]\tvalid_0's multi_logloss: 1.366\n",
            "[25]\tvalid_0's multi_logloss: 1.3557\n",
            "[26]\tvalid_0's multi_logloss: 1.34674\n",
            "[27]\tvalid_0's multi_logloss: 1.33716\n",
            "[28]\tvalid_0's multi_logloss: 1.32899\n",
            "[29]\tvalid_0's multi_logloss: 1.31954\n",
            "[30]\tvalid_0's multi_logloss: 1.31141\n",
            "[31]\tvalid_0's multi_logloss: 1.30425\n",
            "[32]\tvalid_0's multi_logloss: 1.29623\n",
            "[33]\tvalid_0's multi_logloss: 1.29037\n",
            "[34]\tvalid_0's multi_logloss: 1.28349\n",
            "[35]\tvalid_0's multi_logloss: 1.27719\n",
            "[36]\tvalid_0's multi_logloss: 1.27174\n",
            "[37]\tvalid_0's multi_logloss: 1.26681\n",
            "[38]\tvalid_0's multi_logloss: 1.26167\n",
            "[39]\tvalid_0's multi_logloss: 1.25608\n",
            "[40]\tvalid_0's multi_logloss: 1.25052\n",
            "[41]\tvalid_0's multi_logloss: 1.24541\n",
            "[42]\tvalid_0's multi_logloss: 1.2401\n",
            "[43]\tvalid_0's multi_logloss: 1.2356\n",
            "[44]\tvalid_0's multi_logloss: 1.23112\n",
            "[45]\tvalid_0's multi_logloss: 1.22676\n",
            "[46]\tvalid_0's multi_logloss: 1.222\n",
            "[47]\tvalid_0's multi_logloss: 1.21803\n",
            "[48]\tvalid_0's multi_logloss: 1.21407\n",
            "[49]\tvalid_0's multi_logloss: 1.21056\n",
            "[50]\tvalid_0's multi_logloss: 1.20682\n",
            "[51]\tvalid_0's multi_logloss: 1.20433\n",
            "[52]\tvalid_0's multi_logloss: 1.20075\n",
            "[53]\tvalid_0's multi_logloss: 1.19711\n",
            "[54]\tvalid_0's multi_logloss: 1.19358\n",
            "[55]\tvalid_0's multi_logloss: 1.19047\n",
            "[56]\tvalid_0's multi_logloss: 1.18846\n",
            "[57]\tvalid_0's multi_logloss: 1.18563\n",
            "[58]\tvalid_0's multi_logloss: 1.18296\n",
            "[59]\tvalid_0's multi_logloss: 1.18033\n",
            "[60]\tvalid_0's multi_logloss: 1.17704\n",
            "[61]\tvalid_0's multi_logloss: 1.17439\n",
            "[62]\tvalid_0's multi_logloss: 1.17224\n",
            "[63]\tvalid_0's multi_logloss: 1.16957\n",
            "[64]\tvalid_0's multi_logloss: 1.16704\n",
            "[65]\tvalid_0's multi_logloss: 1.16426\n",
            "[66]\tvalid_0's multi_logloss: 1.16215\n",
            "[67]\tvalid_0's multi_logloss: 1.1599\n",
            "[68]\tvalid_0's multi_logloss: 1.15791\n",
            "[69]\tvalid_0's multi_logloss: 1.15557\n",
            "[70]\tvalid_0's multi_logloss: 1.15321\n",
            "[71]\tvalid_0's multi_logloss: 1.15136\n",
            "[72]\tvalid_0's multi_logloss: 1.15008\n",
            "[73]\tvalid_0's multi_logloss: 1.14739\n",
            "[74]\tvalid_0's multi_logloss: 1.14644\n",
            "[75]\tvalid_0's multi_logloss: 1.14467\n",
            "[76]\tvalid_0's multi_logloss: 1.14249\n",
            "[77]\tvalid_0's multi_logloss: 1.1412\n",
            "[78]\tvalid_0's multi_logloss: 1.13962\n",
            "[79]\tvalid_0's multi_logloss: 1.13795\n",
            "[80]\tvalid_0's multi_logloss: 1.13626\n",
            "[81]\tvalid_0's multi_logloss: 1.1354\n",
            "[82]\tvalid_0's multi_logloss: 1.1335\n",
            "[83]\tvalid_0's multi_logloss: 1.1322\n",
            "[84]\tvalid_0's multi_logloss: 1.13109\n",
            "[85]\tvalid_0's multi_logloss: 1.13007\n",
            "[86]\tvalid_0's multi_logloss: 1.1282\n",
            "[87]\tvalid_0's multi_logloss: 1.12706\n",
            "[88]\tvalid_0's multi_logloss: 1.12591\n",
            "[89]\tvalid_0's multi_logloss: 1.12434\n",
            "[90]\tvalid_0's multi_logloss: 1.12291\n",
            "[91]\tvalid_0's multi_logloss: 1.12157\n",
            "[92]\tvalid_0's multi_logloss: 1.12086\n",
            "[93]\tvalid_0's multi_logloss: 1.11995\n",
            "[94]\tvalid_0's multi_logloss: 1.11906\n",
            "[95]\tvalid_0's multi_logloss: 1.11831\n",
            "[96]\tvalid_0's multi_logloss: 1.11713\n",
            "[97]\tvalid_0's multi_logloss: 1.1162\n",
            "[98]\tvalid_0's multi_logloss: 1.11537\n",
            "[99]\tvalid_0's multi_logloss: 1.11471\n",
            "[100]\tvalid_0's multi_logloss: 1.11347\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 2.04607\n",
            "[2]\tvalid_0's multi_logloss: 1.95546\n",
            "[3]\tvalid_0's multi_logloss: 1.88658\n",
            "[4]\tvalid_0's multi_logloss: 1.83081\n",
            "[5]\tvalid_0's multi_logloss: 1.78217\n",
            "[6]\tvalid_0's multi_logloss: 1.73747\n",
            "[7]\tvalid_0's multi_logloss: 1.69914\n",
            "[8]\tvalid_0's multi_logloss: 1.66571\n",
            "[9]\tvalid_0's multi_logloss: 1.6341\n",
            "[10]\tvalid_0's multi_logloss: 1.60668\n",
            "[11]\tvalid_0's multi_logloss: 1.5803\n",
            "[12]\tvalid_0's multi_logloss: 1.55606\n",
            "[13]\tvalid_0's multi_logloss: 1.53308\n",
            "[14]\tvalid_0's multi_logloss: 1.51409\n",
            "[15]\tvalid_0's multi_logloss: 1.49619\n",
            "[16]\tvalid_0's multi_logloss: 1.47922\n",
            "[17]\tvalid_0's multi_logloss: 1.46245\n",
            "[18]\tvalid_0's multi_logloss: 1.44631\n",
            "[19]\tvalid_0's multi_logloss: 1.43213\n",
            "[20]\tvalid_0's multi_logloss: 1.41844\n",
            "[21]\tvalid_0's multi_logloss: 1.40503\n",
            "[22]\tvalid_0's multi_logloss: 1.39313\n",
            "[23]\tvalid_0's multi_logloss: 1.38087\n",
            "[24]\tvalid_0's multi_logloss: 1.3697\n",
            "[25]\tvalid_0's multi_logloss: 1.35906\n",
            "[26]\tvalid_0's multi_logloss: 1.34899\n",
            "[27]\tvalid_0's multi_logloss: 1.34042\n",
            "[28]\tvalid_0's multi_logloss: 1.33138\n",
            "[29]\tvalid_0's multi_logloss: 1.32315\n",
            "[30]\tvalid_0's multi_logloss: 1.31516\n",
            "[31]\tvalid_0's multi_logloss: 1.30803\n",
            "[32]\tvalid_0's multi_logloss: 1.30121\n",
            "[33]\tvalid_0's multi_logloss: 1.29428\n",
            "[34]\tvalid_0's multi_logloss: 1.28824\n",
            "[35]\tvalid_0's multi_logloss: 1.28254\n",
            "[36]\tvalid_0's multi_logloss: 1.27667\n",
            "[37]\tvalid_0's multi_logloss: 1.27068\n",
            "[38]\tvalid_0's multi_logloss: 1.26508\n",
            "[39]\tvalid_0's multi_logloss: 1.25976\n",
            "[40]\tvalid_0's multi_logloss: 1.25462\n",
            "[41]\tvalid_0's multi_logloss: 1.24933\n",
            "[42]\tvalid_0's multi_logloss: 1.24511\n",
            "[43]\tvalid_0's multi_logloss: 1.24033\n",
            "[44]\tvalid_0's multi_logloss: 1.23582\n",
            "[45]\tvalid_0's multi_logloss: 1.23171\n",
            "[46]\tvalid_0's multi_logloss: 1.228\n",
            "[47]\tvalid_0's multi_logloss: 1.224\n",
            "[48]\tvalid_0's multi_logloss: 1.21977\n",
            "[49]\tvalid_0's multi_logloss: 1.21619\n",
            "[50]\tvalid_0's multi_logloss: 1.21326\n",
            "[51]\tvalid_0's multi_logloss: 1.20986\n",
            "[52]\tvalid_0's multi_logloss: 1.20651\n",
            "[53]\tvalid_0's multi_logloss: 1.20286\n",
            "[54]\tvalid_0's multi_logloss: 1.20094\n",
            "[55]\tvalid_0's multi_logloss: 1.19771\n",
            "[56]\tvalid_0's multi_logloss: 1.19459\n",
            "[57]\tvalid_0's multi_logloss: 1.19243\n",
            "[58]\tvalid_0's multi_logloss: 1.18981\n",
            "[59]\tvalid_0's multi_logloss: 1.1872\n",
            "[60]\tvalid_0's multi_logloss: 1.18477\n",
            "[61]\tvalid_0's multi_logloss: 1.18238\n",
            "[62]\tvalid_0's multi_logloss: 1.17951\n",
            "[63]\tvalid_0's multi_logloss: 1.17705\n",
            "[64]\tvalid_0's multi_logloss: 1.17505\n",
            "[65]\tvalid_0's multi_logloss: 1.17268\n",
            "[66]\tvalid_0's multi_logloss: 1.16994\n",
            "[67]\tvalid_0's multi_logloss: 1.16842\n",
            "[68]\tvalid_0's multi_logloss: 1.16627\n",
            "[69]\tvalid_0's multi_logloss: 1.16402\n",
            "[70]\tvalid_0's multi_logloss: 1.16139\n",
            "[71]\tvalid_0's multi_logloss: 1.15929\n",
            "[72]\tvalid_0's multi_logloss: 1.15788\n",
            "[73]\tvalid_0's multi_logloss: 1.15645\n",
            "[74]\tvalid_0's multi_logloss: 1.15465\n",
            "[75]\tvalid_0's multi_logloss: 1.15303\n",
            "[76]\tvalid_0's multi_logloss: 1.15175\n",
            "[77]\tvalid_0's multi_logloss: 1.15039\n",
            "[78]\tvalid_0's multi_logloss: 1.14906\n",
            "[79]\tvalid_0's multi_logloss: 1.14715\n",
            "[80]\tvalid_0's multi_logloss: 1.14555\n",
            "[81]\tvalid_0's multi_logloss: 1.14425\n",
            "[82]\tvalid_0's multi_logloss: 1.1428\n",
            "[83]\tvalid_0's multi_logloss: 1.14121\n",
            "[84]\tvalid_0's multi_logloss: 1.1399\n",
            "[85]\tvalid_0's multi_logloss: 1.13855\n",
            "[86]\tvalid_0's multi_logloss: 1.13762\n",
            "[87]\tvalid_0's multi_logloss: 1.13684\n",
            "[88]\tvalid_0's multi_logloss: 1.13562\n",
            "[89]\tvalid_0's multi_logloss: 1.13505\n",
            "[90]\tvalid_0's multi_logloss: 1.13379\n",
            "[91]\tvalid_0's multi_logloss: 1.13325\n",
            "[92]\tvalid_0's multi_logloss: 1.13194\n",
            "[93]\tvalid_0's multi_logloss: 1.13106\n",
            "[94]\tvalid_0's multi_logloss: 1.13025\n",
            "[95]\tvalid_0's multi_logloss: 1.12951\n",
            "[96]\tvalid_0's multi_logloss: 1.1288\n",
            "[97]\tvalid_0's multi_logloss: 1.12827\n",
            "[98]\tvalid_0's multi_logloss: 1.12737\n",
            "[99]\tvalid_0's multi_logloss: 1.12624\n",
            "[100]\tvalid_0's multi_logloss: 1.12508\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 2.03953\n",
            "[2]\tvalid_0's multi_logloss: 1.94737\n",
            "[3]\tvalid_0's multi_logloss: 1.87915\n",
            "[4]\tvalid_0's multi_logloss: 1.82126\n",
            "[5]\tvalid_0's multi_logloss: 1.77167\n",
            "[6]\tvalid_0's multi_logloss: 1.72868\n",
            "[7]\tvalid_0's multi_logloss: 1.68825\n",
            "[8]\tvalid_0's multi_logloss: 1.65434\n",
            "[9]\tvalid_0's multi_logloss: 1.62357\n",
            "[10]\tvalid_0's multi_logloss: 1.596\n",
            "[11]\tvalid_0's multi_logloss: 1.5693\n",
            "[12]\tvalid_0's multi_logloss: 1.54615\n",
            "[13]\tvalid_0's multi_logloss: 1.52417\n",
            "[14]\tvalid_0's multi_logloss: 1.50513\n",
            "[15]\tvalid_0's multi_logloss: 1.48625\n",
            "[16]\tvalid_0's multi_logloss: 1.46817\n",
            "[17]\tvalid_0's multi_logloss: 1.45139\n",
            "[18]\tvalid_0's multi_logloss: 1.43608\n",
            "[19]\tvalid_0's multi_logloss: 1.42226\n",
            "[20]\tvalid_0's multi_logloss: 1.40865\n",
            "[21]\tvalid_0's multi_logloss: 1.39674\n",
            "[22]\tvalid_0's multi_logloss: 1.3843\n",
            "[23]\tvalid_0's multi_logloss: 1.37261\n",
            "[24]\tvalid_0's multi_logloss: 1.36199\n",
            "[25]\tvalid_0's multi_logloss: 1.35066\n",
            "[26]\tvalid_0's multi_logloss: 1.34107\n",
            "[27]\tvalid_0's multi_logloss: 1.33204\n",
            "[28]\tvalid_0's multi_logloss: 1.32368\n",
            "[29]\tvalid_0's multi_logloss: 1.31431\n",
            "[30]\tvalid_0's multi_logloss: 1.30635\n",
            "[31]\tvalid_0's multi_logloss: 1.29847\n",
            "[32]\tvalid_0's multi_logloss: 1.2917\n",
            "[33]\tvalid_0's multi_logloss: 1.28463\n",
            "[34]\tvalid_0's multi_logloss: 1.27774\n",
            "[35]\tvalid_0's multi_logloss: 1.27132\n",
            "[36]\tvalid_0's multi_logloss: 1.26489\n",
            "[37]\tvalid_0's multi_logloss: 1.25988\n",
            "[38]\tvalid_0's multi_logloss: 1.25434\n",
            "[39]\tvalid_0's multi_logloss: 1.24896\n",
            "[40]\tvalid_0's multi_logloss: 1.2433\n",
            "[41]\tvalid_0's multi_logloss: 1.2383\n",
            "[42]\tvalid_0's multi_logloss: 1.23367\n",
            "[43]\tvalid_0's multi_logloss: 1.22915\n",
            "[44]\tvalid_0's multi_logloss: 1.22531\n",
            "[45]\tvalid_0's multi_logloss: 1.22089\n",
            "[46]\tvalid_0's multi_logloss: 1.21608\n",
            "[47]\tvalid_0's multi_logloss: 1.2116\n",
            "[48]\tvalid_0's multi_logloss: 1.20833\n",
            "[49]\tvalid_0's multi_logloss: 1.20505\n",
            "[50]\tvalid_0's multi_logloss: 1.20139\n",
            "[51]\tvalid_0's multi_logloss: 1.19718\n",
            "[52]\tvalid_0's multi_logloss: 1.19364\n",
            "[53]\tvalid_0's multi_logloss: 1.19017\n",
            "[54]\tvalid_0's multi_logloss: 1.18739\n",
            "[55]\tvalid_0's multi_logloss: 1.18397\n",
            "[56]\tvalid_0's multi_logloss: 1.18116\n",
            "[57]\tvalid_0's multi_logloss: 1.17827\n",
            "[58]\tvalid_0's multi_logloss: 1.1756\n",
            "[59]\tvalid_0's multi_logloss: 1.17362\n",
            "[60]\tvalid_0's multi_logloss: 1.17083\n",
            "[61]\tvalid_0's multi_logloss: 1.16838\n",
            "[62]\tvalid_0's multi_logloss: 1.16587\n",
            "[63]\tvalid_0's multi_logloss: 1.16377\n",
            "[64]\tvalid_0's multi_logloss: 1.16217\n",
            "[65]\tvalid_0's multi_logloss: 1.16057\n",
            "[66]\tvalid_0's multi_logloss: 1.15865\n",
            "[67]\tvalid_0's multi_logloss: 1.15614\n",
            "[68]\tvalid_0's multi_logloss: 1.15423\n",
            "[69]\tvalid_0's multi_logloss: 1.15261\n",
            "[70]\tvalid_0's multi_logloss: 1.15042\n",
            "[71]\tvalid_0's multi_logloss: 1.14809\n",
            "[72]\tvalid_0's multi_logloss: 1.14622\n",
            "[73]\tvalid_0's multi_logloss: 1.14445\n",
            "[74]\tvalid_0's multi_logloss: 1.14303\n",
            "[75]\tvalid_0's multi_logloss: 1.14108\n",
            "[76]\tvalid_0's multi_logloss: 1.13908\n",
            "[77]\tvalid_0's multi_logloss: 1.13783\n",
            "[78]\tvalid_0's multi_logloss: 1.13628\n",
            "[79]\tvalid_0's multi_logloss: 1.13472\n",
            "[80]\tvalid_0's multi_logloss: 1.13337\n",
            "[81]\tvalid_0's multi_logloss: 1.13188\n",
            "[82]\tvalid_0's multi_logloss: 1.13029\n",
            "[83]\tvalid_0's multi_logloss: 1.12938\n",
            "[84]\tvalid_0's multi_logloss: 1.1282\n",
            "[85]\tvalid_0's multi_logloss: 1.1269\n",
            "[86]\tvalid_0's multi_logloss: 1.12569\n",
            "[87]\tvalid_0's multi_logloss: 1.12511\n",
            "[88]\tvalid_0's multi_logloss: 1.12393\n",
            "[89]\tvalid_0's multi_logloss: 1.12292\n",
            "[90]\tvalid_0's multi_logloss: 1.12184\n",
            "[91]\tvalid_0's multi_logloss: 1.12081\n",
            "[92]\tvalid_0's multi_logloss: 1.12016\n",
            "[93]\tvalid_0's multi_logloss: 1.11854\n",
            "[94]\tvalid_0's multi_logloss: 1.11752\n",
            "[95]\tvalid_0's multi_logloss: 1.11715\n",
            "[96]\tvalid_0's multi_logloss: 1.11545\n",
            "[97]\tvalid_0's multi_logloss: 1.11453\n",
            "[98]\tvalid_0's multi_logloss: 1.11392\n",
            "[99]\tvalid_0's multi_logloss: 1.11254\n",
            "[100]\tvalid_0's multi_logloss: 1.11225\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 2.04122\n",
            "[2]\tvalid_0's multi_logloss: 1.95584\n",
            "[3]\tvalid_0's multi_logloss: 1.88796\n",
            "[4]\tvalid_0's multi_logloss: 1.83372\n",
            "[5]\tvalid_0's multi_logloss: 1.78456\n",
            "[6]\tvalid_0's multi_logloss: 1.73885\n",
            "[7]\tvalid_0's multi_logloss: 1.7003\n",
            "[8]\tvalid_0's multi_logloss: 1.665\n",
            "[9]\tvalid_0's multi_logloss: 1.63328\n",
            "[10]\tvalid_0's multi_logloss: 1.60487\n",
            "[11]\tvalid_0's multi_logloss: 1.57877\n",
            "[12]\tvalid_0's multi_logloss: 1.55441\n",
            "[13]\tvalid_0's multi_logloss: 1.5329\n",
            "[14]\tvalid_0's multi_logloss: 1.51116\n",
            "[15]\tvalid_0's multi_logloss: 1.49216\n",
            "[16]\tvalid_0's multi_logloss: 1.47267\n",
            "[17]\tvalid_0's multi_logloss: 1.45502\n",
            "[18]\tvalid_0's multi_logloss: 1.44018\n",
            "[19]\tvalid_0's multi_logloss: 1.42436\n",
            "[20]\tvalid_0's multi_logloss: 1.40987\n",
            "[21]\tvalid_0's multi_logloss: 1.39663\n",
            "[22]\tvalid_0's multi_logloss: 1.38356\n",
            "[23]\tvalid_0's multi_logloss: 1.37096\n",
            "[24]\tvalid_0's multi_logloss: 1.35991\n",
            "[25]\tvalid_0's multi_logloss: 1.35023\n",
            "[26]\tvalid_0's multi_logloss: 1.34155\n",
            "[27]\tvalid_0's multi_logloss: 1.33265\n",
            "[28]\tvalid_0's multi_logloss: 1.32365\n",
            "[29]\tvalid_0's multi_logloss: 1.31479\n",
            "[30]\tvalid_0's multi_logloss: 1.30722\n",
            "[31]\tvalid_0's multi_logloss: 1.29926\n",
            "[32]\tvalid_0's multi_logloss: 1.29208\n",
            "[33]\tvalid_0's multi_logloss: 1.28504\n",
            "[34]\tvalid_0's multi_logloss: 1.27816\n",
            "[35]\tvalid_0's multi_logloss: 1.27158\n",
            "[36]\tvalid_0's multi_logloss: 1.26587\n",
            "[37]\tvalid_0's multi_logloss: 1.26066\n",
            "[38]\tvalid_0's multi_logloss: 1.25614\n",
            "[39]\tvalid_0's multi_logloss: 1.25122\n",
            "[40]\tvalid_0's multi_logloss: 1.24705\n",
            "[41]\tvalid_0's multi_logloss: 1.24224\n",
            "[42]\tvalid_0's multi_logloss: 1.23765\n",
            "[43]\tvalid_0's multi_logloss: 1.23234\n",
            "[44]\tvalid_0's multi_logloss: 1.22889\n",
            "[45]\tvalid_0's multi_logloss: 1.22472\n",
            "[46]\tvalid_0's multi_logloss: 1.22053\n",
            "[47]\tvalid_0's multi_logloss: 1.21702\n",
            "[48]\tvalid_0's multi_logloss: 1.21351\n",
            "[49]\tvalid_0's multi_logloss: 1.2094\n",
            "[50]\tvalid_0's multi_logloss: 1.2059\n",
            "[51]\tvalid_0's multi_logloss: 1.20206\n",
            "[52]\tvalid_0's multi_logloss: 1.19825\n",
            "[53]\tvalid_0's multi_logloss: 1.1948\n",
            "[54]\tvalid_0's multi_logloss: 1.19152\n",
            "[55]\tvalid_0's multi_logloss: 1.18843\n",
            "[56]\tvalid_0's multi_logloss: 1.18537\n",
            "[57]\tvalid_0's multi_logloss: 1.18228\n",
            "[58]\tvalid_0's multi_logloss: 1.17897\n",
            "[59]\tvalid_0's multi_logloss: 1.17598\n",
            "[60]\tvalid_0's multi_logloss: 1.17337\n",
            "[61]\tvalid_0's multi_logloss: 1.17068\n",
            "[62]\tvalid_0's multi_logloss: 1.16834\n",
            "[63]\tvalid_0's multi_logloss: 1.16599\n",
            "[64]\tvalid_0's multi_logloss: 1.16408\n",
            "[65]\tvalid_0's multi_logloss: 1.16101\n",
            "[66]\tvalid_0's multi_logloss: 1.15891\n",
            "[67]\tvalid_0's multi_logloss: 1.15674\n",
            "[68]\tvalid_0's multi_logloss: 1.1551\n",
            "[69]\tvalid_0's multi_logloss: 1.15321\n",
            "[70]\tvalid_0's multi_logloss: 1.15075\n",
            "[71]\tvalid_0's multi_logloss: 1.14883\n",
            "[72]\tvalid_0's multi_logloss: 1.14675\n",
            "[73]\tvalid_0's multi_logloss: 1.1456\n",
            "[74]\tvalid_0's multi_logloss: 1.14438\n",
            "[75]\tvalid_0's multi_logloss: 1.14297\n",
            "[76]\tvalid_0's multi_logloss: 1.14137\n",
            "[77]\tvalid_0's multi_logloss: 1.13861\n",
            "[78]\tvalid_0's multi_logloss: 1.13713\n",
            "[79]\tvalid_0's multi_logloss: 1.13586\n",
            "[80]\tvalid_0's multi_logloss: 1.13451\n",
            "[81]\tvalid_0's multi_logloss: 1.13328\n",
            "[82]\tvalid_0's multi_logloss: 1.13162\n",
            "[83]\tvalid_0's multi_logloss: 1.13037\n",
            "[84]\tvalid_0's multi_logloss: 1.12942\n",
            "[85]\tvalid_0's multi_logloss: 1.12879\n",
            "[86]\tvalid_0's multi_logloss: 1.12784\n",
            "[87]\tvalid_0's multi_logloss: 1.12656\n",
            "[88]\tvalid_0's multi_logloss: 1.12563\n",
            "[89]\tvalid_0's multi_logloss: 1.12473\n",
            "[90]\tvalid_0's multi_logloss: 1.12369\n",
            "[91]\tvalid_0's multi_logloss: 1.12225\n",
            "[92]\tvalid_0's multi_logloss: 1.12136\n",
            "[93]\tvalid_0's multi_logloss: 1.12029\n",
            "[94]\tvalid_0's multi_logloss: 1.11896\n",
            "[95]\tvalid_0's multi_logloss: 1.11739\n",
            "[96]\tvalid_0's multi_logloss: 1.11684\n",
            "[97]\tvalid_0's multi_logloss: 1.11598\n",
            "[98]\tvalid_0's multi_logloss: 1.1153\n",
            "[99]\tvalid_0's multi_logloss: 1.11438\n",
            "[100]\tvalid_0's multi_logloss: 1.11311\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 1.9875\n",
            "[2]\tvalid_0's multi_logloss: 1.88697\n",
            "[3]\tvalid_0's multi_logloss: 1.8119\n",
            "[4]\tvalid_0's multi_logloss: 1.75164\n",
            "[5]\tvalid_0's multi_logloss: 1.69981\n",
            "[6]\tvalid_0's multi_logloss: 1.65744\n",
            "[7]\tvalid_0's multi_logloss: 1.6194\n",
            "[8]\tvalid_0's multi_logloss: 1.58929\n",
            "[9]\tvalid_0's multi_logloss: 1.5601\n",
            "[10]\tvalid_0's multi_logloss: 1.53497\n",
            "[11]\tvalid_0's multi_logloss: 1.5107\n",
            "[12]\tvalid_0's multi_logloss: 1.48834\n",
            "[13]\tvalid_0's multi_logloss: 1.46812\n",
            "[14]\tvalid_0's multi_logloss: 1.44957\n",
            "[15]\tvalid_0's multi_logloss: 1.43551\n",
            "[16]\tvalid_0's multi_logloss: 1.42137\n",
            "[17]\tvalid_0's multi_logloss: 1.40615\n",
            "[18]\tvalid_0's multi_logloss: 1.39205\n",
            "[19]\tvalid_0's multi_logloss: 1.38135\n",
            "[20]\tvalid_0's multi_logloss: 1.3705\n",
            "[21]\tvalid_0's multi_logloss: 1.35946\n",
            "[22]\tvalid_0's multi_logloss: 1.34996\n",
            "[23]\tvalid_0's multi_logloss: 1.3396\n",
            "[24]\tvalid_0's multi_logloss: 1.33209\n",
            "[25]\tvalid_0's multi_logloss: 1.32446\n",
            "[26]\tvalid_0's multi_logloss: 1.31675\n",
            "[27]\tvalid_0's multi_logloss: 1.3105\n",
            "[28]\tvalid_0's multi_logloss: 1.30378\n",
            "[29]\tvalid_0's multi_logloss: 1.29856\n",
            "[30]\tvalid_0's multi_logloss: 1.2915\n",
            "[31]\tvalid_0's multi_logloss: 1.28623\n",
            "[32]\tvalid_0's multi_logloss: 1.28215\n",
            "[33]\tvalid_0's multi_logloss: 1.27594\n",
            "[34]\tvalid_0's multi_logloss: 1.27082\n",
            "[35]\tvalid_0's multi_logloss: 1.26583\n",
            "[36]\tvalid_0's multi_logloss: 1.261\n",
            "[37]\tvalid_0's multi_logloss: 1.25721\n",
            "[38]\tvalid_0's multi_logloss: 1.25307\n",
            "[39]\tvalid_0's multi_logloss: 1.2479\n",
            "[40]\tvalid_0's multi_logloss: 1.24521\n",
            "[41]\tvalid_0's multi_logloss: 1.24231\n",
            "[42]\tvalid_0's multi_logloss: 1.23737\n",
            "[43]\tvalid_0's multi_logloss: 1.23233\n",
            "[44]\tvalid_0's multi_logloss: 1.22918\n",
            "[45]\tvalid_0's multi_logloss: 1.22544\n",
            "[46]\tvalid_0's multi_logloss: 1.22066\n",
            "[47]\tvalid_0's multi_logloss: 1.21849\n",
            "[48]\tvalid_0's multi_logloss: 1.21645\n",
            "[49]\tvalid_0's multi_logloss: 1.21352\n",
            "[50]\tvalid_0's multi_logloss: 1.21125\n",
            "[51]\tvalid_0's multi_logloss: 1.208\n",
            "[52]\tvalid_0's multi_logloss: 1.20538\n",
            "[53]\tvalid_0's multi_logloss: 1.20424\n",
            "[54]\tvalid_0's multi_logloss: 1.2025\n",
            "[55]\tvalid_0's multi_logloss: 1.19992\n",
            "[56]\tvalid_0's multi_logloss: 1.19766\n",
            "[57]\tvalid_0's multi_logloss: 1.1947\n",
            "[58]\tvalid_0's multi_logloss: 1.19309\n",
            "[59]\tvalid_0's multi_logloss: 1.19119\n",
            "[60]\tvalid_0's multi_logloss: 1.18868\n",
            "[61]\tvalid_0's multi_logloss: 1.18702\n",
            "[62]\tvalid_0's multi_logloss: 1.18599\n",
            "[63]\tvalid_0's multi_logloss: 1.18444\n",
            "[64]\tvalid_0's multi_logloss: 1.18239\n",
            "[65]\tvalid_0's multi_logloss: 1.18084\n",
            "[66]\tvalid_0's multi_logloss: 1.17917\n",
            "[67]\tvalid_0's multi_logloss: 1.17891\n",
            "[68]\tvalid_0's multi_logloss: 1.17708\n",
            "[69]\tvalid_0's multi_logloss: 1.17595\n",
            "[70]\tvalid_0's multi_logloss: 1.17475\n",
            "[71]\tvalid_0's multi_logloss: 1.17342\n",
            "[72]\tvalid_0's multi_logloss: 1.17226\n",
            "[73]\tvalid_0's multi_logloss: 1.17121\n",
            "[74]\tvalid_0's multi_logloss: 1.17022\n",
            "[75]\tvalid_0's multi_logloss: 1.16884\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 1.98473\n",
            "[2]\tvalid_0's multi_logloss: 1.88255\n",
            "[3]\tvalid_0's multi_logloss: 1.80487\n",
            "[4]\tvalid_0's multi_logloss: 1.74601\n",
            "[5]\tvalid_0's multi_logloss: 1.69262\n",
            "[6]\tvalid_0's multi_logloss: 1.64708\n",
            "[7]\tvalid_0's multi_logloss: 1.61127\n",
            "[8]\tvalid_0's multi_logloss: 1.57925\n",
            "[9]\tvalid_0's multi_logloss: 1.55119\n",
            "[10]\tvalid_0's multi_logloss: 1.52509\n",
            "[11]\tvalid_0's multi_logloss: 1.5029\n",
            "[12]\tvalid_0's multi_logloss: 1.48157\n",
            "[13]\tvalid_0's multi_logloss: 1.46181\n",
            "[14]\tvalid_0's multi_logloss: 1.44203\n",
            "[15]\tvalid_0's multi_logloss: 1.42456\n",
            "[16]\tvalid_0's multi_logloss: 1.41027\n",
            "[17]\tvalid_0's multi_logloss: 1.3957\n",
            "[18]\tvalid_0's multi_logloss: 1.38165\n",
            "[19]\tvalid_0's multi_logloss: 1.37108\n",
            "[20]\tvalid_0's multi_logloss: 1.35968\n",
            "[21]\tvalid_0's multi_logloss: 1.34888\n",
            "[22]\tvalid_0's multi_logloss: 1.33886\n",
            "[23]\tvalid_0's multi_logloss: 1.33001\n",
            "[24]\tvalid_0's multi_logloss: 1.32094\n",
            "[25]\tvalid_0's multi_logloss: 1.31355\n",
            "[26]\tvalid_0's multi_logloss: 1.30498\n",
            "[27]\tvalid_0's multi_logloss: 1.29775\n",
            "[28]\tvalid_0's multi_logloss: 1.29051\n",
            "[29]\tvalid_0's multi_logloss: 1.28508\n",
            "[30]\tvalid_0's multi_logloss: 1.27812\n",
            "[31]\tvalid_0's multi_logloss: 1.27216\n",
            "[32]\tvalid_0's multi_logloss: 1.26654\n",
            "[33]\tvalid_0's multi_logloss: 1.25912\n",
            "[34]\tvalid_0's multi_logloss: 1.25411\n",
            "[35]\tvalid_0's multi_logloss: 1.24964\n",
            "[36]\tvalid_0's multi_logloss: 1.24354\n",
            "[37]\tvalid_0's multi_logloss: 1.23914\n",
            "[38]\tvalid_0's multi_logloss: 1.23569\n",
            "[39]\tvalid_0's multi_logloss: 1.23261\n",
            "[40]\tvalid_0's multi_logloss: 1.22839\n",
            "[41]\tvalid_0's multi_logloss: 1.2246\n",
            "[42]\tvalid_0's multi_logloss: 1.22107\n",
            "[43]\tvalid_0's multi_logloss: 1.21805\n",
            "[44]\tvalid_0's multi_logloss: 1.21347\n",
            "[45]\tvalid_0's multi_logloss: 1.21206\n",
            "[46]\tvalid_0's multi_logloss: 1.20865\n",
            "[47]\tvalid_0's multi_logloss: 1.20558\n",
            "[48]\tvalid_0's multi_logloss: 1.20288\n",
            "[49]\tvalid_0's multi_logloss: 1.20061\n",
            "[50]\tvalid_0's multi_logloss: 1.19788\n",
            "[51]\tvalid_0's multi_logloss: 1.19528\n",
            "[52]\tvalid_0's multi_logloss: 1.19302\n",
            "[53]\tvalid_0's multi_logloss: 1.19041\n",
            "[54]\tvalid_0's multi_logloss: 1.18815\n",
            "[55]\tvalid_0's multi_logloss: 1.18649\n",
            "[56]\tvalid_0's multi_logloss: 1.18418\n",
            "[57]\tvalid_0's multi_logloss: 1.18156\n",
            "[58]\tvalid_0's multi_logloss: 1.17911\n",
            "[59]\tvalid_0's multi_logloss: 1.17731\n",
            "[60]\tvalid_0's multi_logloss: 1.17486\n",
            "[61]\tvalid_0's multi_logloss: 1.17356\n",
            "[62]\tvalid_0's multi_logloss: 1.17216\n",
            "[63]\tvalid_0's multi_logloss: 1.17118\n",
            "[64]\tvalid_0's multi_logloss: 1.16874\n",
            "[65]\tvalid_0's multi_logloss: 1.16709\n",
            "[66]\tvalid_0's multi_logloss: 1.16551\n",
            "[67]\tvalid_0's multi_logloss: 1.16357\n",
            "[68]\tvalid_0's multi_logloss: 1.16219\n",
            "[69]\tvalid_0's multi_logloss: 1.1612\n",
            "[70]\tvalid_0's multi_logloss: 1.15992\n",
            "[71]\tvalid_0's multi_logloss: 1.15849\n",
            "[72]\tvalid_0's multi_logloss: 1.1573\n",
            "[73]\tvalid_0's multi_logloss: 1.15546\n",
            "[74]\tvalid_0's multi_logloss: 1.15437\n",
            "[75]\tvalid_0's multi_logloss: 1.15306\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 1.98997\n",
            "[2]\tvalid_0's multi_logloss: 1.88875\n",
            "[3]\tvalid_0's multi_logloss: 1.81043\n",
            "[4]\tvalid_0's multi_logloss: 1.75154\n",
            "[5]\tvalid_0's multi_logloss: 1.69597\n",
            "[6]\tvalid_0's multi_logloss: 1.65242\n",
            "[7]\tvalid_0's multi_logloss: 1.61688\n",
            "[8]\tvalid_0's multi_logloss: 1.58414\n",
            "[9]\tvalid_0's multi_logloss: 1.55514\n",
            "[10]\tvalid_0's multi_logloss: 1.52916\n",
            "[11]\tvalid_0's multi_logloss: 1.50777\n",
            "[12]\tvalid_0's multi_logloss: 1.4861\n",
            "[13]\tvalid_0's multi_logloss: 1.46623\n",
            "[14]\tvalid_0's multi_logloss: 1.44711\n",
            "[15]\tvalid_0's multi_logloss: 1.43091\n",
            "[16]\tvalid_0's multi_logloss: 1.41791\n",
            "[17]\tvalid_0's multi_logloss: 1.40291\n",
            "[18]\tvalid_0's multi_logloss: 1.39048\n",
            "[19]\tvalid_0's multi_logloss: 1.37784\n",
            "[20]\tvalid_0's multi_logloss: 1.36773\n",
            "[21]\tvalid_0's multi_logloss: 1.3573\n",
            "[22]\tvalid_0's multi_logloss: 1.34786\n",
            "[23]\tvalid_0's multi_logloss: 1.33866\n",
            "[24]\tvalid_0's multi_logloss: 1.33005\n",
            "[25]\tvalid_0's multi_logloss: 1.32116\n",
            "[26]\tvalid_0's multi_logloss: 1.31358\n",
            "[27]\tvalid_0's multi_logloss: 1.30604\n",
            "[28]\tvalid_0's multi_logloss: 1.29966\n",
            "[29]\tvalid_0's multi_logloss: 1.29429\n",
            "[30]\tvalid_0's multi_logloss: 1.28729\n",
            "[31]\tvalid_0's multi_logloss: 1.28114\n",
            "[32]\tvalid_0's multi_logloss: 1.27588\n",
            "[33]\tvalid_0's multi_logloss: 1.27045\n",
            "[34]\tvalid_0's multi_logloss: 1.26643\n",
            "[35]\tvalid_0's multi_logloss: 1.26136\n",
            "[36]\tvalid_0's multi_logloss: 1.25664\n",
            "[37]\tvalid_0's multi_logloss: 1.25182\n",
            "[38]\tvalid_0's multi_logloss: 1.24774\n",
            "[39]\tvalid_0's multi_logloss: 1.24285\n",
            "[40]\tvalid_0's multi_logloss: 1.23898\n",
            "[41]\tvalid_0's multi_logloss: 1.23497\n",
            "[42]\tvalid_0's multi_logloss: 1.23152\n",
            "[43]\tvalid_0's multi_logloss: 1.2286\n",
            "[44]\tvalid_0's multi_logloss: 1.22519\n",
            "[45]\tvalid_0's multi_logloss: 1.2219\n",
            "[46]\tvalid_0's multi_logloss: 1.21902\n",
            "[47]\tvalid_0's multi_logloss: 1.21632\n",
            "[48]\tvalid_0's multi_logloss: 1.21493\n",
            "[49]\tvalid_0's multi_logloss: 1.21311\n",
            "[50]\tvalid_0's multi_logloss: 1.21045\n",
            "[51]\tvalid_0's multi_logloss: 1.20851\n",
            "[52]\tvalid_0's multi_logloss: 1.20574\n",
            "[53]\tvalid_0's multi_logloss: 1.20332\n",
            "[54]\tvalid_0's multi_logloss: 1.20154\n",
            "[55]\tvalid_0's multi_logloss: 1.20043\n",
            "[56]\tvalid_0's multi_logloss: 1.19946\n",
            "[57]\tvalid_0's multi_logloss: 1.19691\n",
            "[58]\tvalid_0's multi_logloss: 1.19488\n",
            "[59]\tvalid_0's multi_logloss: 1.19228\n",
            "[60]\tvalid_0's multi_logloss: 1.18999\n",
            "[61]\tvalid_0's multi_logloss: 1.18856\n",
            "[62]\tvalid_0's multi_logloss: 1.18633\n",
            "[63]\tvalid_0's multi_logloss: 1.18431\n",
            "[64]\tvalid_0's multi_logloss: 1.18326\n",
            "[65]\tvalid_0's multi_logloss: 1.1818\n",
            "[66]\tvalid_0's multi_logloss: 1.18064\n",
            "[67]\tvalid_0's multi_logloss: 1.17987\n",
            "[68]\tvalid_0's multi_logloss: 1.17889\n",
            "[69]\tvalid_0's multi_logloss: 1.17764\n",
            "[70]\tvalid_0's multi_logloss: 1.17729\n",
            "[71]\tvalid_0's multi_logloss: 1.1763\n",
            "[72]\tvalid_0's multi_logloss: 1.17565\n",
            "[73]\tvalid_0's multi_logloss: 1.17397\n",
            "[74]\tvalid_0's multi_logloss: 1.1721\n",
            "[75]\tvalid_0's multi_logloss: 1.17019\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 1.98291\n",
            "[2]\tvalid_0's multi_logloss: 1.88417\n",
            "[3]\tvalid_0's multi_logloss: 1.80417\n",
            "[4]\tvalid_0's multi_logloss: 1.74328\n",
            "[5]\tvalid_0's multi_logloss: 1.68985\n",
            "[6]\tvalid_0's multi_logloss: 1.6419\n",
            "[7]\tvalid_0's multi_logloss: 1.60436\n",
            "[8]\tvalid_0's multi_logloss: 1.56856\n",
            "[9]\tvalid_0's multi_logloss: 1.54018\n",
            "[10]\tvalid_0's multi_logloss: 1.51546\n",
            "[11]\tvalid_0's multi_logloss: 1.49118\n",
            "[12]\tvalid_0's multi_logloss: 1.46984\n",
            "[13]\tvalid_0's multi_logloss: 1.45281\n",
            "[14]\tvalid_0's multi_logloss: 1.43498\n",
            "[15]\tvalid_0's multi_logloss: 1.41934\n",
            "[16]\tvalid_0's multi_logloss: 1.40473\n",
            "[17]\tvalid_0's multi_logloss: 1.39048\n",
            "[18]\tvalid_0's multi_logloss: 1.37784\n",
            "[19]\tvalid_0's multi_logloss: 1.36523\n",
            "[20]\tvalid_0's multi_logloss: 1.35479\n",
            "[21]\tvalid_0's multi_logloss: 1.34568\n",
            "[22]\tvalid_0's multi_logloss: 1.3358\n",
            "[23]\tvalid_0's multi_logloss: 1.32753\n",
            "[24]\tvalid_0's multi_logloss: 1.31836\n",
            "[25]\tvalid_0's multi_logloss: 1.3099\n",
            "[26]\tvalid_0's multi_logloss: 1.30188\n",
            "[27]\tvalid_0's multi_logloss: 1.29505\n",
            "[28]\tvalid_0's multi_logloss: 1.28839\n",
            "[29]\tvalid_0's multi_logloss: 1.28084\n",
            "[30]\tvalid_0's multi_logloss: 1.27537\n",
            "[31]\tvalid_0's multi_logloss: 1.26969\n",
            "[32]\tvalid_0's multi_logloss: 1.26446\n",
            "[33]\tvalid_0's multi_logloss: 1.2588\n",
            "[34]\tvalid_0's multi_logloss: 1.25256\n",
            "[35]\tvalid_0's multi_logloss: 1.24686\n",
            "[36]\tvalid_0's multi_logloss: 1.2422\n",
            "[37]\tvalid_0's multi_logloss: 1.23858\n",
            "[38]\tvalid_0's multi_logloss: 1.23422\n",
            "[39]\tvalid_0's multi_logloss: 1.23031\n",
            "[40]\tvalid_0's multi_logloss: 1.2272\n",
            "[41]\tvalid_0's multi_logloss: 1.22323\n",
            "[42]\tvalid_0's multi_logloss: 1.21964\n",
            "[43]\tvalid_0's multi_logloss: 1.21615\n",
            "[44]\tvalid_0's multi_logloss: 1.21309\n",
            "[45]\tvalid_0's multi_logloss: 1.2095\n",
            "[46]\tvalid_0's multi_logloss: 1.20725\n",
            "[47]\tvalid_0's multi_logloss: 1.20439\n",
            "[48]\tvalid_0's multi_logloss: 1.20119\n",
            "[49]\tvalid_0's multi_logloss: 1.19897\n",
            "[50]\tvalid_0's multi_logloss: 1.19682\n",
            "[51]\tvalid_0's multi_logloss: 1.19428\n",
            "[52]\tvalid_0's multi_logloss: 1.19248\n",
            "[53]\tvalid_0's multi_logloss: 1.19053\n",
            "[54]\tvalid_0's multi_logloss: 1.18837\n",
            "[55]\tvalid_0's multi_logloss: 1.18671\n",
            "[56]\tvalid_0's multi_logloss: 1.18469\n",
            "[57]\tvalid_0's multi_logloss: 1.18371\n",
            "[58]\tvalid_0's multi_logloss: 1.18204\n",
            "[59]\tvalid_0's multi_logloss: 1.18045\n",
            "[60]\tvalid_0's multi_logloss: 1.17844\n",
            "[61]\tvalid_0's multi_logloss: 1.17729\n",
            "[62]\tvalid_0's multi_logloss: 1.17596\n",
            "[63]\tvalid_0's multi_logloss: 1.17316\n",
            "[64]\tvalid_0's multi_logloss: 1.17129\n",
            "[65]\tvalid_0's multi_logloss: 1.16988\n",
            "[66]\tvalid_0's multi_logloss: 1.16861\n",
            "[67]\tvalid_0's multi_logloss: 1.16724\n",
            "[68]\tvalid_0's multi_logloss: 1.16473\n",
            "[69]\tvalid_0's multi_logloss: 1.16218\n",
            "[70]\tvalid_0's multi_logloss: 1.16048\n",
            "[71]\tvalid_0's multi_logloss: 1.15935\n",
            "[72]\tvalid_0's multi_logloss: 1.15918\n",
            "[73]\tvalid_0's multi_logloss: 1.15874\n",
            "[74]\tvalid_0's multi_logloss: 1.15815\n",
            "[75]\tvalid_0's multi_logloss: 1.15758\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 1.98356\n",
            "[2]\tvalid_0's multi_logloss: 1.88814\n",
            "[3]\tvalid_0's multi_logloss: 1.80835\n",
            "[4]\tvalid_0's multi_logloss: 1.74494\n",
            "[5]\tvalid_0's multi_logloss: 1.6951\n",
            "[6]\tvalid_0's multi_logloss: 1.65211\n",
            "[7]\tvalid_0's multi_logloss: 1.61526\n",
            "[8]\tvalid_0's multi_logloss: 1.58199\n",
            "[9]\tvalid_0's multi_logloss: 1.55166\n",
            "[10]\tvalid_0's multi_logloss: 1.52496\n",
            "[11]\tvalid_0's multi_logloss: 1.50203\n",
            "[12]\tvalid_0's multi_logloss: 1.47881\n",
            "[13]\tvalid_0's multi_logloss: 1.45901\n",
            "[14]\tvalid_0's multi_logloss: 1.44037\n",
            "[15]\tvalid_0's multi_logloss: 1.42438\n",
            "[16]\tvalid_0's multi_logloss: 1.40851\n",
            "[17]\tvalid_0's multi_logloss: 1.39346\n",
            "[18]\tvalid_0's multi_logloss: 1.37993\n",
            "[19]\tvalid_0's multi_logloss: 1.36741\n",
            "[20]\tvalid_0's multi_logloss: 1.35642\n",
            "[21]\tvalid_0's multi_logloss: 1.34692\n",
            "[22]\tvalid_0's multi_logloss: 1.33886\n",
            "[23]\tvalid_0's multi_logloss: 1.33023\n",
            "[24]\tvalid_0's multi_logloss: 1.3211\n",
            "[25]\tvalid_0's multi_logloss: 1.31404\n",
            "[26]\tvalid_0's multi_logloss: 1.30621\n",
            "[27]\tvalid_0's multi_logloss: 1.29897\n",
            "[28]\tvalid_0's multi_logloss: 1.29134\n",
            "[29]\tvalid_0's multi_logloss: 1.28538\n",
            "[30]\tvalid_0's multi_logloss: 1.27929\n",
            "[31]\tvalid_0's multi_logloss: 1.27246\n",
            "[32]\tvalid_0's multi_logloss: 1.26697\n",
            "[33]\tvalid_0's multi_logloss: 1.26225\n",
            "[34]\tvalid_0's multi_logloss: 1.25811\n",
            "[35]\tvalid_0's multi_logloss: 1.25235\n",
            "[36]\tvalid_0's multi_logloss: 1.24701\n",
            "[37]\tvalid_0's multi_logloss: 1.24307\n",
            "[38]\tvalid_0's multi_logloss: 1.23894\n",
            "[39]\tvalid_0's multi_logloss: 1.23513\n",
            "[40]\tvalid_0's multi_logloss: 1.23067\n",
            "[41]\tvalid_0's multi_logloss: 1.22555\n",
            "[42]\tvalid_0's multi_logloss: 1.2218\n",
            "[43]\tvalid_0's multi_logloss: 1.21877\n",
            "[44]\tvalid_0's multi_logloss: 1.21515\n",
            "[45]\tvalid_0's multi_logloss: 1.21116\n",
            "[46]\tvalid_0's multi_logloss: 1.20804\n",
            "[47]\tvalid_0's multi_logloss: 1.20443\n",
            "[48]\tvalid_0's multi_logloss: 1.20191\n",
            "[49]\tvalid_0's multi_logloss: 1.19989\n",
            "[50]\tvalid_0's multi_logloss: 1.19774\n",
            "[51]\tvalid_0's multi_logloss: 1.19519\n",
            "[52]\tvalid_0's multi_logloss: 1.19295\n",
            "[53]\tvalid_0's multi_logloss: 1.18945\n",
            "[54]\tvalid_0's multi_logloss: 1.18837\n",
            "[55]\tvalid_0's multi_logloss: 1.1861\n",
            "[56]\tvalid_0's multi_logloss: 1.18415\n",
            "[57]\tvalid_0's multi_logloss: 1.18233\n",
            "[58]\tvalid_0's multi_logloss: 1.18052\n",
            "[59]\tvalid_0's multi_logloss: 1.17902\n",
            "[60]\tvalid_0's multi_logloss: 1.17711\n",
            "[61]\tvalid_0's multi_logloss: 1.1748\n",
            "[62]\tvalid_0's multi_logloss: 1.17327\n",
            "[63]\tvalid_0's multi_logloss: 1.17091\n",
            "[64]\tvalid_0's multi_logloss: 1.16872\n",
            "[65]\tvalid_0's multi_logloss: 1.16721\n",
            "[66]\tvalid_0's multi_logloss: 1.16589\n",
            "[67]\tvalid_0's multi_logloss: 1.16499\n",
            "[68]\tvalid_0's multi_logloss: 1.16409\n",
            "[69]\tvalid_0's multi_logloss: 1.16212\n",
            "[70]\tvalid_0's multi_logloss: 1.16183\n",
            "[71]\tvalid_0's multi_logloss: 1.15982\n",
            "[72]\tvalid_0's multi_logloss: 1.15773\n",
            "[73]\tvalid_0's multi_logloss: 1.1574\n",
            "[74]\tvalid_0's multi_logloss: 1.15593\n",
            "[75]\tvalid_0's multi_logloss: 1.15399\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 1.93059\n",
            "[2]\tvalid_0's multi_logloss: 1.80999\n",
            "[3]\tvalid_0's multi_logloss: 1.72339\n",
            "[4]\tvalid_0's multi_logloss: 1.65498\n",
            "[5]\tvalid_0's multi_logloss: 1.60131\n",
            "[6]\tvalid_0's multi_logloss: 1.55378\n",
            "[7]\tvalid_0's multi_logloss: 1.51269\n",
            "[8]\tvalid_0's multi_logloss: 1.47845\n",
            "[9]\tvalid_0's multi_logloss: 1.44877\n",
            "[10]\tvalid_0's multi_logloss: 1.422\n",
            "[11]\tvalid_0's multi_logloss: 1.3975\n",
            "[12]\tvalid_0's multi_logloss: 1.37557\n",
            "[13]\tvalid_0's multi_logloss: 1.35745\n",
            "[14]\tvalid_0's multi_logloss: 1.34375\n",
            "[15]\tvalid_0's multi_logloss: 1.32805\n",
            "[16]\tvalid_0's multi_logloss: 1.31408\n",
            "[17]\tvalid_0's multi_logloss: 1.30153\n",
            "[18]\tvalid_0's multi_logloss: 1.28943\n",
            "[19]\tvalid_0's multi_logloss: 1.27814\n",
            "[20]\tvalid_0's multi_logloss: 1.26641\n",
            "[21]\tvalid_0's multi_logloss: 1.25845\n",
            "[22]\tvalid_0's multi_logloss: 1.25068\n",
            "[23]\tvalid_0's multi_logloss: 1.24419\n",
            "[24]\tvalid_0's multi_logloss: 1.23729\n",
            "[25]\tvalid_0's multi_logloss: 1.22931\n",
            "[26]\tvalid_0's multi_logloss: 1.22484\n",
            "[27]\tvalid_0's multi_logloss: 1.21964\n",
            "[28]\tvalid_0's multi_logloss: 1.21427\n",
            "[29]\tvalid_0's multi_logloss: 1.20886\n",
            "[30]\tvalid_0's multi_logloss: 1.20403\n",
            "[31]\tvalid_0's multi_logloss: 1.20061\n",
            "[32]\tvalid_0's multi_logloss: 1.19573\n",
            "[33]\tvalid_0's multi_logloss: 1.19012\n",
            "[34]\tvalid_0's multi_logloss: 1.18549\n",
            "[35]\tvalid_0's multi_logloss: 1.18078\n",
            "[36]\tvalid_0's multi_logloss: 1.17652\n",
            "[37]\tvalid_0's multi_logloss: 1.17239\n",
            "[38]\tvalid_0's multi_logloss: 1.16948\n",
            "[39]\tvalid_0's multi_logloss: 1.16616\n",
            "[40]\tvalid_0's multi_logloss: 1.16272\n",
            "[41]\tvalid_0's multi_logloss: 1.16095\n",
            "[42]\tvalid_0's multi_logloss: 1.15977\n",
            "[43]\tvalid_0's multi_logloss: 1.15842\n",
            "[44]\tvalid_0's multi_logloss: 1.15576\n",
            "[45]\tvalid_0's multi_logloss: 1.15359\n",
            "[46]\tvalid_0's multi_logloss: 1.15105\n",
            "[47]\tvalid_0's multi_logloss: 1.14904\n",
            "[48]\tvalid_0's multi_logloss: 1.14615\n",
            "[49]\tvalid_0's multi_logloss: 1.1441\n",
            "[50]\tvalid_0's multi_logloss: 1.14223\n",
            "[51]\tvalid_0's multi_logloss: 1.14013\n",
            "[52]\tvalid_0's multi_logloss: 1.13868\n",
            "[53]\tvalid_0's multi_logloss: 1.13598\n",
            "[54]\tvalid_0's multi_logloss: 1.13531\n",
            "[55]\tvalid_0's multi_logloss: 1.13495\n",
            "[56]\tvalid_0's multi_logloss: 1.13389\n",
            "[57]\tvalid_0's multi_logloss: 1.13216\n",
            "[58]\tvalid_0's multi_logloss: 1.13126\n",
            "[59]\tvalid_0's multi_logloss: 1.13089\n",
            "[60]\tvalid_0's multi_logloss: 1.12969\n",
            "[61]\tvalid_0's multi_logloss: 1.12872\n",
            "[62]\tvalid_0's multi_logloss: 1.12854\n",
            "[63]\tvalid_0's multi_logloss: 1.12864\n",
            "[64]\tvalid_0's multi_logloss: 1.12792\n",
            "[65]\tvalid_0's multi_logloss: 1.12769\n",
            "[66]\tvalid_0's multi_logloss: 1.12625\n",
            "[67]\tvalid_0's multi_logloss: 1.12539\n",
            "[68]\tvalid_0's multi_logloss: 1.12385\n",
            "[69]\tvalid_0's multi_logloss: 1.12321\n",
            "[70]\tvalid_0's multi_logloss: 1.12237\n",
            "[71]\tvalid_0's multi_logloss: 1.12134\n",
            "[72]\tvalid_0's multi_logloss: 1.12039\n",
            "[73]\tvalid_0's multi_logloss: 1.11934\n",
            "[74]\tvalid_0's multi_logloss: 1.11912\n",
            "[75]\tvalid_0's multi_logloss: 1.11887\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 1.93296\n",
            "[2]\tvalid_0's multi_logloss: 1.81649\n",
            "[3]\tvalid_0's multi_logloss: 1.73152\n",
            "[4]\tvalid_0's multi_logloss: 1.66197\n",
            "[5]\tvalid_0's multi_logloss: 1.60602\n",
            "[6]\tvalid_0's multi_logloss: 1.55457\n",
            "[7]\tvalid_0's multi_logloss: 1.51694\n",
            "[8]\tvalid_0's multi_logloss: 1.48305\n",
            "[9]\tvalid_0's multi_logloss: 1.45495\n",
            "[10]\tvalid_0's multi_logloss: 1.42923\n",
            "[11]\tvalid_0's multi_logloss: 1.4038\n",
            "[12]\tvalid_0's multi_logloss: 1.38272\n",
            "[13]\tvalid_0's multi_logloss: 1.36199\n",
            "[14]\tvalid_0's multi_logloss: 1.34436\n",
            "[15]\tvalid_0's multi_logloss: 1.32814\n",
            "[16]\tvalid_0's multi_logloss: 1.31515\n",
            "[17]\tvalid_0's multi_logloss: 1.30369\n",
            "[18]\tvalid_0's multi_logloss: 1.29176\n",
            "[19]\tvalid_0's multi_logloss: 1.28139\n",
            "[20]\tvalid_0's multi_logloss: 1.27104\n",
            "[21]\tvalid_0's multi_logloss: 1.26248\n",
            "[22]\tvalid_0's multi_logloss: 1.25424\n",
            "[23]\tvalid_0's multi_logloss: 1.24763\n",
            "[24]\tvalid_0's multi_logloss: 1.23913\n",
            "[25]\tvalid_0's multi_logloss: 1.2324\n",
            "[26]\tvalid_0's multi_logloss: 1.22614\n",
            "[27]\tvalid_0's multi_logloss: 1.22027\n",
            "[28]\tvalid_0's multi_logloss: 1.21488\n",
            "[29]\tvalid_0's multi_logloss: 1.20985\n",
            "[30]\tvalid_0's multi_logloss: 1.20398\n",
            "[31]\tvalid_0's multi_logloss: 1.2001\n",
            "[32]\tvalid_0's multi_logloss: 1.19614\n",
            "[33]\tvalid_0's multi_logloss: 1.19249\n",
            "[34]\tvalid_0's multi_logloss: 1.18883\n",
            "[35]\tvalid_0's multi_logloss: 1.18463\n",
            "[36]\tvalid_0's multi_logloss: 1.18027\n",
            "[37]\tvalid_0's multi_logloss: 1.17622\n",
            "[38]\tvalid_0's multi_logloss: 1.17283\n",
            "[39]\tvalid_0's multi_logloss: 1.16878\n",
            "[40]\tvalid_0's multi_logloss: 1.16512\n",
            "[41]\tvalid_0's multi_logloss: 1.16258\n",
            "[42]\tvalid_0's multi_logloss: 1.16048\n",
            "[43]\tvalid_0's multi_logloss: 1.15911\n",
            "[44]\tvalid_0's multi_logloss: 1.15652\n",
            "[45]\tvalid_0's multi_logloss: 1.15437\n",
            "[46]\tvalid_0's multi_logloss: 1.1531\n",
            "[47]\tvalid_0's multi_logloss: 1.15132\n",
            "[48]\tvalid_0's multi_logloss: 1.14944\n",
            "[49]\tvalid_0's multi_logloss: 1.14763\n",
            "[50]\tvalid_0's multi_logloss: 1.14623\n",
            "[51]\tvalid_0's multi_logloss: 1.14489\n",
            "[52]\tvalid_0's multi_logloss: 1.14308\n",
            "[53]\tvalid_0's multi_logloss: 1.14223\n",
            "[54]\tvalid_0's multi_logloss: 1.14032\n",
            "[55]\tvalid_0's multi_logloss: 1.13869\n",
            "[56]\tvalid_0's multi_logloss: 1.13795\n",
            "[57]\tvalid_0's multi_logloss: 1.13711\n",
            "[58]\tvalid_0's multi_logloss: 1.13674\n",
            "[59]\tvalid_0's multi_logloss: 1.13519\n",
            "[60]\tvalid_0's multi_logloss: 1.13423\n",
            "[61]\tvalid_0's multi_logloss: 1.13262\n",
            "[62]\tvalid_0's multi_logloss: 1.1323\n",
            "[63]\tvalid_0's multi_logloss: 1.13138\n",
            "[64]\tvalid_0's multi_logloss: 1.13045\n",
            "[65]\tvalid_0's multi_logloss: 1.12913\n",
            "[66]\tvalid_0's multi_logloss: 1.12817\n",
            "[67]\tvalid_0's multi_logloss: 1.12715\n",
            "[68]\tvalid_0's multi_logloss: 1.12508\n",
            "[69]\tvalid_0's multi_logloss: 1.12341\n",
            "[70]\tvalid_0's multi_logloss: 1.12285\n",
            "[71]\tvalid_0's multi_logloss: 1.1223\n",
            "[72]\tvalid_0's multi_logloss: 1.12261\n",
            "[73]\tvalid_0's multi_logloss: 1.12188\n",
            "[74]\tvalid_0's multi_logloss: 1.12114\n",
            "[75]\tvalid_0's multi_logloss: 1.12102\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 1.94023\n",
            "[2]\tvalid_0's multi_logloss: 1.81714\n",
            "[3]\tvalid_0's multi_logloss: 1.73126\n",
            "[4]\tvalid_0's multi_logloss: 1.66112\n",
            "[5]\tvalid_0's multi_logloss: 1.60422\n",
            "[6]\tvalid_0's multi_logloss: 1.55332\n",
            "[7]\tvalid_0's multi_logloss: 1.5119\n",
            "[8]\tvalid_0's multi_logloss: 1.47828\n",
            "[9]\tvalid_0's multi_logloss: 1.44932\n",
            "[10]\tvalid_0's multi_logloss: 1.42389\n",
            "[11]\tvalid_0's multi_logloss: 1.39956\n",
            "[12]\tvalid_0's multi_logloss: 1.37962\n",
            "[13]\tvalid_0's multi_logloss: 1.36134\n",
            "[14]\tvalid_0's multi_logloss: 1.34231\n",
            "[15]\tvalid_0's multi_logloss: 1.32815\n",
            "[16]\tvalid_0's multi_logloss: 1.31195\n",
            "[17]\tvalid_0's multi_logloss: 1.29939\n",
            "[18]\tvalid_0's multi_logloss: 1.28842\n",
            "[19]\tvalid_0's multi_logloss: 1.2786\n",
            "[20]\tvalid_0's multi_logloss: 1.26936\n",
            "[21]\tvalid_0's multi_logloss: 1.2589\n",
            "[22]\tvalid_0's multi_logloss: 1.25089\n",
            "[23]\tvalid_0's multi_logloss: 1.24395\n",
            "[24]\tvalid_0's multi_logloss: 1.23686\n",
            "[25]\tvalid_0's multi_logloss: 1.22973\n",
            "[26]\tvalid_0's multi_logloss: 1.2232\n",
            "[27]\tvalid_0's multi_logloss: 1.21814\n",
            "[28]\tvalid_0's multi_logloss: 1.21223\n",
            "[29]\tvalid_0's multi_logloss: 1.20754\n",
            "[30]\tvalid_0's multi_logloss: 1.202\n",
            "[31]\tvalid_0's multi_logloss: 1.19817\n",
            "[32]\tvalid_0's multi_logloss: 1.19387\n",
            "[33]\tvalid_0's multi_logloss: 1.18906\n",
            "[34]\tvalid_0's multi_logloss: 1.18493\n",
            "[35]\tvalid_0's multi_logloss: 1.18119\n",
            "[36]\tvalid_0's multi_logloss: 1.17741\n",
            "[37]\tvalid_0's multi_logloss: 1.17356\n",
            "[38]\tvalid_0's multi_logloss: 1.1713\n",
            "[39]\tvalid_0's multi_logloss: 1.16893\n",
            "[40]\tvalid_0's multi_logloss: 1.16535\n",
            "[41]\tvalid_0's multi_logloss: 1.16181\n",
            "[42]\tvalid_0's multi_logloss: 1.15901\n",
            "[43]\tvalid_0's multi_logloss: 1.1562\n",
            "[44]\tvalid_0's multi_logloss: 1.15469\n",
            "[45]\tvalid_0's multi_logloss: 1.15266\n",
            "[46]\tvalid_0's multi_logloss: 1.14994\n",
            "[47]\tvalid_0's multi_logloss: 1.14762\n",
            "[48]\tvalid_0's multi_logloss: 1.14672\n",
            "[49]\tvalid_0's multi_logloss: 1.14449\n",
            "[50]\tvalid_0's multi_logloss: 1.14236\n",
            "[51]\tvalid_0's multi_logloss: 1.13994\n",
            "[52]\tvalid_0's multi_logloss: 1.13875\n",
            "[53]\tvalid_0's multi_logloss: 1.13788\n",
            "[54]\tvalid_0's multi_logloss: 1.13654\n",
            "[55]\tvalid_0's multi_logloss: 1.13592\n",
            "[56]\tvalid_0's multi_logloss: 1.13581\n",
            "[57]\tvalid_0's multi_logloss: 1.13491\n",
            "[58]\tvalid_0's multi_logloss: 1.13412\n",
            "[59]\tvalid_0's multi_logloss: 1.13378\n",
            "[60]\tvalid_0's multi_logloss: 1.13244\n",
            "[61]\tvalid_0's multi_logloss: 1.13197\n",
            "[62]\tvalid_0's multi_logloss: 1.13107\n",
            "[63]\tvalid_0's multi_logloss: 1.1312\n",
            "[64]\tvalid_0's multi_logloss: 1.13153\n",
            "[65]\tvalid_0's multi_logloss: 1.12994\n",
            "[66]\tvalid_0's multi_logloss: 1.12925\n",
            "[67]\tvalid_0's multi_logloss: 1.12805\n",
            "[68]\tvalid_0's multi_logloss: 1.12817\n",
            "[69]\tvalid_0's multi_logloss: 1.12789\n",
            "[70]\tvalid_0's multi_logloss: 1.12672\n",
            "[71]\tvalid_0's multi_logloss: 1.12521\n",
            "[72]\tvalid_0's multi_logloss: 1.12457\n",
            "[73]\tvalid_0's multi_logloss: 1.12345\n",
            "[74]\tvalid_0's multi_logloss: 1.12216\n",
            "[75]\tvalid_0's multi_logloss: 1.12164\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 1.92863\n",
            "[2]\tvalid_0's multi_logloss: 1.80606\n",
            "[3]\tvalid_0's multi_logloss: 1.71291\n",
            "[4]\tvalid_0's multi_logloss: 1.64565\n",
            "[5]\tvalid_0's multi_logloss: 1.59151\n",
            "[6]\tvalid_0's multi_logloss: 1.54614\n",
            "[7]\tvalid_0's multi_logloss: 1.50412\n",
            "[8]\tvalid_0's multi_logloss: 1.46957\n",
            "[9]\tvalid_0's multi_logloss: 1.43822\n",
            "[10]\tvalid_0's multi_logloss: 1.41159\n",
            "[11]\tvalid_0's multi_logloss: 1.38881\n",
            "[12]\tvalid_0's multi_logloss: 1.36619\n",
            "[13]\tvalid_0's multi_logloss: 1.34498\n",
            "[14]\tvalid_0's multi_logloss: 1.33108\n",
            "[15]\tvalid_0's multi_logloss: 1.31602\n",
            "[16]\tvalid_0's multi_logloss: 1.30087\n",
            "[17]\tvalid_0's multi_logloss: 1.28704\n",
            "[18]\tvalid_0's multi_logloss: 1.27462\n",
            "[19]\tvalid_0's multi_logloss: 1.26624\n",
            "[20]\tvalid_0's multi_logloss: 1.25628\n",
            "[21]\tvalid_0's multi_logloss: 1.24666\n",
            "[22]\tvalid_0's multi_logloss: 1.23755\n",
            "[23]\tvalid_0's multi_logloss: 1.23023\n",
            "[24]\tvalid_0's multi_logloss: 1.22214\n",
            "[25]\tvalid_0's multi_logloss: 1.21554\n",
            "[26]\tvalid_0's multi_logloss: 1.20926\n",
            "[27]\tvalid_0's multi_logloss: 1.20515\n",
            "[28]\tvalid_0's multi_logloss: 1.19882\n",
            "[29]\tvalid_0's multi_logloss: 1.19529\n",
            "[30]\tvalid_0's multi_logloss: 1.19041\n",
            "[31]\tvalid_0's multi_logloss: 1.18552\n",
            "[32]\tvalid_0's multi_logloss: 1.17991\n",
            "[33]\tvalid_0's multi_logloss: 1.17539\n",
            "[34]\tvalid_0's multi_logloss: 1.17084\n",
            "[35]\tvalid_0's multi_logloss: 1.16572\n",
            "[36]\tvalid_0's multi_logloss: 1.16209\n",
            "[37]\tvalid_0's multi_logloss: 1.15829\n",
            "[38]\tvalid_0's multi_logloss: 1.15563\n",
            "[39]\tvalid_0's multi_logloss: 1.15414\n",
            "[40]\tvalid_0's multi_logloss: 1.15191\n",
            "[41]\tvalid_0's multi_logloss: 1.14942\n",
            "[42]\tvalid_0's multi_logloss: 1.14657\n",
            "[43]\tvalid_0's multi_logloss: 1.14478\n",
            "[44]\tvalid_0's multi_logloss: 1.14235\n",
            "[45]\tvalid_0's multi_logloss: 1.13965\n",
            "[46]\tvalid_0's multi_logloss: 1.13624\n",
            "[47]\tvalid_0's multi_logloss: 1.13359\n",
            "[48]\tvalid_0's multi_logloss: 1.13178\n",
            "[49]\tvalid_0's multi_logloss: 1.12999\n",
            "[50]\tvalid_0's multi_logloss: 1.12823\n",
            "[51]\tvalid_0's multi_logloss: 1.12624\n",
            "[52]\tvalid_0's multi_logloss: 1.12573\n",
            "[53]\tvalid_0's multi_logloss: 1.12431\n",
            "[54]\tvalid_0's multi_logloss: 1.12315\n",
            "[55]\tvalid_0's multi_logloss: 1.12159\n",
            "[56]\tvalid_0's multi_logloss: 1.12018\n",
            "[57]\tvalid_0's multi_logloss: 1.11889\n",
            "[58]\tvalid_0's multi_logloss: 1.11805\n",
            "[59]\tvalid_0's multi_logloss: 1.11636\n",
            "[60]\tvalid_0's multi_logloss: 1.11583\n",
            "[61]\tvalid_0's multi_logloss: 1.11476\n",
            "[62]\tvalid_0's multi_logloss: 1.11408\n",
            "[63]\tvalid_0's multi_logloss: 1.11293\n",
            "[64]\tvalid_0's multi_logloss: 1.11179\n",
            "[65]\tvalid_0's multi_logloss: 1.11043\n",
            "[66]\tvalid_0's multi_logloss: 1.10967\n",
            "[67]\tvalid_0's multi_logloss: 1.10901\n",
            "[68]\tvalid_0's multi_logloss: 1.10791\n",
            "[69]\tvalid_0's multi_logloss: 1.10721\n",
            "[70]\tvalid_0's multi_logloss: 1.10692\n",
            "[71]\tvalid_0's multi_logloss: 1.10699\n",
            "[72]\tvalid_0's multi_logloss: 1.10614\n",
            "[73]\tvalid_0's multi_logloss: 1.10634\n",
            "[74]\tvalid_0's multi_logloss: 1.10581\n",
            "[75]\tvalid_0's multi_logloss: 1.10521\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 1.93127\n",
            "[2]\tvalid_0's multi_logloss: 1.81636\n",
            "[3]\tvalid_0's multi_logloss: 1.72833\n",
            "[4]\tvalid_0's multi_logloss: 1.6616\n",
            "[5]\tvalid_0's multi_logloss: 1.60463\n",
            "[6]\tvalid_0's multi_logloss: 1.55619\n",
            "[7]\tvalid_0's multi_logloss: 1.51597\n",
            "[8]\tvalid_0's multi_logloss: 1.48202\n",
            "[9]\tvalid_0's multi_logloss: 1.45151\n",
            "[10]\tvalid_0's multi_logloss: 1.42147\n",
            "[11]\tvalid_0's multi_logloss: 1.39844\n",
            "[12]\tvalid_0's multi_logloss: 1.37456\n",
            "[13]\tvalid_0's multi_logloss: 1.35697\n",
            "[14]\tvalid_0's multi_logloss: 1.34017\n",
            "[15]\tvalid_0's multi_logloss: 1.32556\n",
            "[16]\tvalid_0's multi_logloss: 1.31225\n",
            "[17]\tvalid_0's multi_logloss: 1.30101\n",
            "[18]\tvalid_0's multi_logloss: 1.28871\n",
            "[19]\tvalid_0's multi_logloss: 1.27887\n",
            "[20]\tvalid_0's multi_logloss: 1.26878\n",
            "[21]\tvalid_0's multi_logloss: 1.25899\n",
            "[22]\tvalid_0's multi_logloss: 1.25041\n",
            "[23]\tvalid_0's multi_logloss: 1.24171\n",
            "[24]\tvalid_0's multi_logloss: 1.23519\n",
            "[25]\tvalid_0's multi_logloss: 1.22872\n",
            "[26]\tvalid_0's multi_logloss: 1.22313\n",
            "[27]\tvalid_0's multi_logloss: 1.21779\n",
            "[28]\tvalid_0's multi_logloss: 1.21116\n",
            "[29]\tvalid_0's multi_logloss: 1.20572\n",
            "[30]\tvalid_0's multi_logloss: 1.20155\n",
            "[31]\tvalid_0's multi_logloss: 1.1965\n",
            "[32]\tvalid_0's multi_logloss: 1.19249\n",
            "[33]\tvalid_0's multi_logloss: 1.18842\n",
            "[34]\tvalid_0's multi_logloss: 1.18624\n",
            "[35]\tvalid_0's multi_logloss: 1.18241\n",
            "[36]\tvalid_0's multi_logloss: 1.17915\n",
            "[37]\tvalid_0's multi_logloss: 1.17653\n",
            "[38]\tvalid_0's multi_logloss: 1.17353\n",
            "[39]\tvalid_0's multi_logloss: 1.17242\n",
            "[40]\tvalid_0's multi_logloss: 1.16913\n",
            "[41]\tvalid_0's multi_logloss: 1.16665\n",
            "[42]\tvalid_0's multi_logloss: 1.16351\n",
            "[43]\tvalid_0's multi_logloss: 1.16218\n",
            "[44]\tvalid_0's multi_logloss: 1.16109\n",
            "[45]\tvalid_0's multi_logloss: 1.15863\n",
            "[46]\tvalid_0's multi_logloss: 1.1575\n",
            "[47]\tvalid_0's multi_logloss: 1.15359\n",
            "[48]\tvalid_0's multi_logloss: 1.15095\n",
            "[49]\tvalid_0's multi_logloss: 1.14957\n",
            "[50]\tvalid_0's multi_logloss: 1.14839\n",
            "[51]\tvalid_0's multi_logloss: 1.14656\n",
            "[52]\tvalid_0's multi_logloss: 1.14541\n",
            "[53]\tvalid_0's multi_logloss: 1.14292\n",
            "[54]\tvalid_0's multi_logloss: 1.1411\n",
            "[55]\tvalid_0's multi_logloss: 1.13996\n",
            "[56]\tvalid_0's multi_logloss: 1.13901\n",
            "[57]\tvalid_0's multi_logloss: 1.13783\n",
            "[58]\tvalid_0's multi_logloss: 1.13664\n",
            "[59]\tvalid_0's multi_logloss: 1.1361\n",
            "[60]\tvalid_0's multi_logloss: 1.13511\n",
            "[61]\tvalid_0's multi_logloss: 1.13379\n",
            "[62]\tvalid_0's multi_logloss: 1.13235\n",
            "[63]\tvalid_0's multi_logloss: 1.13162\n",
            "[64]\tvalid_0's multi_logloss: 1.13108\n",
            "[65]\tvalid_0's multi_logloss: 1.13042\n",
            "[66]\tvalid_0's multi_logloss: 1.1294\n",
            "[67]\tvalid_0's multi_logloss: 1.12886\n",
            "[68]\tvalid_0's multi_logloss: 1.1286\n",
            "[69]\tvalid_0's multi_logloss: 1.12707\n",
            "[70]\tvalid_0's multi_logloss: 1.12605\n",
            "[71]\tvalid_0's multi_logloss: 1.1259\n",
            "[72]\tvalid_0's multi_logloss: 1.12528\n",
            "[73]\tvalid_0's multi_logloss: 1.12361\n",
            "[74]\tvalid_0's multi_logloss: 1.12339\n",
            "[75]\tvalid_0's multi_logloss: 1.12378\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 1.9875\n",
            "[2]\tvalid_0's multi_logloss: 1.88697\n",
            "[3]\tvalid_0's multi_logloss: 1.8119\n",
            "[4]\tvalid_0's multi_logloss: 1.75164\n",
            "[5]\tvalid_0's multi_logloss: 1.69981\n",
            "[6]\tvalid_0's multi_logloss: 1.65744\n",
            "[7]\tvalid_0's multi_logloss: 1.6194\n",
            "[8]\tvalid_0's multi_logloss: 1.58929\n",
            "[9]\tvalid_0's multi_logloss: 1.5601\n",
            "[10]\tvalid_0's multi_logloss: 1.53497\n",
            "[11]\tvalid_0's multi_logloss: 1.5107\n",
            "[12]\tvalid_0's multi_logloss: 1.48834\n",
            "[13]\tvalid_0's multi_logloss: 1.46812\n",
            "[14]\tvalid_0's multi_logloss: 1.44957\n",
            "[15]\tvalid_0's multi_logloss: 1.43551\n",
            "[16]\tvalid_0's multi_logloss: 1.42137\n",
            "[17]\tvalid_0's multi_logloss: 1.40615\n",
            "[18]\tvalid_0's multi_logloss: 1.39205\n",
            "[19]\tvalid_0's multi_logloss: 1.38135\n",
            "[20]\tvalid_0's multi_logloss: 1.3705\n",
            "[21]\tvalid_0's multi_logloss: 1.35946\n",
            "[22]\tvalid_0's multi_logloss: 1.34996\n",
            "[23]\tvalid_0's multi_logloss: 1.3396\n",
            "[24]\tvalid_0's multi_logloss: 1.33209\n",
            "[25]\tvalid_0's multi_logloss: 1.32446\n",
            "[26]\tvalid_0's multi_logloss: 1.31675\n",
            "[27]\tvalid_0's multi_logloss: 1.3105\n",
            "[28]\tvalid_0's multi_logloss: 1.30378\n",
            "[29]\tvalid_0's multi_logloss: 1.29856\n",
            "[30]\tvalid_0's multi_logloss: 1.2915\n",
            "[31]\tvalid_0's multi_logloss: 1.28623\n",
            "[32]\tvalid_0's multi_logloss: 1.28215\n",
            "[33]\tvalid_0's multi_logloss: 1.27594\n",
            "[34]\tvalid_0's multi_logloss: 1.27082\n",
            "[35]\tvalid_0's multi_logloss: 1.26583\n",
            "[36]\tvalid_0's multi_logloss: 1.261\n",
            "[37]\tvalid_0's multi_logloss: 1.25721\n",
            "[38]\tvalid_0's multi_logloss: 1.25307\n",
            "[39]\tvalid_0's multi_logloss: 1.2479\n",
            "[40]\tvalid_0's multi_logloss: 1.24521\n",
            "[41]\tvalid_0's multi_logloss: 1.24231\n",
            "[42]\tvalid_0's multi_logloss: 1.23737\n",
            "[43]\tvalid_0's multi_logloss: 1.23233\n",
            "[44]\tvalid_0's multi_logloss: 1.22918\n",
            "[45]\tvalid_0's multi_logloss: 1.22544\n",
            "[46]\tvalid_0's multi_logloss: 1.22066\n",
            "[47]\tvalid_0's multi_logloss: 1.21849\n",
            "[48]\tvalid_0's multi_logloss: 1.21645\n",
            "[49]\tvalid_0's multi_logloss: 1.21352\n",
            "[50]\tvalid_0's multi_logloss: 1.21125\n",
            "[51]\tvalid_0's multi_logloss: 1.208\n",
            "[52]\tvalid_0's multi_logloss: 1.20538\n",
            "[53]\tvalid_0's multi_logloss: 1.20424\n",
            "[54]\tvalid_0's multi_logloss: 1.2025\n",
            "[55]\tvalid_0's multi_logloss: 1.19992\n",
            "[56]\tvalid_0's multi_logloss: 1.19766\n",
            "[57]\tvalid_0's multi_logloss: 1.1947\n",
            "[58]\tvalid_0's multi_logloss: 1.19309\n",
            "[59]\tvalid_0's multi_logloss: 1.19119\n",
            "[60]\tvalid_0's multi_logloss: 1.18868\n",
            "[61]\tvalid_0's multi_logloss: 1.18702\n",
            "[62]\tvalid_0's multi_logloss: 1.18599\n",
            "[63]\tvalid_0's multi_logloss: 1.18444\n",
            "[64]\tvalid_0's multi_logloss: 1.18239\n",
            "[65]\tvalid_0's multi_logloss: 1.18084\n",
            "[66]\tvalid_0's multi_logloss: 1.17917\n",
            "[67]\tvalid_0's multi_logloss: 1.17891\n",
            "[68]\tvalid_0's multi_logloss: 1.17708\n",
            "[69]\tvalid_0's multi_logloss: 1.17595\n",
            "[70]\tvalid_0's multi_logloss: 1.17475\n",
            "[71]\tvalid_0's multi_logloss: 1.17342\n",
            "[72]\tvalid_0's multi_logloss: 1.17226\n",
            "[73]\tvalid_0's multi_logloss: 1.17121\n",
            "[74]\tvalid_0's multi_logloss: 1.17022\n",
            "[75]\tvalid_0's multi_logloss: 1.16884\n",
            "[76]\tvalid_0's multi_logloss: 1.16767\n",
            "[77]\tvalid_0's multi_logloss: 1.16706\n",
            "[78]\tvalid_0's multi_logloss: 1.16498\n",
            "[79]\tvalid_0's multi_logloss: 1.16482\n",
            "[80]\tvalid_0's multi_logloss: 1.16356\n",
            "[81]\tvalid_0's multi_logloss: 1.16253\n",
            "[82]\tvalid_0's multi_logloss: 1.16036\n",
            "[83]\tvalid_0's multi_logloss: 1.16022\n",
            "[84]\tvalid_0's multi_logloss: 1.1598\n",
            "[85]\tvalid_0's multi_logloss: 1.15916\n",
            "[86]\tvalid_0's multi_logloss: 1.15883\n",
            "[87]\tvalid_0's multi_logloss: 1.1582\n",
            "[88]\tvalid_0's multi_logloss: 1.15683\n",
            "[89]\tvalid_0's multi_logloss: 1.15635\n",
            "[90]\tvalid_0's multi_logloss: 1.15648\n",
            "[91]\tvalid_0's multi_logloss: 1.15552\n",
            "[92]\tvalid_0's multi_logloss: 1.15553\n",
            "[93]\tvalid_0's multi_logloss: 1.15519\n",
            "[94]\tvalid_0's multi_logloss: 1.15522\n",
            "[95]\tvalid_0's multi_logloss: 1.15394\n",
            "[96]\tvalid_0's multi_logloss: 1.15336\n",
            "[97]\tvalid_0's multi_logloss: 1.15277\n",
            "[98]\tvalid_0's multi_logloss: 1.15229\n",
            "[99]\tvalid_0's multi_logloss: 1.15138\n",
            "[100]\tvalid_0's multi_logloss: 1.1499\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 1.98473\n",
            "[2]\tvalid_0's multi_logloss: 1.88255\n",
            "[3]\tvalid_0's multi_logloss: 1.80487\n",
            "[4]\tvalid_0's multi_logloss: 1.74601\n",
            "[5]\tvalid_0's multi_logloss: 1.69262\n",
            "[6]\tvalid_0's multi_logloss: 1.64708\n",
            "[7]\tvalid_0's multi_logloss: 1.61127\n",
            "[8]\tvalid_0's multi_logloss: 1.57925\n",
            "[9]\tvalid_0's multi_logloss: 1.55119\n",
            "[10]\tvalid_0's multi_logloss: 1.52509\n",
            "[11]\tvalid_0's multi_logloss: 1.5029\n",
            "[12]\tvalid_0's multi_logloss: 1.48157\n",
            "[13]\tvalid_0's multi_logloss: 1.46181\n",
            "[14]\tvalid_0's multi_logloss: 1.44203\n",
            "[15]\tvalid_0's multi_logloss: 1.42456\n",
            "[16]\tvalid_0's multi_logloss: 1.41027\n",
            "[17]\tvalid_0's multi_logloss: 1.3957\n",
            "[18]\tvalid_0's multi_logloss: 1.38165\n",
            "[19]\tvalid_0's multi_logloss: 1.37108\n",
            "[20]\tvalid_0's multi_logloss: 1.35968\n",
            "[21]\tvalid_0's multi_logloss: 1.34888\n",
            "[22]\tvalid_0's multi_logloss: 1.33886\n",
            "[23]\tvalid_0's multi_logloss: 1.33001\n",
            "[24]\tvalid_0's multi_logloss: 1.32094\n",
            "[25]\tvalid_0's multi_logloss: 1.31355\n",
            "[26]\tvalid_0's multi_logloss: 1.30498\n",
            "[27]\tvalid_0's multi_logloss: 1.29775\n",
            "[28]\tvalid_0's multi_logloss: 1.29051\n",
            "[29]\tvalid_0's multi_logloss: 1.28508\n",
            "[30]\tvalid_0's multi_logloss: 1.27812\n",
            "[31]\tvalid_0's multi_logloss: 1.27216\n",
            "[32]\tvalid_0's multi_logloss: 1.26654\n",
            "[33]\tvalid_0's multi_logloss: 1.25912\n",
            "[34]\tvalid_0's multi_logloss: 1.25411\n",
            "[35]\tvalid_0's multi_logloss: 1.24964\n",
            "[36]\tvalid_0's multi_logloss: 1.24354\n",
            "[37]\tvalid_0's multi_logloss: 1.23914\n",
            "[38]\tvalid_0's multi_logloss: 1.23569\n",
            "[39]\tvalid_0's multi_logloss: 1.23261\n",
            "[40]\tvalid_0's multi_logloss: 1.22839\n",
            "[41]\tvalid_0's multi_logloss: 1.2246\n",
            "[42]\tvalid_0's multi_logloss: 1.22107\n",
            "[43]\tvalid_0's multi_logloss: 1.21805\n",
            "[44]\tvalid_0's multi_logloss: 1.21347\n",
            "[45]\tvalid_0's multi_logloss: 1.21206\n",
            "[46]\tvalid_0's multi_logloss: 1.20865\n",
            "[47]\tvalid_0's multi_logloss: 1.20558\n",
            "[48]\tvalid_0's multi_logloss: 1.20288\n",
            "[49]\tvalid_0's multi_logloss: 1.20061\n",
            "[50]\tvalid_0's multi_logloss: 1.19788\n",
            "[51]\tvalid_0's multi_logloss: 1.19528\n",
            "[52]\tvalid_0's multi_logloss: 1.19302\n",
            "[53]\tvalid_0's multi_logloss: 1.19041\n",
            "[54]\tvalid_0's multi_logloss: 1.18815\n",
            "[55]\tvalid_0's multi_logloss: 1.18649\n",
            "[56]\tvalid_0's multi_logloss: 1.18418\n",
            "[57]\tvalid_0's multi_logloss: 1.18156\n",
            "[58]\tvalid_0's multi_logloss: 1.17911\n",
            "[59]\tvalid_0's multi_logloss: 1.17731\n",
            "[60]\tvalid_0's multi_logloss: 1.17486\n",
            "[61]\tvalid_0's multi_logloss: 1.17356\n",
            "[62]\tvalid_0's multi_logloss: 1.17216\n",
            "[63]\tvalid_0's multi_logloss: 1.17118\n",
            "[64]\tvalid_0's multi_logloss: 1.16874\n",
            "[65]\tvalid_0's multi_logloss: 1.16709\n",
            "[66]\tvalid_0's multi_logloss: 1.16551\n",
            "[67]\tvalid_0's multi_logloss: 1.16357\n",
            "[68]\tvalid_0's multi_logloss: 1.16219\n",
            "[69]\tvalid_0's multi_logloss: 1.1612\n",
            "[70]\tvalid_0's multi_logloss: 1.15992\n",
            "[71]\tvalid_0's multi_logloss: 1.15849\n",
            "[72]\tvalid_0's multi_logloss: 1.1573\n",
            "[73]\tvalid_0's multi_logloss: 1.15546\n",
            "[74]\tvalid_0's multi_logloss: 1.15437\n",
            "[75]\tvalid_0's multi_logloss: 1.15306\n",
            "[76]\tvalid_0's multi_logloss: 1.15195\n",
            "[77]\tvalid_0's multi_logloss: 1.15157\n",
            "[78]\tvalid_0's multi_logloss: 1.15012\n",
            "[79]\tvalid_0's multi_logloss: 1.14833\n",
            "[80]\tvalid_0's multi_logloss: 1.14732\n",
            "[81]\tvalid_0's multi_logloss: 1.14682\n",
            "[82]\tvalid_0's multi_logloss: 1.14509\n",
            "[83]\tvalid_0's multi_logloss: 1.14401\n",
            "[84]\tvalid_0's multi_logloss: 1.1435\n",
            "[85]\tvalid_0's multi_logloss: 1.14276\n",
            "[86]\tvalid_0's multi_logloss: 1.14192\n",
            "[87]\tvalid_0's multi_logloss: 1.14111\n",
            "[88]\tvalid_0's multi_logloss: 1.14003\n",
            "[89]\tvalid_0's multi_logloss: 1.13979\n",
            "[90]\tvalid_0's multi_logloss: 1.13929\n",
            "[91]\tvalid_0's multi_logloss: 1.13759\n",
            "[92]\tvalid_0's multi_logloss: 1.13639\n",
            "[93]\tvalid_0's multi_logloss: 1.1355\n",
            "[94]\tvalid_0's multi_logloss: 1.13437\n",
            "[95]\tvalid_0's multi_logloss: 1.13325\n",
            "[96]\tvalid_0's multi_logloss: 1.13158\n",
            "[97]\tvalid_0's multi_logloss: 1.13025\n",
            "[98]\tvalid_0's multi_logloss: 1.12913\n",
            "[99]\tvalid_0's multi_logloss: 1.12738\n",
            "[100]\tvalid_0's multi_logloss: 1.12744\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 1.98997\n",
            "[2]\tvalid_0's multi_logloss: 1.88875\n",
            "[3]\tvalid_0's multi_logloss: 1.81043\n",
            "[4]\tvalid_0's multi_logloss: 1.75154\n",
            "[5]\tvalid_0's multi_logloss: 1.69597\n",
            "[6]\tvalid_0's multi_logloss: 1.65242\n",
            "[7]\tvalid_0's multi_logloss: 1.61688\n",
            "[8]\tvalid_0's multi_logloss: 1.58414\n",
            "[9]\tvalid_0's multi_logloss: 1.55514\n",
            "[10]\tvalid_0's multi_logloss: 1.52916\n",
            "[11]\tvalid_0's multi_logloss: 1.50777\n",
            "[12]\tvalid_0's multi_logloss: 1.4861\n",
            "[13]\tvalid_0's multi_logloss: 1.46623\n",
            "[14]\tvalid_0's multi_logloss: 1.44711\n",
            "[15]\tvalid_0's multi_logloss: 1.43091\n",
            "[16]\tvalid_0's multi_logloss: 1.41791\n",
            "[17]\tvalid_0's multi_logloss: 1.40291\n",
            "[18]\tvalid_0's multi_logloss: 1.39048\n",
            "[19]\tvalid_0's multi_logloss: 1.37784\n",
            "[20]\tvalid_0's multi_logloss: 1.36773\n",
            "[21]\tvalid_0's multi_logloss: 1.3573\n",
            "[22]\tvalid_0's multi_logloss: 1.34786\n",
            "[23]\tvalid_0's multi_logloss: 1.33866\n",
            "[24]\tvalid_0's multi_logloss: 1.33005\n",
            "[25]\tvalid_0's multi_logloss: 1.32116\n",
            "[26]\tvalid_0's multi_logloss: 1.31358\n",
            "[27]\tvalid_0's multi_logloss: 1.30604\n",
            "[28]\tvalid_0's multi_logloss: 1.29966\n",
            "[29]\tvalid_0's multi_logloss: 1.29429\n",
            "[30]\tvalid_0's multi_logloss: 1.28729\n",
            "[31]\tvalid_0's multi_logloss: 1.28114\n",
            "[32]\tvalid_0's multi_logloss: 1.27588\n",
            "[33]\tvalid_0's multi_logloss: 1.27045\n",
            "[34]\tvalid_0's multi_logloss: 1.26643\n",
            "[35]\tvalid_0's multi_logloss: 1.26136\n",
            "[36]\tvalid_0's multi_logloss: 1.25664\n",
            "[37]\tvalid_0's multi_logloss: 1.25182\n",
            "[38]\tvalid_0's multi_logloss: 1.24774\n",
            "[39]\tvalid_0's multi_logloss: 1.24285\n",
            "[40]\tvalid_0's multi_logloss: 1.23898\n",
            "[41]\tvalid_0's multi_logloss: 1.23497\n",
            "[42]\tvalid_0's multi_logloss: 1.23152\n",
            "[43]\tvalid_0's multi_logloss: 1.2286\n",
            "[44]\tvalid_0's multi_logloss: 1.22519\n",
            "[45]\tvalid_0's multi_logloss: 1.2219\n",
            "[46]\tvalid_0's multi_logloss: 1.21902\n",
            "[47]\tvalid_0's multi_logloss: 1.21632\n",
            "[48]\tvalid_0's multi_logloss: 1.21493\n",
            "[49]\tvalid_0's multi_logloss: 1.21311\n",
            "[50]\tvalid_0's multi_logloss: 1.21045\n",
            "[51]\tvalid_0's multi_logloss: 1.20851\n",
            "[52]\tvalid_0's multi_logloss: 1.20574\n",
            "[53]\tvalid_0's multi_logloss: 1.20332\n",
            "[54]\tvalid_0's multi_logloss: 1.20154\n",
            "[55]\tvalid_0's multi_logloss: 1.20043\n",
            "[56]\tvalid_0's multi_logloss: 1.19946\n",
            "[57]\tvalid_0's multi_logloss: 1.19691\n",
            "[58]\tvalid_0's multi_logloss: 1.19488\n",
            "[59]\tvalid_0's multi_logloss: 1.19228\n",
            "[60]\tvalid_0's multi_logloss: 1.18999\n",
            "[61]\tvalid_0's multi_logloss: 1.18856\n",
            "[62]\tvalid_0's multi_logloss: 1.18633\n",
            "[63]\tvalid_0's multi_logloss: 1.18431\n",
            "[64]\tvalid_0's multi_logloss: 1.18326\n",
            "[65]\tvalid_0's multi_logloss: 1.1818\n",
            "[66]\tvalid_0's multi_logloss: 1.18064\n",
            "[67]\tvalid_0's multi_logloss: 1.17987\n",
            "[68]\tvalid_0's multi_logloss: 1.17889\n",
            "[69]\tvalid_0's multi_logloss: 1.17764\n",
            "[70]\tvalid_0's multi_logloss: 1.17729\n",
            "[71]\tvalid_0's multi_logloss: 1.1763\n",
            "[72]\tvalid_0's multi_logloss: 1.17565\n",
            "[73]\tvalid_0's multi_logloss: 1.17397\n",
            "[74]\tvalid_0's multi_logloss: 1.1721\n",
            "[75]\tvalid_0's multi_logloss: 1.17019\n",
            "[76]\tvalid_0's multi_logloss: 1.1696\n",
            "[77]\tvalid_0's multi_logloss: 1.16856\n",
            "[78]\tvalid_0's multi_logloss: 1.16733\n",
            "[79]\tvalid_0's multi_logloss: 1.16693\n",
            "[80]\tvalid_0's multi_logloss: 1.16501\n",
            "[81]\tvalid_0's multi_logloss: 1.16308\n",
            "[82]\tvalid_0's multi_logloss: 1.16238\n",
            "[83]\tvalid_0's multi_logloss: 1.16133\n",
            "[84]\tvalid_0's multi_logloss: 1.16148\n",
            "[85]\tvalid_0's multi_logloss: 1.16045\n",
            "[86]\tvalid_0's multi_logloss: 1.15994\n",
            "[87]\tvalid_0's multi_logloss: 1.15901\n",
            "[88]\tvalid_0's multi_logloss: 1.15794\n",
            "[89]\tvalid_0's multi_logloss: 1.15655\n",
            "[90]\tvalid_0's multi_logloss: 1.15606\n",
            "[91]\tvalid_0's multi_logloss: 1.15434\n",
            "[92]\tvalid_0's multi_logloss: 1.15391\n",
            "[93]\tvalid_0's multi_logloss: 1.15355\n",
            "[94]\tvalid_0's multi_logloss: 1.15266\n",
            "[95]\tvalid_0's multi_logloss: 1.15136\n",
            "[96]\tvalid_0's multi_logloss: 1.15061\n",
            "[97]\tvalid_0's multi_logloss: 1.14971\n",
            "[98]\tvalid_0's multi_logloss: 1.1498\n",
            "[99]\tvalid_0's multi_logloss: 1.14979\n",
            "[100]\tvalid_0's multi_logloss: 1.14935\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 1.98291\n",
            "[2]\tvalid_0's multi_logloss: 1.88417\n",
            "[3]\tvalid_0's multi_logloss: 1.80417\n",
            "[4]\tvalid_0's multi_logloss: 1.74328\n",
            "[5]\tvalid_0's multi_logloss: 1.68985\n",
            "[6]\tvalid_0's multi_logloss: 1.6419\n",
            "[7]\tvalid_0's multi_logloss: 1.60436\n",
            "[8]\tvalid_0's multi_logloss: 1.56856\n",
            "[9]\tvalid_0's multi_logloss: 1.54018\n",
            "[10]\tvalid_0's multi_logloss: 1.51546\n",
            "[11]\tvalid_0's multi_logloss: 1.49118\n",
            "[12]\tvalid_0's multi_logloss: 1.46984\n",
            "[13]\tvalid_0's multi_logloss: 1.45281\n",
            "[14]\tvalid_0's multi_logloss: 1.43498\n",
            "[15]\tvalid_0's multi_logloss: 1.41934\n",
            "[16]\tvalid_0's multi_logloss: 1.40473\n",
            "[17]\tvalid_0's multi_logloss: 1.39048\n",
            "[18]\tvalid_0's multi_logloss: 1.37784\n",
            "[19]\tvalid_0's multi_logloss: 1.36523\n",
            "[20]\tvalid_0's multi_logloss: 1.35479\n",
            "[21]\tvalid_0's multi_logloss: 1.34568\n",
            "[22]\tvalid_0's multi_logloss: 1.3358\n",
            "[23]\tvalid_0's multi_logloss: 1.32753\n",
            "[24]\tvalid_0's multi_logloss: 1.31836\n",
            "[25]\tvalid_0's multi_logloss: 1.3099\n",
            "[26]\tvalid_0's multi_logloss: 1.30188\n",
            "[27]\tvalid_0's multi_logloss: 1.29505\n",
            "[28]\tvalid_0's multi_logloss: 1.28839\n",
            "[29]\tvalid_0's multi_logloss: 1.28084\n",
            "[30]\tvalid_0's multi_logloss: 1.27537\n",
            "[31]\tvalid_0's multi_logloss: 1.26969\n",
            "[32]\tvalid_0's multi_logloss: 1.26446\n",
            "[33]\tvalid_0's multi_logloss: 1.2588\n",
            "[34]\tvalid_0's multi_logloss: 1.25256\n",
            "[35]\tvalid_0's multi_logloss: 1.24686\n",
            "[36]\tvalid_0's multi_logloss: 1.2422\n",
            "[37]\tvalid_0's multi_logloss: 1.23858\n",
            "[38]\tvalid_0's multi_logloss: 1.23422\n",
            "[39]\tvalid_0's multi_logloss: 1.23031\n",
            "[40]\tvalid_0's multi_logloss: 1.2272\n",
            "[41]\tvalid_0's multi_logloss: 1.22323\n",
            "[42]\tvalid_0's multi_logloss: 1.21964\n",
            "[43]\tvalid_0's multi_logloss: 1.21615\n",
            "[44]\tvalid_0's multi_logloss: 1.21309\n",
            "[45]\tvalid_0's multi_logloss: 1.2095\n",
            "[46]\tvalid_0's multi_logloss: 1.20725\n",
            "[47]\tvalid_0's multi_logloss: 1.20439\n",
            "[48]\tvalid_0's multi_logloss: 1.20119\n",
            "[49]\tvalid_0's multi_logloss: 1.19897\n",
            "[50]\tvalid_0's multi_logloss: 1.19682\n",
            "[51]\tvalid_0's multi_logloss: 1.19428\n",
            "[52]\tvalid_0's multi_logloss: 1.19248\n",
            "[53]\tvalid_0's multi_logloss: 1.19053\n",
            "[54]\tvalid_0's multi_logloss: 1.18837\n",
            "[55]\tvalid_0's multi_logloss: 1.18671\n",
            "[56]\tvalid_0's multi_logloss: 1.18469\n",
            "[57]\tvalid_0's multi_logloss: 1.18371\n",
            "[58]\tvalid_0's multi_logloss: 1.18204\n",
            "[59]\tvalid_0's multi_logloss: 1.18045\n",
            "[60]\tvalid_0's multi_logloss: 1.17844\n",
            "[61]\tvalid_0's multi_logloss: 1.17729\n",
            "[62]\tvalid_0's multi_logloss: 1.17596\n",
            "[63]\tvalid_0's multi_logloss: 1.17316\n",
            "[64]\tvalid_0's multi_logloss: 1.17129\n",
            "[65]\tvalid_0's multi_logloss: 1.16988\n",
            "[66]\tvalid_0's multi_logloss: 1.16861\n",
            "[67]\tvalid_0's multi_logloss: 1.16724\n",
            "[68]\tvalid_0's multi_logloss: 1.16473\n",
            "[69]\tvalid_0's multi_logloss: 1.16218\n",
            "[70]\tvalid_0's multi_logloss: 1.16048\n",
            "[71]\tvalid_0's multi_logloss: 1.15935\n",
            "[72]\tvalid_0's multi_logloss: 1.15918\n",
            "[73]\tvalid_0's multi_logloss: 1.15874\n",
            "[74]\tvalid_0's multi_logloss: 1.15815\n",
            "[75]\tvalid_0's multi_logloss: 1.15758\n",
            "[76]\tvalid_0's multi_logloss: 1.15642\n",
            "[77]\tvalid_0's multi_logloss: 1.1559\n",
            "[78]\tvalid_0's multi_logloss: 1.15496\n",
            "[79]\tvalid_0's multi_logloss: 1.15435\n",
            "[80]\tvalid_0's multi_logloss: 1.15315\n",
            "[81]\tvalid_0's multi_logloss: 1.15161\n",
            "[82]\tvalid_0's multi_logloss: 1.15102\n",
            "[83]\tvalid_0's multi_logloss: 1.15064\n",
            "[84]\tvalid_0's multi_logloss: 1.15027\n",
            "[85]\tvalid_0's multi_logloss: 1.14871\n",
            "[86]\tvalid_0's multi_logloss: 1.14751\n",
            "[87]\tvalid_0's multi_logloss: 1.14661\n",
            "[88]\tvalid_0's multi_logloss: 1.14559\n",
            "[89]\tvalid_0's multi_logloss: 1.14436\n",
            "[90]\tvalid_0's multi_logloss: 1.1433\n",
            "[91]\tvalid_0's multi_logloss: 1.1423\n",
            "[92]\tvalid_0's multi_logloss: 1.14129\n",
            "[93]\tvalid_0's multi_logloss: 1.1396\n",
            "[94]\tvalid_0's multi_logloss: 1.13834\n",
            "[95]\tvalid_0's multi_logloss: 1.13811\n",
            "[96]\tvalid_0's multi_logloss: 1.13661\n",
            "[97]\tvalid_0's multi_logloss: 1.13621\n",
            "[98]\tvalid_0's multi_logloss: 1.1355\n",
            "[99]\tvalid_0's multi_logloss: 1.13551\n",
            "[100]\tvalid_0's multi_logloss: 1.13514\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 1.98356\n",
            "[2]\tvalid_0's multi_logloss: 1.88814\n",
            "[3]\tvalid_0's multi_logloss: 1.80835\n",
            "[4]\tvalid_0's multi_logloss: 1.74494\n",
            "[5]\tvalid_0's multi_logloss: 1.6951\n",
            "[6]\tvalid_0's multi_logloss: 1.65211\n",
            "[7]\tvalid_0's multi_logloss: 1.61526\n",
            "[8]\tvalid_0's multi_logloss: 1.58199\n",
            "[9]\tvalid_0's multi_logloss: 1.55166\n",
            "[10]\tvalid_0's multi_logloss: 1.52496\n",
            "[11]\tvalid_0's multi_logloss: 1.50203\n",
            "[12]\tvalid_0's multi_logloss: 1.47881\n",
            "[13]\tvalid_0's multi_logloss: 1.45901\n",
            "[14]\tvalid_0's multi_logloss: 1.44037\n",
            "[15]\tvalid_0's multi_logloss: 1.42438\n",
            "[16]\tvalid_0's multi_logloss: 1.40851\n",
            "[17]\tvalid_0's multi_logloss: 1.39346\n",
            "[18]\tvalid_0's multi_logloss: 1.37993\n",
            "[19]\tvalid_0's multi_logloss: 1.36741\n",
            "[20]\tvalid_0's multi_logloss: 1.35642\n",
            "[21]\tvalid_0's multi_logloss: 1.34692\n",
            "[22]\tvalid_0's multi_logloss: 1.33886\n",
            "[23]\tvalid_0's multi_logloss: 1.33023\n",
            "[24]\tvalid_0's multi_logloss: 1.3211\n",
            "[25]\tvalid_0's multi_logloss: 1.31404\n",
            "[26]\tvalid_0's multi_logloss: 1.30621\n",
            "[27]\tvalid_0's multi_logloss: 1.29897\n",
            "[28]\tvalid_0's multi_logloss: 1.29134\n",
            "[29]\tvalid_0's multi_logloss: 1.28538\n",
            "[30]\tvalid_0's multi_logloss: 1.27929\n",
            "[31]\tvalid_0's multi_logloss: 1.27246\n",
            "[32]\tvalid_0's multi_logloss: 1.26697\n",
            "[33]\tvalid_0's multi_logloss: 1.26225\n",
            "[34]\tvalid_0's multi_logloss: 1.25811\n",
            "[35]\tvalid_0's multi_logloss: 1.25235\n",
            "[36]\tvalid_0's multi_logloss: 1.24701\n",
            "[37]\tvalid_0's multi_logloss: 1.24307\n",
            "[38]\tvalid_0's multi_logloss: 1.23894\n",
            "[39]\tvalid_0's multi_logloss: 1.23513\n",
            "[40]\tvalid_0's multi_logloss: 1.23067\n",
            "[41]\tvalid_0's multi_logloss: 1.22555\n",
            "[42]\tvalid_0's multi_logloss: 1.2218\n",
            "[43]\tvalid_0's multi_logloss: 1.21877\n",
            "[44]\tvalid_0's multi_logloss: 1.21515\n",
            "[45]\tvalid_0's multi_logloss: 1.21116\n",
            "[46]\tvalid_0's multi_logloss: 1.20804\n",
            "[47]\tvalid_0's multi_logloss: 1.20443\n",
            "[48]\tvalid_0's multi_logloss: 1.20191\n",
            "[49]\tvalid_0's multi_logloss: 1.19989\n",
            "[50]\tvalid_0's multi_logloss: 1.19774\n",
            "[51]\tvalid_0's multi_logloss: 1.19519\n",
            "[52]\tvalid_0's multi_logloss: 1.19295\n",
            "[53]\tvalid_0's multi_logloss: 1.18945\n",
            "[54]\tvalid_0's multi_logloss: 1.18837\n",
            "[55]\tvalid_0's multi_logloss: 1.1861\n",
            "[56]\tvalid_0's multi_logloss: 1.18415\n",
            "[57]\tvalid_0's multi_logloss: 1.18233\n",
            "[58]\tvalid_0's multi_logloss: 1.18052\n",
            "[59]\tvalid_0's multi_logloss: 1.17902\n",
            "[60]\tvalid_0's multi_logloss: 1.17711\n",
            "[61]\tvalid_0's multi_logloss: 1.1748\n",
            "[62]\tvalid_0's multi_logloss: 1.17327\n",
            "[63]\tvalid_0's multi_logloss: 1.17091\n",
            "[64]\tvalid_0's multi_logloss: 1.16872\n",
            "[65]\tvalid_0's multi_logloss: 1.16721\n",
            "[66]\tvalid_0's multi_logloss: 1.16589\n",
            "[67]\tvalid_0's multi_logloss: 1.16499\n",
            "[68]\tvalid_0's multi_logloss: 1.16409\n",
            "[69]\tvalid_0's multi_logloss: 1.16212\n",
            "[70]\tvalid_0's multi_logloss: 1.16183\n",
            "[71]\tvalid_0's multi_logloss: 1.15982\n",
            "[72]\tvalid_0's multi_logloss: 1.15773\n",
            "[73]\tvalid_0's multi_logloss: 1.1574\n",
            "[74]\tvalid_0's multi_logloss: 1.15593\n",
            "[75]\tvalid_0's multi_logloss: 1.15399\n",
            "[76]\tvalid_0's multi_logloss: 1.15269\n",
            "[77]\tvalid_0's multi_logloss: 1.15264\n",
            "[78]\tvalid_0's multi_logloss: 1.15181\n",
            "[79]\tvalid_0's multi_logloss: 1.15155\n",
            "[80]\tvalid_0's multi_logloss: 1.15133\n",
            "[81]\tvalid_0's multi_logloss: 1.15027\n",
            "[82]\tvalid_0's multi_logloss: 1.14957\n",
            "[83]\tvalid_0's multi_logloss: 1.1488\n",
            "[84]\tvalid_0's multi_logloss: 1.14761\n",
            "[85]\tvalid_0's multi_logloss: 1.14725\n",
            "[86]\tvalid_0's multi_logloss: 1.14541\n",
            "[87]\tvalid_0's multi_logloss: 1.14406\n",
            "[88]\tvalid_0's multi_logloss: 1.14385\n",
            "[89]\tvalid_0's multi_logloss: 1.14394\n",
            "[90]\tvalid_0's multi_logloss: 1.1428\n",
            "[91]\tvalid_0's multi_logloss: 1.14187\n",
            "[92]\tvalid_0's multi_logloss: 1.14183\n",
            "[93]\tvalid_0's multi_logloss: 1.14152\n",
            "[94]\tvalid_0's multi_logloss: 1.14022\n",
            "[95]\tvalid_0's multi_logloss: 1.1398\n",
            "[96]\tvalid_0's multi_logloss: 1.13843\n",
            "[97]\tvalid_0's multi_logloss: 1.13801\n",
            "[98]\tvalid_0's multi_logloss: 1.13747\n",
            "[99]\tvalid_0's multi_logloss: 1.13697\n",
            "[100]\tvalid_0's multi_logloss: 1.13584\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 1.93059\n",
            "[2]\tvalid_0's multi_logloss: 1.80999\n",
            "[3]\tvalid_0's multi_logloss: 1.72339\n",
            "[4]\tvalid_0's multi_logloss: 1.65498\n",
            "[5]\tvalid_0's multi_logloss: 1.60131\n",
            "[6]\tvalid_0's multi_logloss: 1.55378\n",
            "[7]\tvalid_0's multi_logloss: 1.51269\n",
            "[8]\tvalid_0's multi_logloss: 1.47845\n",
            "[9]\tvalid_0's multi_logloss: 1.44877\n",
            "[10]\tvalid_0's multi_logloss: 1.422\n",
            "[11]\tvalid_0's multi_logloss: 1.3975\n",
            "[12]\tvalid_0's multi_logloss: 1.37557\n",
            "[13]\tvalid_0's multi_logloss: 1.35745\n",
            "[14]\tvalid_0's multi_logloss: 1.34375\n",
            "[15]\tvalid_0's multi_logloss: 1.32805\n",
            "[16]\tvalid_0's multi_logloss: 1.31408\n",
            "[17]\tvalid_0's multi_logloss: 1.30153\n",
            "[18]\tvalid_0's multi_logloss: 1.28943\n",
            "[19]\tvalid_0's multi_logloss: 1.27814\n",
            "[20]\tvalid_0's multi_logloss: 1.26641\n",
            "[21]\tvalid_0's multi_logloss: 1.25845\n",
            "[22]\tvalid_0's multi_logloss: 1.25068\n",
            "[23]\tvalid_0's multi_logloss: 1.24419\n",
            "[24]\tvalid_0's multi_logloss: 1.23729\n",
            "[25]\tvalid_0's multi_logloss: 1.22931\n",
            "[26]\tvalid_0's multi_logloss: 1.22484\n",
            "[27]\tvalid_0's multi_logloss: 1.21964\n",
            "[28]\tvalid_0's multi_logloss: 1.21427\n",
            "[29]\tvalid_0's multi_logloss: 1.20886\n",
            "[30]\tvalid_0's multi_logloss: 1.20403\n",
            "[31]\tvalid_0's multi_logloss: 1.20061\n",
            "[32]\tvalid_0's multi_logloss: 1.19573\n",
            "[33]\tvalid_0's multi_logloss: 1.19012\n",
            "[34]\tvalid_0's multi_logloss: 1.18549\n",
            "[35]\tvalid_0's multi_logloss: 1.18078\n",
            "[36]\tvalid_0's multi_logloss: 1.17652\n",
            "[37]\tvalid_0's multi_logloss: 1.17239\n",
            "[38]\tvalid_0's multi_logloss: 1.16948\n",
            "[39]\tvalid_0's multi_logloss: 1.16616\n",
            "[40]\tvalid_0's multi_logloss: 1.16272\n",
            "[41]\tvalid_0's multi_logloss: 1.16095\n",
            "[42]\tvalid_0's multi_logloss: 1.15977\n",
            "[43]\tvalid_0's multi_logloss: 1.15842\n",
            "[44]\tvalid_0's multi_logloss: 1.15576\n",
            "[45]\tvalid_0's multi_logloss: 1.15359\n",
            "[46]\tvalid_0's multi_logloss: 1.15105\n",
            "[47]\tvalid_0's multi_logloss: 1.14904\n",
            "[48]\tvalid_0's multi_logloss: 1.14615\n",
            "[49]\tvalid_0's multi_logloss: 1.1441\n",
            "[50]\tvalid_0's multi_logloss: 1.14223\n",
            "[51]\tvalid_0's multi_logloss: 1.14013\n",
            "[52]\tvalid_0's multi_logloss: 1.13868\n",
            "[53]\tvalid_0's multi_logloss: 1.13598\n",
            "[54]\tvalid_0's multi_logloss: 1.13531\n",
            "[55]\tvalid_0's multi_logloss: 1.13495\n",
            "[56]\tvalid_0's multi_logloss: 1.13389\n",
            "[57]\tvalid_0's multi_logloss: 1.13216\n",
            "[58]\tvalid_0's multi_logloss: 1.13126\n",
            "[59]\tvalid_0's multi_logloss: 1.13089\n",
            "[60]\tvalid_0's multi_logloss: 1.12969\n",
            "[61]\tvalid_0's multi_logloss: 1.12872\n",
            "[62]\tvalid_0's multi_logloss: 1.12854\n",
            "[63]\tvalid_0's multi_logloss: 1.12864\n",
            "[64]\tvalid_0's multi_logloss: 1.12792\n",
            "[65]\tvalid_0's multi_logloss: 1.12769\n",
            "[66]\tvalid_0's multi_logloss: 1.12625\n",
            "[67]\tvalid_0's multi_logloss: 1.12539\n",
            "[68]\tvalid_0's multi_logloss: 1.12385\n",
            "[69]\tvalid_0's multi_logloss: 1.12321\n",
            "[70]\tvalid_0's multi_logloss: 1.12237\n",
            "[71]\tvalid_0's multi_logloss: 1.12134\n",
            "[72]\tvalid_0's multi_logloss: 1.12039\n",
            "[73]\tvalid_0's multi_logloss: 1.11934\n",
            "[74]\tvalid_0's multi_logloss: 1.11912\n",
            "[75]\tvalid_0's multi_logloss: 1.11887\n",
            "[76]\tvalid_0's multi_logloss: 1.11876\n",
            "[77]\tvalid_0's multi_logloss: 1.11905\n",
            "[78]\tvalid_0's multi_logloss: 1.11902\n",
            "[79]\tvalid_0's multi_logloss: 1.11857\n",
            "[80]\tvalid_0's multi_logloss: 1.1176\n",
            "[81]\tvalid_0's multi_logloss: 1.11739\n",
            "[82]\tvalid_0's multi_logloss: 1.11703\n",
            "[83]\tvalid_0's multi_logloss: 1.11613\n",
            "[84]\tvalid_0's multi_logloss: 1.11642\n",
            "[85]\tvalid_0's multi_logloss: 1.115\n",
            "[86]\tvalid_0's multi_logloss: 1.11381\n",
            "[87]\tvalid_0's multi_logloss: 1.11343\n",
            "[88]\tvalid_0's multi_logloss: 1.11259\n",
            "[89]\tvalid_0's multi_logloss: 1.11244\n",
            "[90]\tvalid_0's multi_logloss: 1.11241\n",
            "[91]\tvalid_0's multi_logloss: 1.11234\n",
            "[92]\tvalid_0's multi_logloss: 1.11204\n",
            "[93]\tvalid_0's multi_logloss: 1.11211\n",
            "[94]\tvalid_0's multi_logloss: 1.11163\n",
            "[95]\tvalid_0's multi_logloss: 1.1111\n",
            "[96]\tvalid_0's multi_logloss: 1.11094\n",
            "[97]\tvalid_0's multi_logloss: 1.10985\n",
            "[98]\tvalid_0's multi_logloss: 1.10987\n",
            "[99]\tvalid_0's multi_logloss: 1.11042\n",
            "[100]\tvalid_0's multi_logloss: 1.1109\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 1.93296\n",
            "[2]\tvalid_0's multi_logloss: 1.81649\n",
            "[3]\tvalid_0's multi_logloss: 1.73152\n",
            "[4]\tvalid_0's multi_logloss: 1.66197\n",
            "[5]\tvalid_0's multi_logloss: 1.60602\n",
            "[6]\tvalid_0's multi_logloss: 1.55457\n",
            "[7]\tvalid_0's multi_logloss: 1.51694\n",
            "[8]\tvalid_0's multi_logloss: 1.48305\n",
            "[9]\tvalid_0's multi_logloss: 1.45495\n",
            "[10]\tvalid_0's multi_logloss: 1.42923\n",
            "[11]\tvalid_0's multi_logloss: 1.4038\n",
            "[12]\tvalid_0's multi_logloss: 1.38272\n",
            "[13]\tvalid_0's multi_logloss: 1.36199\n",
            "[14]\tvalid_0's multi_logloss: 1.34436\n",
            "[15]\tvalid_0's multi_logloss: 1.32814\n",
            "[16]\tvalid_0's multi_logloss: 1.31515\n",
            "[17]\tvalid_0's multi_logloss: 1.30369\n",
            "[18]\tvalid_0's multi_logloss: 1.29176\n",
            "[19]\tvalid_0's multi_logloss: 1.28139\n",
            "[20]\tvalid_0's multi_logloss: 1.27104\n",
            "[21]\tvalid_0's multi_logloss: 1.26248\n",
            "[22]\tvalid_0's multi_logloss: 1.25424\n",
            "[23]\tvalid_0's multi_logloss: 1.24763\n",
            "[24]\tvalid_0's multi_logloss: 1.23913\n",
            "[25]\tvalid_0's multi_logloss: 1.2324\n",
            "[26]\tvalid_0's multi_logloss: 1.22614\n",
            "[27]\tvalid_0's multi_logloss: 1.22027\n",
            "[28]\tvalid_0's multi_logloss: 1.21488\n",
            "[29]\tvalid_0's multi_logloss: 1.20985\n",
            "[30]\tvalid_0's multi_logloss: 1.20398\n",
            "[31]\tvalid_0's multi_logloss: 1.2001\n",
            "[32]\tvalid_0's multi_logloss: 1.19614\n",
            "[33]\tvalid_0's multi_logloss: 1.19249\n",
            "[34]\tvalid_0's multi_logloss: 1.18883\n",
            "[35]\tvalid_0's multi_logloss: 1.18463\n",
            "[36]\tvalid_0's multi_logloss: 1.18027\n",
            "[37]\tvalid_0's multi_logloss: 1.17622\n",
            "[38]\tvalid_0's multi_logloss: 1.17283\n",
            "[39]\tvalid_0's multi_logloss: 1.16878\n",
            "[40]\tvalid_0's multi_logloss: 1.16512\n",
            "[41]\tvalid_0's multi_logloss: 1.16258\n",
            "[42]\tvalid_0's multi_logloss: 1.16048\n",
            "[43]\tvalid_0's multi_logloss: 1.15911\n",
            "[44]\tvalid_0's multi_logloss: 1.15652\n",
            "[45]\tvalid_0's multi_logloss: 1.15437\n",
            "[46]\tvalid_0's multi_logloss: 1.1531\n",
            "[47]\tvalid_0's multi_logloss: 1.15132\n",
            "[48]\tvalid_0's multi_logloss: 1.14944\n",
            "[49]\tvalid_0's multi_logloss: 1.14763\n",
            "[50]\tvalid_0's multi_logloss: 1.14623\n",
            "[51]\tvalid_0's multi_logloss: 1.14489\n",
            "[52]\tvalid_0's multi_logloss: 1.14308\n",
            "[53]\tvalid_0's multi_logloss: 1.14223\n",
            "[54]\tvalid_0's multi_logloss: 1.14032\n",
            "[55]\tvalid_0's multi_logloss: 1.13869\n",
            "[56]\tvalid_0's multi_logloss: 1.13795\n",
            "[57]\tvalid_0's multi_logloss: 1.13711\n",
            "[58]\tvalid_0's multi_logloss: 1.13674\n",
            "[59]\tvalid_0's multi_logloss: 1.13519\n",
            "[60]\tvalid_0's multi_logloss: 1.13423\n",
            "[61]\tvalid_0's multi_logloss: 1.13262\n",
            "[62]\tvalid_0's multi_logloss: 1.1323\n",
            "[63]\tvalid_0's multi_logloss: 1.13138\n",
            "[64]\tvalid_0's multi_logloss: 1.13045\n",
            "[65]\tvalid_0's multi_logloss: 1.12913\n",
            "[66]\tvalid_0's multi_logloss: 1.12817\n",
            "[67]\tvalid_0's multi_logloss: 1.12715\n",
            "[68]\tvalid_0's multi_logloss: 1.12508\n",
            "[69]\tvalid_0's multi_logloss: 1.12341\n",
            "[70]\tvalid_0's multi_logloss: 1.12285\n",
            "[71]\tvalid_0's multi_logloss: 1.1223\n",
            "[72]\tvalid_0's multi_logloss: 1.12261\n",
            "[73]\tvalid_0's multi_logloss: 1.12188\n",
            "[74]\tvalid_0's multi_logloss: 1.12114\n",
            "[75]\tvalid_0's multi_logloss: 1.12102\n",
            "[76]\tvalid_0's multi_logloss: 1.11981\n",
            "[77]\tvalid_0's multi_logloss: 1.11941\n",
            "[78]\tvalid_0's multi_logloss: 1.11972\n",
            "[79]\tvalid_0's multi_logloss: 1.11943\n",
            "[80]\tvalid_0's multi_logloss: 1.11891\n",
            "[81]\tvalid_0's multi_logloss: 1.11905\n",
            "[82]\tvalid_0's multi_logloss: 1.11889\n",
            "[83]\tvalid_0's multi_logloss: 1.11963\n",
            "[84]\tvalid_0's multi_logloss: 1.11916\n",
            "[85]\tvalid_0's multi_logloss: 1.11891\n",
            "[86]\tvalid_0's multi_logloss: 1.11854\n",
            "[87]\tvalid_0's multi_logloss: 1.11836\n",
            "[88]\tvalid_0's multi_logloss: 1.11824\n",
            "[89]\tvalid_0's multi_logloss: 1.11773\n",
            "[90]\tvalid_0's multi_logloss: 1.11731\n",
            "[91]\tvalid_0's multi_logloss: 1.11645\n",
            "[92]\tvalid_0's multi_logloss: 1.11585\n",
            "[93]\tvalid_0's multi_logloss: 1.11565\n",
            "[94]\tvalid_0's multi_logloss: 1.11454\n",
            "[95]\tvalid_0's multi_logloss: 1.11391\n",
            "[96]\tvalid_0's multi_logloss: 1.11418\n",
            "[97]\tvalid_0's multi_logloss: 1.11433\n",
            "[98]\tvalid_0's multi_logloss: 1.1146\n",
            "[99]\tvalid_0's multi_logloss: 1.11445\n",
            "[100]\tvalid_0's multi_logloss: 1.11354\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 1.94023\n",
            "[2]\tvalid_0's multi_logloss: 1.81714\n",
            "[3]\tvalid_0's multi_logloss: 1.73126\n",
            "[4]\tvalid_0's multi_logloss: 1.66112\n",
            "[5]\tvalid_0's multi_logloss: 1.60422\n",
            "[6]\tvalid_0's multi_logloss: 1.55332\n",
            "[7]\tvalid_0's multi_logloss: 1.5119\n",
            "[8]\tvalid_0's multi_logloss: 1.47828\n",
            "[9]\tvalid_0's multi_logloss: 1.44932\n",
            "[10]\tvalid_0's multi_logloss: 1.42389\n",
            "[11]\tvalid_0's multi_logloss: 1.39956\n",
            "[12]\tvalid_0's multi_logloss: 1.37962\n",
            "[13]\tvalid_0's multi_logloss: 1.36134\n",
            "[14]\tvalid_0's multi_logloss: 1.34231\n",
            "[15]\tvalid_0's multi_logloss: 1.32815\n",
            "[16]\tvalid_0's multi_logloss: 1.31195\n",
            "[17]\tvalid_0's multi_logloss: 1.29939\n",
            "[18]\tvalid_0's multi_logloss: 1.28842\n",
            "[19]\tvalid_0's multi_logloss: 1.2786\n",
            "[20]\tvalid_0's multi_logloss: 1.26936\n",
            "[21]\tvalid_0's multi_logloss: 1.2589\n",
            "[22]\tvalid_0's multi_logloss: 1.25089\n",
            "[23]\tvalid_0's multi_logloss: 1.24395\n",
            "[24]\tvalid_0's multi_logloss: 1.23686\n",
            "[25]\tvalid_0's multi_logloss: 1.22973\n",
            "[26]\tvalid_0's multi_logloss: 1.2232\n",
            "[27]\tvalid_0's multi_logloss: 1.21814\n",
            "[28]\tvalid_0's multi_logloss: 1.21223\n",
            "[29]\tvalid_0's multi_logloss: 1.20754\n",
            "[30]\tvalid_0's multi_logloss: 1.202\n",
            "[31]\tvalid_0's multi_logloss: 1.19817\n",
            "[32]\tvalid_0's multi_logloss: 1.19387\n",
            "[33]\tvalid_0's multi_logloss: 1.18906\n",
            "[34]\tvalid_0's multi_logloss: 1.18493\n",
            "[35]\tvalid_0's multi_logloss: 1.18119\n",
            "[36]\tvalid_0's multi_logloss: 1.17741\n",
            "[37]\tvalid_0's multi_logloss: 1.17356\n",
            "[38]\tvalid_0's multi_logloss: 1.1713\n",
            "[39]\tvalid_0's multi_logloss: 1.16893\n",
            "[40]\tvalid_0's multi_logloss: 1.16535\n",
            "[41]\tvalid_0's multi_logloss: 1.16181\n",
            "[42]\tvalid_0's multi_logloss: 1.15901\n",
            "[43]\tvalid_0's multi_logloss: 1.1562\n",
            "[44]\tvalid_0's multi_logloss: 1.15469\n",
            "[45]\tvalid_0's multi_logloss: 1.15266\n",
            "[46]\tvalid_0's multi_logloss: 1.14994\n",
            "[47]\tvalid_0's multi_logloss: 1.14762\n",
            "[48]\tvalid_0's multi_logloss: 1.14672\n",
            "[49]\tvalid_0's multi_logloss: 1.14449\n",
            "[50]\tvalid_0's multi_logloss: 1.14236\n",
            "[51]\tvalid_0's multi_logloss: 1.13994\n",
            "[52]\tvalid_0's multi_logloss: 1.13875\n",
            "[53]\tvalid_0's multi_logloss: 1.13788\n",
            "[54]\tvalid_0's multi_logloss: 1.13654\n",
            "[55]\tvalid_0's multi_logloss: 1.13592\n",
            "[56]\tvalid_0's multi_logloss: 1.13581\n",
            "[57]\tvalid_0's multi_logloss: 1.13491\n",
            "[58]\tvalid_0's multi_logloss: 1.13412\n",
            "[59]\tvalid_0's multi_logloss: 1.13378\n",
            "[60]\tvalid_0's multi_logloss: 1.13244\n",
            "[61]\tvalid_0's multi_logloss: 1.13197\n",
            "[62]\tvalid_0's multi_logloss: 1.13107\n",
            "[63]\tvalid_0's multi_logloss: 1.1312\n",
            "[64]\tvalid_0's multi_logloss: 1.13153\n",
            "[65]\tvalid_0's multi_logloss: 1.12994\n",
            "[66]\tvalid_0's multi_logloss: 1.12925\n",
            "[67]\tvalid_0's multi_logloss: 1.12805\n",
            "[68]\tvalid_0's multi_logloss: 1.12817\n",
            "[69]\tvalid_0's multi_logloss: 1.12789\n",
            "[70]\tvalid_0's multi_logloss: 1.12672\n",
            "[71]\tvalid_0's multi_logloss: 1.12521\n",
            "[72]\tvalid_0's multi_logloss: 1.12457\n",
            "[73]\tvalid_0's multi_logloss: 1.12345\n",
            "[74]\tvalid_0's multi_logloss: 1.12216\n",
            "[75]\tvalid_0's multi_logloss: 1.12164\n",
            "[76]\tvalid_0's multi_logloss: 1.12174\n",
            "[77]\tvalid_0's multi_logloss: 1.12117\n",
            "[78]\tvalid_0's multi_logloss: 1.12112\n",
            "[79]\tvalid_0's multi_logloss: 1.12056\n",
            "[80]\tvalid_0's multi_logloss: 1.12003\n",
            "[81]\tvalid_0's multi_logloss: 1.12047\n",
            "[82]\tvalid_0's multi_logloss: 1.11954\n",
            "[83]\tvalid_0's multi_logloss: 1.11923\n",
            "[84]\tvalid_0's multi_logloss: 1.11977\n",
            "[85]\tvalid_0's multi_logloss: 1.12064\n",
            "[86]\tvalid_0's multi_logloss: 1.12059\n",
            "[87]\tvalid_0's multi_logloss: 1.12062\n",
            "[88]\tvalid_0's multi_logloss: 1.12028\n",
            "[89]\tvalid_0's multi_logloss: 1.11964\n",
            "[90]\tvalid_0's multi_logloss: 1.11876\n",
            "[91]\tvalid_0's multi_logloss: 1.11778\n",
            "[92]\tvalid_0's multi_logloss: 1.11714\n",
            "[93]\tvalid_0's multi_logloss: 1.11714\n",
            "[94]\tvalid_0's multi_logloss: 1.11737\n",
            "[95]\tvalid_0's multi_logloss: 1.11668\n",
            "[96]\tvalid_0's multi_logloss: 1.11618\n",
            "[97]\tvalid_0's multi_logloss: 1.11508\n",
            "[98]\tvalid_0's multi_logloss: 1.11468\n",
            "[99]\tvalid_0's multi_logloss: 1.11507\n",
            "[100]\tvalid_0's multi_logloss: 1.1151\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 1.92863\n",
            "[2]\tvalid_0's multi_logloss: 1.80606\n",
            "[3]\tvalid_0's multi_logloss: 1.71291\n",
            "[4]\tvalid_0's multi_logloss: 1.64565\n",
            "[5]\tvalid_0's multi_logloss: 1.59151\n",
            "[6]\tvalid_0's multi_logloss: 1.54614\n",
            "[7]\tvalid_0's multi_logloss: 1.50412\n",
            "[8]\tvalid_0's multi_logloss: 1.46957\n",
            "[9]\tvalid_0's multi_logloss: 1.43822\n",
            "[10]\tvalid_0's multi_logloss: 1.41159\n",
            "[11]\tvalid_0's multi_logloss: 1.38881\n",
            "[12]\tvalid_0's multi_logloss: 1.36619\n",
            "[13]\tvalid_0's multi_logloss: 1.34498\n",
            "[14]\tvalid_0's multi_logloss: 1.33108\n",
            "[15]\tvalid_0's multi_logloss: 1.31602\n",
            "[16]\tvalid_0's multi_logloss: 1.30087\n",
            "[17]\tvalid_0's multi_logloss: 1.28704\n",
            "[18]\tvalid_0's multi_logloss: 1.27462\n",
            "[19]\tvalid_0's multi_logloss: 1.26624\n",
            "[20]\tvalid_0's multi_logloss: 1.25628\n",
            "[21]\tvalid_0's multi_logloss: 1.24666\n",
            "[22]\tvalid_0's multi_logloss: 1.23755\n",
            "[23]\tvalid_0's multi_logloss: 1.23023\n",
            "[24]\tvalid_0's multi_logloss: 1.22214\n",
            "[25]\tvalid_0's multi_logloss: 1.21554\n",
            "[26]\tvalid_0's multi_logloss: 1.20926\n",
            "[27]\tvalid_0's multi_logloss: 1.20515\n",
            "[28]\tvalid_0's multi_logloss: 1.19882\n",
            "[29]\tvalid_0's multi_logloss: 1.19529\n",
            "[30]\tvalid_0's multi_logloss: 1.19041\n",
            "[31]\tvalid_0's multi_logloss: 1.18552\n",
            "[32]\tvalid_0's multi_logloss: 1.17991\n",
            "[33]\tvalid_0's multi_logloss: 1.17539\n",
            "[34]\tvalid_0's multi_logloss: 1.17084\n",
            "[35]\tvalid_0's multi_logloss: 1.16572\n",
            "[36]\tvalid_0's multi_logloss: 1.16209\n",
            "[37]\tvalid_0's multi_logloss: 1.15829\n",
            "[38]\tvalid_0's multi_logloss: 1.15563\n",
            "[39]\tvalid_0's multi_logloss: 1.15414\n",
            "[40]\tvalid_0's multi_logloss: 1.15191\n",
            "[41]\tvalid_0's multi_logloss: 1.14942\n",
            "[42]\tvalid_0's multi_logloss: 1.14657\n",
            "[43]\tvalid_0's multi_logloss: 1.14478\n",
            "[44]\tvalid_0's multi_logloss: 1.14235\n",
            "[45]\tvalid_0's multi_logloss: 1.13965\n",
            "[46]\tvalid_0's multi_logloss: 1.13624\n",
            "[47]\tvalid_0's multi_logloss: 1.13359\n",
            "[48]\tvalid_0's multi_logloss: 1.13178\n",
            "[49]\tvalid_0's multi_logloss: 1.12999\n",
            "[50]\tvalid_0's multi_logloss: 1.12823\n",
            "[51]\tvalid_0's multi_logloss: 1.12624\n",
            "[52]\tvalid_0's multi_logloss: 1.12573\n",
            "[53]\tvalid_0's multi_logloss: 1.12431\n",
            "[54]\tvalid_0's multi_logloss: 1.12315\n",
            "[55]\tvalid_0's multi_logloss: 1.12159\n",
            "[56]\tvalid_0's multi_logloss: 1.12018\n",
            "[57]\tvalid_0's multi_logloss: 1.11889\n",
            "[58]\tvalid_0's multi_logloss: 1.11805\n",
            "[59]\tvalid_0's multi_logloss: 1.11636\n",
            "[60]\tvalid_0's multi_logloss: 1.11583\n",
            "[61]\tvalid_0's multi_logloss: 1.11476\n",
            "[62]\tvalid_0's multi_logloss: 1.11408\n",
            "[63]\tvalid_0's multi_logloss: 1.11293\n",
            "[64]\tvalid_0's multi_logloss: 1.11179\n",
            "[65]\tvalid_0's multi_logloss: 1.11043\n",
            "[66]\tvalid_0's multi_logloss: 1.10967\n",
            "[67]\tvalid_0's multi_logloss: 1.10901\n",
            "[68]\tvalid_0's multi_logloss: 1.10791\n",
            "[69]\tvalid_0's multi_logloss: 1.10721\n",
            "[70]\tvalid_0's multi_logloss: 1.10692\n",
            "[71]\tvalid_0's multi_logloss: 1.10699\n",
            "[72]\tvalid_0's multi_logloss: 1.10614\n",
            "[73]\tvalid_0's multi_logloss: 1.10634\n",
            "[74]\tvalid_0's multi_logloss: 1.10581\n",
            "[75]\tvalid_0's multi_logloss: 1.10521\n",
            "[76]\tvalid_0's multi_logloss: 1.10446\n",
            "[77]\tvalid_0's multi_logloss: 1.10403\n",
            "[78]\tvalid_0's multi_logloss: 1.10342\n",
            "[79]\tvalid_0's multi_logloss: 1.10322\n",
            "[80]\tvalid_0's multi_logloss: 1.10353\n",
            "[81]\tvalid_0's multi_logloss: 1.10252\n",
            "[82]\tvalid_0's multi_logloss: 1.1026\n",
            "[83]\tvalid_0's multi_logloss: 1.10305\n",
            "[84]\tvalid_0's multi_logloss: 1.10316\n",
            "[85]\tvalid_0's multi_logloss: 1.10255\n",
            "[86]\tvalid_0's multi_logloss: 1.10256\n",
            "[87]\tvalid_0's multi_logloss: 1.10159\n",
            "[88]\tvalid_0's multi_logloss: 1.10192\n",
            "[89]\tvalid_0's multi_logloss: 1.1007\n",
            "[90]\tvalid_0's multi_logloss: 1.10096\n",
            "[91]\tvalid_0's multi_logloss: 1.10105\n",
            "[92]\tvalid_0's multi_logloss: 1.10076\n",
            "[93]\tvalid_0's multi_logloss: 1.10114\n",
            "[94]\tvalid_0's multi_logloss: 1.101\n",
            "[95]\tvalid_0's multi_logloss: 1.10119\n",
            "[96]\tvalid_0's multi_logloss: 1.1004\n",
            "[97]\tvalid_0's multi_logloss: 1.1003\n",
            "[98]\tvalid_0's multi_logloss: 1.10001\n",
            "[99]\tvalid_0's multi_logloss: 1.10011\n",
            "[100]\tvalid_0's multi_logloss: 1.09989\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 1.93127\n",
            "[2]\tvalid_0's multi_logloss: 1.81636\n",
            "[3]\tvalid_0's multi_logloss: 1.72833\n",
            "[4]\tvalid_0's multi_logloss: 1.6616\n",
            "[5]\tvalid_0's multi_logloss: 1.60463\n",
            "[6]\tvalid_0's multi_logloss: 1.55619\n",
            "[7]\tvalid_0's multi_logloss: 1.51597\n",
            "[8]\tvalid_0's multi_logloss: 1.48202\n",
            "[9]\tvalid_0's multi_logloss: 1.45151\n",
            "[10]\tvalid_0's multi_logloss: 1.42147\n",
            "[11]\tvalid_0's multi_logloss: 1.39844\n",
            "[12]\tvalid_0's multi_logloss: 1.37456\n",
            "[13]\tvalid_0's multi_logloss: 1.35697\n",
            "[14]\tvalid_0's multi_logloss: 1.34017\n",
            "[15]\tvalid_0's multi_logloss: 1.32556\n",
            "[16]\tvalid_0's multi_logloss: 1.31225\n",
            "[17]\tvalid_0's multi_logloss: 1.30101\n",
            "[18]\tvalid_0's multi_logloss: 1.28871\n",
            "[19]\tvalid_0's multi_logloss: 1.27887\n",
            "[20]\tvalid_0's multi_logloss: 1.26878\n",
            "[21]\tvalid_0's multi_logloss: 1.25899\n",
            "[22]\tvalid_0's multi_logloss: 1.25041\n",
            "[23]\tvalid_0's multi_logloss: 1.24171\n",
            "[24]\tvalid_0's multi_logloss: 1.23519\n",
            "[25]\tvalid_0's multi_logloss: 1.22872\n",
            "[26]\tvalid_0's multi_logloss: 1.22313\n",
            "[27]\tvalid_0's multi_logloss: 1.21779\n",
            "[28]\tvalid_0's multi_logloss: 1.21116\n",
            "[29]\tvalid_0's multi_logloss: 1.20572\n",
            "[30]\tvalid_0's multi_logloss: 1.20155\n",
            "[31]\tvalid_0's multi_logloss: 1.1965\n",
            "[32]\tvalid_0's multi_logloss: 1.19249\n",
            "[33]\tvalid_0's multi_logloss: 1.18842\n",
            "[34]\tvalid_0's multi_logloss: 1.18624\n",
            "[35]\tvalid_0's multi_logloss: 1.18241\n",
            "[36]\tvalid_0's multi_logloss: 1.17915\n",
            "[37]\tvalid_0's multi_logloss: 1.17653\n",
            "[38]\tvalid_0's multi_logloss: 1.17353\n",
            "[39]\tvalid_0's multi_logloss: 1.17242\n",
            "[40]\tvalid_0's multi_logloss: 1.16913\n",
            "[41]\tvalid_0's multi_logloss: 1.16665\n",
            "[42]\tvalid_0's multi_logloss: 1.16351\n",
            "[43]\tvalid_0's multi_logloss: 1.16218\n",
            "[44]\tvalid_0's multi_logloss: 1.16109\n",
            "[45]\tvalid_0's multi_logloss: 1.15863\n",
            "[46]\tvalid_0's multi_logloss: 1.1575\n",
            "[47]\tvalid_0's multi_logloss: 1.15359\n",
            "[48]\tvalid_0's multi_logloss: 1.15095\n",
            "[49]\tvalid_0's multi_logloss: 1.14957\n",
            "[50]\tvalid_0's multi_logloss: 1.14839\n",
            "[51]\tvalid_0's multi_logloss: 1.14656\n",
            "[52]\tvalid_0's multi_logloss: 1.14541\n",
            "[53]\tvalid_0's multi_logloss: 1.14292\n",
            "[54]\tvalid_0's multi_logloss: 1.1411\n",
            "[55]\tvalid_0's multi_logloss: 1.13996\n",
            "[56]\tvalid_0's multi_logloss: 1.13901\n",
            "[57]\tvalid_0's multi_logloss: 1.13783\n",
            "[58]\tvalid_0's multi_logloss: 1.13664\n",
            "[59]\tvalid_0's multi_logloss: 1.1361\n",
            "[60]\tvalid_0's multi_logloss: 1.13511\n",
            "[61]\tvalid_0's multi_logloss: 1.13379\n",
            "[62]\tvalid_0's multi_logloss: 1.13235\n",
            "[63]\tvalid_0's multi_logloss: 1.13162\n",
            "[64]\tvalid_0's multi_logloss: 1.13108\n",
            "[65]\tvalid_0's multi_logloss: 1.13042\n",
            "[66]\tvalid_0's multi_logloss: 1.1294\n",
            "[67]\tvalid_0's multi_logloss: 1.12886\n",
            "[68]\tvalid_0's multi_logloss: 1.1286\n",
            "[69]\tvalid_0's multi_logloss: 1.12707\n",
            "[70]\tvalid_0's multi_logloss: 1.12605\n",
            "[71]\tvalid_0's multi_logloss: 1.1259\n",
            "[72]\tvalid_0's multi_logloss: 1.12528\n",
            "[73]\tvalid_0's multi_logloss: 1.12361\n",
            "[74]\tvalid_0's multi_logloss: 1.12339\n",
            "[75]\tvalid_0's multi_logloss: 1.12378\n",
            "[76]\tvalid_0's multi_logloss: 1.1223\n",
            "[77]\tvalid_0's multi_logloss: 1.12117\n",
            "[78]\tvalid_0's multi_logloss: 1.12045\n",
            "[79]\tvalid_0's multi_logloss: 1.12054\n",
            "[80]\tvalid_0's multi_logloss: 1.12012\n",
            "[81]\tvalid_0's multi_logloss: 1.1194\n",
            "[82]\tvalid_0's multi_logloss: 1.11823\n",
            "[83]\tvalid_0's multi_logloss: 1.1172\n",
            "[84]\tvalid_0's multi_logloss: 1.11703\n",
            "[85]\tvalid_0's multi_logloss: 1.11681\n",
            "[86]\tvalid_0's multi_logloss: 1.11657\n",
            "[87]\tvalid_0's multi_logloss: 1.11569\n",
            "[88]\tvalid_0's multi_logloss: 1.11506\n",
            "[89]\tvalid_0's multi_logloss: 1.11574\n",
            "[90]\tvalid_0's multi_logloss: 1.11502\n",
            "[91]\tvalid_0's multi_logloss: 1.11445\n",
            "[92]\tvalid_0's multi_logloss: 1.11407\n",
            "[93]\tvalid_0's multi_logloss: 1.11332\n",
            "[94]\tvalid_0's multi_logloss: 1.11268\n",
            "[95]\tvalid_0's multi_logloss: 1.11248\n",
            "[96]\tvalid_0's multi_logloss: 1.11301\n",
            "[97]\tvalid_0's multi_logloss: 1.11277\n",
            "[98]\tvalid_0's multi_logloss: 1.11275\n",
            "[99]\tvalid_0's multi_logloss: 1.11208\n",
            "[100]\tvalid_0's multi_logloss: 1.11178\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n",
            "[1]\tvalid_0's multi_logloss: 2.04078\n",
            "[2]\tvalid_0's multi_logloss: 1.95268\n",
            "[3]\tvalid_0's multi_logloss: 1.88261\n",
            "[4]\tvalid_0's multi_logloss: 1.82788\n",
            "[5]\tvalid_0's multi_logloss: 1.78046\n",
            "[6]\tvalid_0's multi_logloss: 1.73594\n",
            "[7]\tvalid_0's multi_logloss: 1.69978\n",
            "[8]\tvalid_0's multi_logloss: 1.66613\n",
            "[9]\tvalid_0's multi_logloss: 1.63507\n",
            "[10]\tvalid_0's multi_logloss: 1.60653\n",
            "[11]\tvalid_0's multi_logloss: 1.58058\n",
            "[12]\tvalid_0's multi_logloss: 1.55737\n",
            "[13]\tvalid_0's multi_logloss: 1.53472\n",
            "[14]\tvalid_0's multi_logloss: 1.51391\n",
            "[15]\tvalid_0's multi_logloss: 1.4956\n",
            "[16]\tvalid_0's multi_logloss: 1.47794\n",
            "[17]\tvalid_0's multi_logloss: 1.4615\n",
            "[18]\tvalid_0's multi_logloss: 1.44543\n",
            "[19]\tvalid_0's multi_logloss: 1.4301\n",
            "[20]\tvalid_0's multi_logloss: 1.4151\n",
            "[21]\tvalid_0's multi_logloss: 1.40099\n",
            "[22]\tvalid_0's multi_logloss: 1.38846\n",
            "[23]\tvalid_0's multi_logloss: 1.37664\n",
            "[24]\tvalid_0's multi_logloss: 1.36469\n",
            "[25]\tvalid_0's multi_logloss: 1.35466\n",
            "[26]\tvalid_0's multi_logloss: 1.34454\n",
            "[27]\tvalid_0's multi_logloss: 1.33381\n",
            "[28]\tvalid_0's multi_logloss: 1.32507\n",
            "[29]\tvalid_0's multi_logloss: 1.31613\n",
            "[30]\tvalid_0's multi_logloss: 1.30853\n",
            "[31]\tvalid_0's multi_logloss: 1.30078\n",
            "[32]\tvalid_0's multi_logloss: 1.29411\n",
            "[33]\tvalid_0's multi_logloss: 1.28711\n",
            "[34]\tvalid_0's multi_logloss: 1.28052\n",
            "[35]\tvalid_0's multi_logloss: 1.27417\n",
            "[36]\tvalid_0's multi_logloss: 1.26722\n",
            "[37]\tvalid_0's multi_logloss: 1.26059\n",
            "[38]\tvalid_0's multi_logloss: 1.25505\n",
            "[39]\tvalid_0's multi_logloss: 1.24892\n",
            "[40]\tvalid_0's multi_logloss: 1.24324\n",
            "[41]\tvalid_0's multi_logloss: 1.23814\n",
            "[42]\tvalid_0's multi_logloss: 1.23331\n",
            "[43]\tvalid_0's multi_logloss: 1.2278\n",
            "[44]\tvalid_0's multi_logloss: 1.22366\n",
            "[45]\tvalid_0's multi_logloss: 1.21908\n",
            "[46]\tvalid_0's multi_logloss: 1.21516\n",
            "[47]\tvalid_0's multi_logloss: 1.21079\n",
            "[48]\tvalid_0's multi_logloss: 1.20607\n",
            "[49]\tvalid_0's multi_logloss: 1.20219\n",
            "[50]\tvalid_0's multi_logloss: 1.19811\n",
            "[51]\tvalid_0's multi_logloss: 1.19411\n",
            "[52]\tvalid_0's multi_logloss: 1.19067\n",
            "[53]\tvalid_0's multi_logloss: 1.18681\n",
            "[54]\tvalid_0's multi_logloss: 1.18393\n",
            "[55]\tvalid_0's multi_logloss: 1.18082\n",
            "[56]\tvalid_0's multi_logloss: 1.17774\n",
            "[57]\tvalid_0's multi_logloss: 1.17432\n",
            "[58]\tvalid_0's multi_logloss: 1.17192\n",
            "[59]\tvalid_0's multi_logloss: 1.16926\n",
            "[60]\tvalid_0's multi_logloss: 1.1671\n",
            "[61]\tvalid_0's multi_logloss: 1.16515\n",
            "[62]\tvalid_0's multi_logloss: 1.16228\n",
            "[63]\tvalid_0's multi_logloss: 1.1598\n",
            "[64]\tvalid_0's multi_logloss: 1.15733\n",
            "[65]\tvalid_0's multi_logloss: 1.15493\n",
            "[66]\tvalid_0's multi_logloss: 1.15263\n",
            "[67]\tvalid_0's multi_logloss: 1.15065\n",
            "[68]\tvalid_0's multi_logloss: 1.14873\n",
            "[69]\tvalid_0's multi_logloss: 1.14673\n",
            "[70]\tvalid_0's multi_logloss: 1.1442\n",
            "[71]\tvalid_0's multi_logloss: 1.14246\n",
            "[72]\tvalid_0's multi_logloss: 1.14128\n",
            "[73]\tvalid_0's multi_logloss: 1.13955\n",
            "[74]\tvalid_0's multi_logloss: 1.13858\n",
            "[75]\tvalid_0's multi_logloss: 1.13723\n",
            "[76]\tvalid_0's multi_logloss: 1.13505\n",
            "[77]\tvalid_0's multi_logloss: 1.13345\n",
            "[78]\tvalid_0's multi_logloss: 1.13176\n",
            "[79]\tvalid_0's multi_logloss: 1.13011\n",
            "[80]\tvalid_0's multi_logloss: 1.12887\n",
            "[81]\tvalid_0's multi_logloss: 1.12688\n",
            "[82]\tvalid_0's multi_logloss: 1.12552\n",
            "[83]\tvalid_0's multi_logloss: 1.12359\n",
            "[84]\tvalid_0's multi_logloss: 1.12232\n",
            "[85]\tvalid_0's multi_logloss: 1.12063\n",
            "[86]\tvalid_0's multi_logloss: 1.12019\n",
            "[87]\tvalid_0's multi_logloss: 1.11951\n",
            "[88]\tvalid_0's multi_logloss: 1.11839\n",
            "[89]\tvalid_0's multi_logloss: 1.11741\n",
            "[90]\tvalid_0's multi_logloss: 1.11595\n",
            "[91]\tvalid_0's multi_logloss: 1.11488\n",
            "[92]\tvalid_0's multi_logloss: 1.11373\n",
            "[93]\tvalid_0's multi_logloss: 1.11251\n",
            "[94]\tvalid_0's multi_logloss: 1.11172\n",
            "[95]\tvalid_0's multi_logloss: 1.11022\n",
            "[96]\tvalid_0's multi_logloss: 1.109\n",
            "[97]\tvalid_0's multi_logloss: 1.10783\n",
            "[98]\tvalid_0's multi_logloss: 1.10706\n",
            "[99]\tvalid_0's multi_logloss: 1.10627\n",
            "[100]\tvalid_0's multi_logloss: 1.10521\n",
            "Best parameters found by grid search are: {'boosting_type': 'gbdt', 'lambda_l1': 0.1, 'lambda_l2': 0.2, 'learning_rate': 0.1, 'metric': 'multiclass', 'n_estimators': 100, 'num_leaves': 10, 'objective': 'multiclass', 'random_state': 501}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import auc, accuracy_score, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "estimator = lgb.LGBMClassifier(boosting_type='gbdt', \n",
        "                               learning_rate = 0.125, \n",
        "                               metric = 'multiclass', n_estimators = 20,\n",
        "                               num_leaves = 38)\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [x for x in [75,100]],\n",
        "    'learning_rate': [0.01,0.1,0.2],\n",
        "    'num_leaves': [5,10],\n",
        "    'boosting_type' : ['gbdt'],\n",
        "    'objective' : ['multiclass'],\n",
        "    'metric': ['multiclass'],\n",
        "    'lambda_l1' : [0.10],\n",
        "    'lambda_l2' : [0.20],\n",
        "    'random_state' : [501]}\n",
        "\n",
        "gridsearch = GridSearchCV(estimator, param_grid)\n",
        "\n",
        "gridsearch.fit(X_train, y_train.values.ravel(),eval_set = [(X_test, y_test)],eval_metric = ['multi_logloss'],early_stopping_rounds = 10)\n",
        "\n",
        "print('Best parameters found by grid search are:', gridsearch.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0Zj78alAr-9b",
        "outputId": "975d0344-f7b6-4474-8df2-b30ec15ef7ab"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's multi_logloss: 2.04196\n",
            "[2]\tvalid_0's multi_logloss: 1.95347\n",
            "[3]\tvalid_0's multi_logloss: 1.8835\n",
            "[4]\tvalid_0's multi_logloss: 1.82712\n",
            "[5]\tvalid_0's multi_logloss: 1.78018\n",
            "[6]\tvalid_0's multi_logloss: 1.73626\n",
            "[7]\tvalid_0's multi_logloss: 1.69877\n",
            "[8]\tvalid_0's multi_logloss: 1.6663\n",
            "[9]\tvalid_0's multi_logloss: 1.63524\n",
            "[10]\tvalid_0's multi_logloss: 1.60541\n",
            "[11]\tvalid_0's multi_logloss: 1.58017\n",
            "[12]\tvalid_0's multi_logloss: 1.55574\n",
            "[13]\tvalid_0's multi_logloss: 1.53299\n",
            "[14]\tvalid_0's multi_logloss: 1.51338\n",
            "[15]\tvalid_0's multi_logloss: 1.49423\n",
            "[16]\tvalid_0's multi_logloss: 1.47682\n",
            "[17]\tvalid_0's multi_logloss: 1.45896\n",
            "[18]\tvalid_0's multi_logloss: 1.44387\n",
            "[19]\tvalid_0's multi_logloss: 1.42768\n",
            "[20]\tvalid_0's multi_logloss: 1.41335\n",
            "[21]\tvalid_0's multi_logloss: 1.40082\n",
            "[22]\tvalid_0's multi_logloss: 1.3873\n",
            "[23]\tvalid_0's multi_logloss: 1.37667\n",
            "[24]\tvalid_0's multi_logloss: 1.36527\n",
            "[25]\tvalid_0's multi_logloss: 1.35505\n",
            "[26]\tvalid_0's multi_logloss: 1.3443\n",
            "[27]\tvalid_0's multi_logloss: 1.33388\n",
            "[28]\tvalid_0's multi_logloss: 1.32543\n",
            "[29]\tvalid_0's multi_logloss: 1.31724\n",
            "[30]\tvalid_0's multi_logloss: 1.30891\n",
            "[31]\tvalid_0's multi_logloss: 1.30093\n",
            "[32]\tvalid_0's multi_logloss: 1.29357\n",
            "[33]\tvalid_0's multi_logloss: 1.28643\n",
            "[34]\tvalid_0's multi_logloss: 1.27969\n",
            "[35]\tvalid_0's multi_logloss: 1.27352\n",
            "[36]\tvalid_0's multi_logloss: 1.26647\n",
            "[37]\tvalid_0's multi_logloss: 1.26003\n",
            "[38]\tvalid_0's multi_logloss: 1.25408\n",
            "[39]\tvalid_0's multi_logloss: 1.24832\n",
            "[40]\tvalid_0's multi_logloss: 1.24291\n",
            "[41]\tvalid_0's multi_logloss: 1.23673\n",
            "[42]\tvalid_0's multi_logloss: 1.23097\n",
            "[43]\tvalid_0's multi_logloss: 1.22651\n",
            "[44]\tvalid_0's multi_logloss: 1.22189\n",
            "[45]\tvalid_0's multi_logloss: 1.21766\n",
            "[46]\tvalid_0's multi_logloss: 1.2132\n",
            "[47]\tvalid_0's multi_logloss: 1.20898\n",
            "[48]\tvalid_0's multi_logloss: 1.20534\n",
            "[49]\tvalid_0's multi_logloss: 1.20215\n",
            "[50]\tvalid_0's multi_logloss: 1.19826\n",
            "[51]\tvalid_0's multi_logloss: 1.19494\n",
            "[52]\tvalid_0's multi_logloss: 1.19143\n",
            "[53]\tvalid_0's multi_logloss: 1.18776\n",
            "[54]\tvalid_0's multi_logloss: 1.18499\n",
            "[55]\tvalid_0's multi_logloss: 1.18202\n",
            "[56]\tvalid_0's multi_logloss: 1.17873\n",
            "[57]\tvalid_0's multi_logloss: 1.17607\n",
            "[58]\tvalid_0's multi_logloss: 1.17358\n",
            "[59]\tvalid_0's multi_logloss: 1.17063\n",
            "[60]\tvalid_0's multi_logloss: 1.16787\n",
            "[61]\tvalid_0's multi_logloss: 1.16549\n",
            "[62]\tvalid_0's multi_logloss: 1.16284\n",
            "[63]\tvalid_0's multi_logloss: 1.16081\n",
            "[64]\tvalid_0's multi_logloss: 1.1579\n",
            "[65]\tvalid_0's multi_logloss: 1.15555\n",
            "[66]\tvalid_0's multi_logloss: 1.15371\n",
            "[67]\tvalid_0's multi_logloss: 1.15175\n",
            "[68]\tvalid_0's multi_logloss: 1.14912\n",
            "[69]\tvalid_0's multi_logloss: 1.1472\n",
            "[70]\tvalid_0's multi_logloss: 1.14511\n",
            "[71]\tvalid_0's multi_logloss: 1.14269\n",
            "[72]\tvalid_0's multi_logloss: 1.14102\n",
            "[73]\tvalid_0's multi_logloss: 1.13935\n",
            "[74]\tvalid_0's multi_logloss: 1.13782\n",
            "[75]\tvalid_0's multi_logloss: 1.1357\n",
            "[76]\tvalid_0's multi_logloss: 1.134\n",
            "[77]\tvalid_0's multi_logloss: 1.13226\n",
            "[78]\tvalid_0's multi_logloss: 1.13064\n",
            "[79]\tvalid_0's multi_logloss: 1.12947\n",
            "[80]\tvalid_0's multi_logloss: 1.12808\n",
            "[81]\tvalid_0's multi_logloss: 1.12654\n",
            "[82]\tvalid_0's multi_logloss: 1.1253\n",
            "[83]\tvalid_0's multi_logloss: 1.12353\n",
            "[84]\tvalid_0's multi_logloss: 1.12181\n",
            "[85]\tvalid_0's multi_logloss: 1.12063\n",
            "[86]\tvalid_0's multi_logloss: 1.11925\n",
            "[87]\tvalid_0's multi_logloss: 1.11739\n",
            "[88]\tvalid_0's multi_logloss: 1.11609\n",
            "[89]\tvalid_0's multi_logloss: 1.1149\n",
            "[90]\tvalid_0's multi_logloss: 1.11351\n",
            "[91]\tvalid_0's multi_logloss: 1.11244\n",
            "[92]\tvalid_0's multi_logloss: 1.11098\n",
            "[93]\tvalid_0's multi_logloss: 1.10981\n",
            "[94]\tvalid_0's multi_logloss: 1.10889\n",
            "[95]\tvalid_0's multi_logloss: 1.1081\n",
            "[96]\tvalid_0's multi_logloss: 1.10743\n",
            "[97]\tvalid_0's multi_logloss: 1.1061\n",
            "[98]\tvalid_0's multi_logloss: 1.1051\n",
            "[99]\tvalid_0's multi_logloss: 1.10389\n",
            "[100]\tvalid_0's multi_logloss: 1.10245\n",
            "[101]\tvalid_0's multi_logloss: 1.10163\n",
            "[102]\tvalid_0's multi_logloss: 1.10077\n",
            "[103]\tvalid_0's multi_logloss: 1.10061\n",
            "[104]\tvalid_0's multi_logloss: 1.09925\n",
            "[105]\tvalid_0's multi_logloss: 1.09831\n",
            "[106]\tvalid_0's multi_logloss: 1.09783\n",
            "[107]\tvalid_0's multi_logloss: 1.09705\n",
            "[108]\tvalid_0's multi_logloss: 1.0962\n",
            "[109]\tvalid_0's multi_logloss: 1.09551\n",
            "[110]\tvalid_0's multi_logloss: 1.09489\n",
            "[111]\tvalid_0's multi_logloss: 1.09443\n",
            "[112]\tvalid_0's multi_logloss: 1.09312\n",
            "[113]\tvalid_0's multi_logloss: 1.09253\n",
            "[114]\tvalid_0's multi_logloss: 1.09213\n",
            "[115]\tvalid_0's multi_logloss: 1.09148\n",
            "[116]\tvalid_0's multi_logloss: 1.09099\n",
            "[117]\tvalid_0's multi_logloss: 1.09059\n",
            "[118]\tvalid_0's multi_logloss: 1.08954\n",
            "[119]\tvalid_0's multi_logloss: 1.08899\n",
            "[120]\tvalid_0's multi_logloss: 1.08802\n",
            "[121]\tvalid_0's multi_logloss: 1.08755\n",
            "[122]\tvalid_0's multi_logloss: 1.08691\n",
            "[123]\tvalid_0's multi_logloss: 1.08608\n",
            "[124]\tvalid_0's multi_logloss: 1.08529\n",
            "[125]\tvalid_0's multi_logloss: 1.08479\n",
            "[126]\tvalid_0's multi_logloss: 1.08435\n",
            "[127]\tvalid_0's multi_logloss: 1.08364\n",
            "[128]\tvalid_0's multi_logloss: 1.08295\n",
            "[129]\tvalid_0's multi_logloss: 1.08252\n",
            "[130]\tvalid_0's multi_logloss: 1.0817\n",
            "[131]\tvalid_0's multi_logloss: 1.08125\n",
            "[132]\tvalid_0's multi_logloss: 1.08082\n",
            "[133]\tvalid_0's multi_logloss: 1.08032\n",
            "[134]\tvalid_0's multi_logloss: 1.07949\n",
            "[135]\tvalid_0's multi_logloss: 1.07854\n",
            "[136]\tvalid_0's multi_logloss: 1.07796\n",
            "[137]\tvalid_0's multi_logloss: 1.07774\n",
            "[138]\tvalid_0's multi_logloss: 1.0774\n",
            "[139]\tvalid_0's multi_logloss: 1.07632\n",
            "[140]\tvalid_0's multi_logloss: 1.07549\n",
            "[141]\tvalid_0's multi_logloss: 1.07511\n",
            "[142]\tvalid_0's multi_logloss: 1.07483\n",
            "[143]\tvalid_0's multi_logloss: 1.07441\n",
            "[144]\tvalid_0's multi_logloss: 1.07406\n",
            "[145]\tvalid_0's multi_logloss: 1.07352\n",
            "[146]\tvalid_0's multi_logloss: 1.07282\n",
            "[147]\tvalid_0's multi_logloss: 1.07226\n",
            "[148]\tvalid_0's multi_logloss: 1.072\n",
            "[149]\tvalid_0's multi_logloss: 1.07106\n",
            "[150]\tvalid_0's multi_logloss: 1.07083\n",
            "[151]\tvalid_0's multi_logloss: 1.07052\n",
            "[152]\tvalid_0's multi_logloss: 1.07027\n",
            "[153]\tvalid_0's multi_logloss: 1.0694\n",
            "[154]\tvalid_0's multi_logloss: 1.06866\n",
            "[155]\tvalid_0's multi_logloss: 1.06819\n",
            "[156]\tvalid_0's multi_logloss: 1.06763\n",
            "[157]\tvalid_0's multi_logloss: 1.06707\n",
            "[158]\tvalid_0's multi_logloss: 1.06694\n",
            "[159]\tvalid_0's multi_logloss: 1.06671\n",
            "[160]\tvalid_0's multi_logloss: 1.0662\n",
            "[161]\tvalid_0's multi_logloss: 1.06584\n",
            "[162]\tvalid_0's multi_logloss: 1.06568\n",
            "[163]\tvalid_0's multi_logloss: 1.06556\n",
            "[164]\tvalid_0's multi_logloss: 1.06554\n",
            "[165]\tvalid_0's multi_logloss: 1.06528\n",
            "[166]\tvalid_0's multi_logloss: 1.06517\n",
            "[167]\tvalid_0's multi_logloss: 1.06491\n",
            "[168]\tvalid_0's multi_logloss: 1.06508\n",
            "[169]\tvalid_0's multi_logloss: 1.06493\n",
            "[170]\tvalid_0's multi_logloss: 1.06516\n",
            "[171]\tvalid_0's multi_logloss: 1.06432\n",
            "[172]\tvalid_0's multi_logloss: 1.06401\n",
            "[173]\tvalid_0's multi_logloss: 1.06379\n",
            "[174]\tvalid_0's multi_logloss: 1.06359\n",
            "[175]\tvalid_0's multi_logloss: 1.06318\n",
            "[176]\tvalid_0's multi_logloss: 1.06272\n",
            "[177]\tvalid_0's multi_logloss: 1.06234\n",
            "[178]\tvalid_0's multi_logloss: 1.06201\n",
            "[179]\tvalid_0's multi_logloss: 1.0619\n",
            "[180]\tvalid_0's multi_logloss: 1.06198\n",
            "[181]\tvalid_0's multi_logloss: 1.06153\n",
            "[182]\tvalid_0's multi_logloss: 1.06112\n",
            "[183]\tvalid_0's multi_logloss: 1.06098\n",
            "[184]\tvalid_0's multi_logloss: 1.06055\n",
            "[185]\tvalid_0's multi_logloss: 1.0601\n",
            "[186]\tvalid_0's multi_logloss: 1.05964\n",
            "[187]\tvalid_0's multi_logloss: 1.0598\n",
            "[188]\tvalid_0's multi_logloss: 1.05932\n",
            "[189]\tvalid_0's multi_logloss: 1.05892\n",
            "[190]\tvalid_0's multi_logloss: 1.0587\n",
            "[191]\tvalid_0's multi_logloss: 1.05841\n",
            "[192]\tvalid_0's multi_logloss: 1.05818\n",
            "[193]\tvalid_0's multi_logloss: 1.058\n",
            "[194]\tvalid_0's multi_logloss: 1.05781\n",
            "[195]\tvalid_0's multi_logloss: 1.05759\n",
            "[196]\tvalid_0's multi_logloss: 1.05728\n",
            "[197]\tvalid_0's multi_logloss: 1.05677\n",
            "[198]\tvalid_0's multi_logloss: 1.0563\n",
            "[199]\tvalid_0's multi_logloss: 1.05587\n",
            "[200]\tvalid_0's multi_logloss: 1.0557\n",
            "[201]\tvalid_0's multi_logloss: 1.05566\n",
            "[202]\tvalid_0's multi_logloss: 1.05537\n",
            "[203]\tvalid_0's multi_logloss: 1.05476\n",
            "[204]\tvalid_0's multi_logloss: 1.05469\n",
            "[205]\tvalid_0's multi_logloss: 1.05442\n",
            "[206]\tvalid_0's multi_logloss: 1.05388\n",
            "[207]\tvalid_0's multi_logloss: 1.05365\n",
            "[208]\tvalid_0's multi_logloss: 1.05347\n",
            "[209]\tvalid_0's multi_logloss: 1.05351\n",
            "[210]\tvalid_0's multi_logloss: 1.05338\n",
            "[211]\tvalid_0's multi_logloss: 1.05339\n",
            "[212]\tvalid_0's multi_logloss: 1.05302\n",
            "[213]\tvalid_0's multi_logloss: 1.0529\n",
            "[214]\tvalid_0's multi_logloss: 1.05228\n",
            "[215]\tvalid_0's multi_logloss: 1.05208\n",
            "[216]\tvalid_0's multi_logloss: 1.05201\n",
            "[217]\tvalid_0's multi_logloss: 1.0516\n",
            "[218]\tvalid_0's multi_logloss: 1.05145\n",
            "[219]\tvalid_0's multi_logloss: 1.05108\n",
            "[220]\tvalid_0's multi_logloss: 1.05097\n",
            "[221]\tvalid_0's multi_logloss: 1.0508\n",
            "[222]\tvalid_0's multi_logloss: 1.05043\n",
            "[223]\tvalid_0's multi_logloss: 1.04992\n",
            "[224]\tvalid_0's multi_logloss: 1.04944\n",
            "[225]\tvalid_0's multi_logloss: 1.0495\n",
            "[226]\tvalid_0's multi_logloss: 1.0494\n",
            "[227]\tvalid_0's multi_logloss: 1.0495\n",
            "[228]\tvalid_0's multi_logloss: 1.04935\n",
            "[229]\tvalid_0's multi_logloss: 1.04898\n",
            "[230]\tvalid_0's multi_logloss: 1.04876\n",
            "[231]\tvalid_0's multi_logloss: 1.04887\n",
            "[232]\tvalid_0's multi_logloss: 1.04856\n",
            "[233]\tvalid_0's multi_logloss: 1.04857\n",
            "[234]\tvalid_0's multi_logloss: 1.04862\n",
            "[235]\tvalid_0's multi_logloss: 1.04817\n",
            "[236]\tvalid_0's multi_logloss: 1.04796\n",
            "[237]\tvalid_0's multi_logloss: 1.04796\n",
            "[238]\tvalid_0's multi_logloss: 1.04839\n",
            "[239]\tvalid_0's multi_logloss: 1.04809\n",
            "[240]\tvalid_0's multi_logloss: 1.04808\n",
            "[241]\tvalid_0's multi_logloss: 1.04768\n",
            "[242]\tvalid_0's multi_logloss: 1.04759\n",
            "[243]\tvalid_0's multi_logloss: 1.04764\n",
            "[244]\tvalid_0's multi_logloss: 1.04764\n",
            "[245]\tvalid_0's multi_logloss: 1.0472\n",
            "[246]\tvalid_0's multi_logloss: 1.04754\n",
            "[247]\tvalid_0's multi_logloss: 1.04741\n",
            "[248]\tvalid_0's multi_logloss: 1.04729\n",
            "[249]\tvalid_0's multi_logloss: 1.04742\n",
            "[250]\tvalid_0's multi_logloss: 1.04735\n",
            "[251]\tvalid_0's multi_logloss: 1.04705\n",
            "[252]\tvalid_0's multi_logloss: 1.0467\n",
            "[253]\tvalid_0's multi_logloss: 1.04661\n",
            "[254]\tvalid_0's multi_logloss: 1.04675\n",
            "[255]\tvalid_0's multi_logloss: 1.04651\n",
            "[256]\tvalid_0's multi_logloss: 1.04651\n",
            "[257]\tvalid_0's multi_logloss: 1.0464\n",
            "[258]\tvalid_0's multi_logloss: 1.04638\n",
            "[259]\tvalid_0's multi_logloss: 1.04646\n",
            "[260]\tvalid_0's multi_logloss: 1.04637\n",
            "[261]\tvalid_0's multi_logloss: 1.04601\n",
            "[262]\tvalid_0's multi_logloss: 1.04605\n",
            "[263]\tvalid_0's multi_logloss: 1.04611\n",
            "[264]\tvalid_0's multi_logloss: 1.04599\n",
            "[265]\tvalid_0's multi_logloss: 1.04575\n",
            "[266]\tvalid_0's multi_logloss: 1.04583\n",
            "[267]\tvalid_0's multi_logloss: 1.04606\n",
            "[268]\tvalid_0's multi_logloss: 1.04605\n",
            "[269]\tvalid_0's multi_logloss: 1.04611\n",
            "[270]\tvalid_0's multi_logloss: 1.04561\n",
            "[271]\tvalid_0's multi_logloss: 1.04571\n",
            "[272]\tvalid_0's multi_logloss: 1.04537\n",
            "[273]\tvalid_0's multi_logloss: 1.04527\n",
            "[274]\tvalid_0's multi_logloss: 1.04544\n",
            "[275]\tvalid_0's multi_logloss: 1.04535\n",
            "[276]\tvalid_0's multi_logloss: 1.04535\n",
            "[277]\tvalid_0's multi_logloss: 1.04537\n",
            "[278]\tvalid_0's multi_logloss: 1.04523\n",
            "[279]\tvalid_0's multi_logloss: 1.04542\n",
            "[280]\tvalid_0's multi_logloss: 1.04502\n",
            "[281]\tvalid_0's multi_logloss: 1.04473\n",
            "[282]\tvalid_0's multi_logloss: 1.0448\n",
            "[283]\tvalid_0's multi_logloss: 1.04458\n",
            "[284]\tvalid_0's multi_logloss: 1.04417\n",
            "[285]\tvalid_0's multi_logloss: 1.04402\n",
            "[286]\tvalid_0's multi_logloss: 1.0439\n",
            "[287]\tvalid_0's multi_logloss: 1.04371\n",
            "[288]\tvalid_0's multi_logloss: 1.04344\n",
            "[289]\tvalid_0's multi_logloss: 1.04308\n",
            "[290]\tvalid_0's multi_logloss: 1.04332\n",
            "[291]\tvalid_0's multi_logloss: 1.04351\n",
            "[292]\tvalid_0's multi_logloss: 1.04359\n",
            "[293]\tvalid_0's multi_logloss: 1.04352\n",
            "[294]\tvalid_0's multi_logloss: 1.04343\n",
            "[295]\tvalid_0's multi_logloss: 1.04361\n",
            "[296]\tvalid_0's multi_logloss: 1.04349\n",
            "[297]\tvalid_0's multi_logloss: 1.04336\n",
            "[298]\tvalid_0's multi_logloss: 1.04345\n",
            "[299]\tvalid_0's multi_logloss: 1.04308\n",
            "[300]\tvalid_0's multi_logloss: 1.04314\n",
            "[301]\tvalid_0's multi_logloss: 1.04285\n",
            "[302]\tvalid_0's multi_logloss: 1.04271\n",
            "[303]\tvalid_0's multi_logloss: 1.0427\n",
            "[304]\tvalid_0's multi_logloss: 1.0428\n",
            "[305]\tvalid_0's multi_logloss: 1.04276\n",
            "[306]\tvalid_0's multi_logloss: 1.04277\n",
            "[307]\tvalid_0's multi_logloss: 1.04285\n",
            "[308]\tvalid_0's multi_logloss: 1.04281\n",
            "[309]\tvalid_0's multi_logloss: 1.04258\n",
            "[310]\tvalid_0's multi_logloss: 1.04261\n",
            "[311]\tvalid_0's multi_logloss: 1.04253\n",
            "[312]\tvalid_0's multi_logloss: 1.04262\n",
            "[313]\tvalid_0's multi_logloss: 1.04241\n",
            "[314]\tvalid_0's multi_logloss: 1.04223\n",
            "[315]\tvalid_0's multi_logloss: 1.04212\n",
            "[316]\tvalid_0's multi_logloss: 1.04213\n",
            "[317]\tvalid_0's multi_logloss: 1.04213\n",
            "[318]\tvalid_0's multi_logloss: 1.04236\n",
            "[319]\tvalid_0's multi_logloss: 1.04284\n",
            "[320]\tvalid_0's multi_logloss: 1.04292\n",
            "[321]\tvalid_0's multi_logloss: 1.04312\n",
            "[322]\tvalid_0's multi_logloss: 1.04303\n",
            "[323]\tvalid_0's multi_logloss: 1.04265\n",
            "[324]\tvalid_0's multi_logloss: 1.04263\n",
            "[325]\tvalid_0's multi_logloss: 1.04257\n",
            "[326]\tvalid_0's multi_logloss: 1.04243\n",
            "[327]\tvalid_0's multi_logloss: 1.0424\n",
            "[328]\tvalid_0's multi_logloss: 1.04229\n",
            "[329]\tvalid_0's multi_logloss: 1.04216\n",
            "[330]\tvalid_0's multi_logloss: 1.04221\n",
            "[331]\tvalid_0's multi_logloss: 1.04205\n",
            "[332]\tvalid_0's multi_logloss: 1.04218\n",
            "[333]\tvalid_0's multi_logloss: 1.042\n",
            "[334]\tvalid_0's multi_logloss: 1.04217\n",
            "[335]\tvalid_0's multi_logloss: 1.04198\n",
            "[336]\tvalid_0's multi_logloss: 1.04186\n",
            "[337]\tvalid_0's multi_logloss: 1.04166\n",
            "[338]\tvalid_0's multi_logloss: 1.04194\n",
            "[339]\tvalid_0's multi_logloss: 1.04197\n",
            "[340]\tvalid_0's multi_logloss: 1.04184\n",
            "[341]\tvalid_0's multi_logloss: 1.04201\n",
            "[342]\tvalid_0's multi_logloss: 1.0421\n",
            "[343]\tvalid_0's multi_logloss: 1.04217\n",
            "[344]\tvalid_0's multi_logloss: 1.04232\n",
            "[345]\tvalid_0's multi_logloss: 1.04246\n",
            "[346]\tvalid_0's multi_logloss: 1.04282\n",
            "[347]\tvalid_0's multi_logloss: 1.04277\n",
            "[348]\tvalid_0's multi_logloss: 1.04272\n",
            "[349]\tvalid_0's multi_logloss: 1.04283\n",
            "[350]\tvalid_0's multi_logloss: 1.04276\n",
            "[351]\tvalid_0's multi_logloss: 1.04278\n",
            "[352]\tvalid_0's multi_logloss: 1.04257\n",
            "[353]\tvalid_0's multi_logloss: 1.04239\n",
            "[354]\tvalid_0's multi_logloss: 1.04281\n",
            "[355]\tvalid_0's multi_logloss: 1.04303\n",
            "[356]\tvalid_0's multi_logloss: 1.04334\n",
            "[357]\tvalid_0's multi_logloss: 1.04323\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(lambda_l1=0.5, lambda_l2=0.4, n_estimators=400, num_leaves=10,\n",
              "               objective=&#x27;multiclass&#x27;, random_state=501)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(lambda_l1=0.5, lambda_l2=0.4, n_estimators=400, num_leaves=10,\n",
              "               objective=&#x27;multiclass&#x27;, random_state=501)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LGBMClassifier(lambda_l1=0.5, lambda_l2=0.4, n_estimators=400, num_leaves=10,\n",
              "               objective='multiclass', random_state=501)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gbm = lgb.LGBMClassifier(boosting_type= 'gbdt', learning_rate=0.1, \n",
        "                         n_estimators=400, num_leaves= 10,\n",
        "                         lambda_l1=0.5,\n",
        "                         lambda_l2=0.4,\n",
        "                         objective= 'multiclass', random_state= 501)\n",
        "\n",
        "gbm.fit(X_train, y_train,\n",
        "        eval_set=[(X_test, y_test)],\n",
        "        eval_metric=['multiclass'],\n",
        "early_stopping_rounds=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noA4btHFsG_3",
        "outputId": "2983bf71-b2ae-4b14-a719-4e69fa4aff53"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9773602757315673"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gbm.score(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfG7otzrsTJ7",
        "outputId": "cce0ea14-c754-4601-a9fa-f44b97e4fcea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6683559699979729\n"
          ]
        }
      ],
      "source": [
        "# Test Metric Validation\n",
        "y_pred_prob = gbm.predict_proba(X_test)\n",
        "pred_list=[]\n",
        "for i in range(len(y_pred_prob)):\n",
        "  pred_list.append(np.argmax(y_pred_prob[i]))\n",
        "\n",
        "test_predictions  = pd.DataFrame({'prediction' : pred_list,'Actual':y_test.Target})\n",
        "\n",
        "from sklearn import metrics\n",
        "print(metrics.accuracy_score(test_predictions.prediction, test_predictions.Actual))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXIFjd5I-exD"
      },
      "outputs": [],
      "source": [
        "df.to_csv('ModelCaptions.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}